diff --git a/DEFT_func.py b/DEFT_func.py
deleted file mode 100644
index 575b310..0000000
--- a/DEFT_func.py
+++ /dev/null
@@ -1,672 +0,0 @@
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-import theseus as th
-
-# Custom utility functions
-from util import (
-    extractSinandCos,
-    computeEdges,
-    computeKB,
-    quaternion_q,
-    computeW,
-    skew_symmetric,
-    scalar_func,
-    quaternion_rotation,
-    quaternion_rotation_parallel,
-)
-from theta_solver_numpy import theta_optimize_numpy
-from theta_solver import theta_optimize
-
-
-class DEFT_func(nn.Module):
-    """
-    A differentiable rod-modeling class that implements the Discrete Elastic Rods
-    theory (DER). It uses a "Bishop frame" approach for computing rod kinematics
-    (curvature, twist, etc.) and works with a solver to minimize the elastic
-    energy of the rod segments.
-
-    Args:
-        batch (int): Batch size for parallel processing.
-        n_branch (int): Number of branches in the rod structure (if multiple rods or branching).
-        n_vert (int): Number of vertices in the rod discretization.
-        n_edge (int): Number of edges (n_vert-1 typically).
-        edge_mask (torch.Tensor): A mask indicating which edges are valid/active.
-        zero_mask (torch.Tensor): A mask indicating which vertices are valid/active.
-        m_restEdgeL (torch.Tensor): The undeformed (rest) lengths of all edges.
-        bend_stiffness_parent (torch.Tensor): Per-edge bending stiffness for the parent rod segment.
-        bend_stiffness_child1 (torch.Tensor): Per-edge bending stiffness for child rod segment #1.
-        bend_stiffness_child2 (torch.Tensor): Per-edge bending stiffness for child rod segment #2.
-        twist_stiffness (torch.Tensor): Per-edge twisting stiffness.
-        device (torch.device): CPU or GPU device.
-
-    """
-    def __init__(
-        self,
-        batch,
-        n_branch,
-        n_vert,
-        n_edge,
-        edge_mask,
-        zero_mask,
-        m_restEdgeL,
-        bend_stiffness_parent,
-        bend_stiffness_child1,
-        bend_stiffness_child2,
-        twist_stiffness,
-        device,
-    ):
-        super().__init__()
-
-        # Initialize basic properties
-        self.batch = batch
-        self.n_vert = n_vert
-        self.n_edge = n_edge
-        self.device = device
-        self.n_branch = n_branch
-
-        # Combine bending stiffness from parent, child1, and child2
-        self.bend_stiffness_parent = bend_stiffness_parent
-        self.bend_stiffness_child1 = bend_stiffness_child1
-        self.bend_stiffness_child2 = bend_stiffness_child2
-        self.bend_stiffness = torch.cat(
-            (self.bend_stiffness_parent,
-             self.bend_stiffness_child1,
-             self.bend_stiffness_child2),
-            dim=1
-        )
-        self.twist_stiffness = twist_stiffness
-
-        # Error/stiffness thresholds for numerical stability
-        self.err = torch.tensor(1e-6).to(device)
-        self.stiff_threshold = torch.tensor(1e-10).to(device)
-
-        # For batch-wise operations, repeat/reshape stiffness arrays
-        # bend_stiffness_last_unsq and bend_stiffness_next_unsq correspond to
-        # edges [:-1] and edges [1:] respectively, repeated over the batch.
-        self.bend_stiffness_last_unsq = (
-            self.bend_stiffness[:, :, :-1]
-            .repeat(batch, 1, 1)
-            .view(-1, n_edge - 1, 1)
-        )
-        self.bend_stiffness_next_unsq = (
-            self.bend_stiffness[:, :, 1:]
-            .repeat(batch, 1, 1)
-            .view(-1, n_edge - 1, 1)
-        )
-        self.twist_stiffness_unsq = (
-            self.twist_stiffness[:, :, 1:]
-            .repeat(batch, 1, 1)
-            .view(-1, self.n_edge - 1)
-        )
-
-        # Repeat edge_mask for batch dimension
-        # shape: (batch*n_branch, n_edge, 1)
-        self.edge_mask = edge_mask.repeat(self.batch, 1, 1).view(-1, self.n_edge, 1)
-
-    def compute_u0(self, e0, init_direct):
-        """
-        Compute the initial (first edge) Bishop-frame direction 'u0',
-        ensuring it is perpendicular to the first edge e0.
-
-        Args:
-            e0 (torch.Tensor): The first edge vector, shape (batch, 3).
-            init_direct (torch.Tensor): A random 3D vector not parallel to e0.
-
-        Returns:
-            u0 (torch.Tensor): The 'u' axis of the Bishop frame for the first edge,
-                               normalized and perpendicular to e0.
-        """
-        batch = e0.size(0)
-
-        # Compute a normal vector N_0 that is perpendicular to e0
-        # and init_direct by cross product
-        N_0 = torch.cross(e0, init_direct.view(batch, -1), dim=1)
-
-        # Compute u0 by crossing N_0 with e0 and normalizing
-        u0 = F.normalize(torch.cross(N_0, e0, dim=1), dim=1)
-        return u0
-
-    def computeBishopFrame(self, u0, edges, restEdgeL):
-        """
-        Compute the Bishop frames (u, v) and curvature binormal kb
-        for all edges based on the initial frame u0.
-
-        Bishop Frame is a twist-minimizing reference frame for rods,
-        described in the Discrete Elastic Rods (DER) literature.
-
-        Args:
-            u0 (torch.Tensor): Initial Bishop frame 'u' for the first edge, shape (batch, 3).
-            edges (torch.Tensor): Edge vectors of the rod, shape (batch, n_edge, 3).
-            restEdgeL (torch.Tensor): Undeformed edge lengths, shape (batch, n_edge).
-
-        Returns:
-            b_u (torch.Tensor): The Bishop frame 'u' for each edge, shape (batch, n_edge, 3).
-            b_v (torch.Tensor): The Bishop frame 'v' for each edge, shape (batch, n_edge, 3).
-            kb (torch.Tensor): The discrete curvature binormal, shape (batch, n_edge, 3).
-        """
-        batch = edges.size(0)
-
-        # Compute curvature binormal kb from edges and rest lengths
-        # DER eqn (1)
-        kb = computeKB(edges, restEdgeL)
-
-        # Initialize b_u with the first edge's Bishop frame 'u0'
-        b_u = u0.unsqueeze(dim=1)
-
-        # Magnitude of kb for each edge
-        magnitude = (kb * kb).sum(dim=2)
-
-        # Extract sinPhi and cosPhi from curvature magnitudes
-        sinPhi, cosPhi = extractSinandCos(magnitude)
-
-        # Convert (cosPhi, sinPhi*kb) to quaternions for rotation
-        q = quaternion_q(cosPhi, sinPhi.unsqueeze(dim=2) * F.normalize(kb, dim=2))
-
-        # Recursively compute b_u for each edge using the Bishop update:
-        # b_u(i+1) = rotate(b_u(i)) by the quaternion that aligns edges i -> i+1.
-        for i in range(1, self.n_edge):
-            # If rotation is very small (cosPhi ~ 1), skip the rotation
-            # otherwise apply quaternion rotation to get new b_u
-            b_u = torch.cat(
-                (
-                    b_u,
-                    torch.where(
-                        (1 - cosPhi[:, i].unsqueeze(dim=1)) <= self.err,
-                        b_u[:, i - 1],
-                        quaternion_rotation(b_u, edges, q, i)[0][:, 0, :],
-                    ).unsqueeze(dim=1),
-                ),
-                dim=1,
-            )
-
-        # b_v is orthogonal to the edge and b_u
-        b_v = F.normalize(torch.cross(edges, b_u), dim=2)
-
-        # Mask out invalid edges (if any) using edge_mask
-        b_u = b_u * self.edge_mask
-        b_v = b_v * self.edge_mask
-
-        return b_u, b_v, kb
-
-    def computeMaterialCurvature(self, kb, m1, m2):
-        """
-        Compute the material curvature (kappa1, kappa2) in the material frame
-        given the discrete curvature binormal kb and the material frames m1, m2.
-
-        From DER eqn (2): kappa = (kappa . m1, kappa . m2).
-
-        Args:
-            kb (torch.Tensor): Discrete curvature binormal, shape (batch, n_edge, 3).
-            m1 (torch.Tensor): Material frame axis 1, shape (batch, n_edge, 3).
-            m2 (torch.Tensor): Material frame axis 2, shape (batch, n_edge, 3).
-
-        Returns:
-            m_W1 (torch.Tensor): Material curvature wrt m1, shape (batch, n_edge, 2).
-            m_W2 (torch.Tensor): Material curvature wrt m2, shape (batch, n_edge, 2).
-        """
-        batch, n_edge = kb.size(0), kb.size(1)
-
-        # Initialize outputs
-        m_W1 = torch.zeros(batch, n_edge, 2).to(self.device)
-        m_W2 = torch.zeros(batch, n_edge, 2).to(self.device)
-
-        # computeW returns (kappa . m1, kappa . m2) from discrete curvature binormal
-        # Indices [1:] because the curvature for the first edge is zero or not used
-        m_W1[:, 1:] = computeW(kb[:, 1:], m1[:, :-1], m2[:, :-1])
-        m_W2[:, 1:] = computeW(kb[:, 1:], m1[:, 1:], m2[:, 1:])
-        return m_W1, m_W2
-
-    def parallelTransportFrame(self, previous_e0, current_e0, b_u0):
-        """
-        Update the first edge's Bishop frame vector after a change in the first edge,
-        ensuring orthonormality. (Section 4.2.2 "Bishop Frame Update" in DER paper.)
-
-        Args:
-            previous_e0 (torch.Tensor): The previous (old) first-edge vector, shape (batch, 3).
-            current_e0 (torch.Tensor): The new (updated) first-edge vector, shape (batch, 3).
-            b_u0 (torch.Tensor): The previous Bishop frame 'u' for the first edge, shape (batch, 3).
-
-        Returns:
-            b_u0 (torch.Tensor): The updated, orthonormal Bishop frame 'u' for the current first edge.
-        """
-        batch = previous_e0.size(0)
-
-        # Axis for rotation is cross(previous_e0, current_e0) normalized
-        # The factor in the denominator is from the Rodrigues' rotation formula
-        axis = 2.0 * torch.cross(previous_e0, current_e0, dim=1) / (
-            previous_e0.norm(dim=1) * current_e0.norm(dim=1)
-            + (previous_e0 * current_e0).sum(dim=1)
-        ).unsqueeze(dim=1)
-
-        # Magnitude of the rotation axis
-        magnitude = (axis * axis).sum(dim=1)
-        sinPhi, cosPhi = extractSinandCos(magnitude)
-
-        # If the rotation is negligible, skip it; otherwise rotate b_u0
-        b_u0 = torch.where(
-            (1 - cosPhi.unsqueeze(dim=1)) <= self.err,
-            F.normalize(
-                torch.cross(torch.cross(current_e0, b_u0, dim=1), current_e0, dim=1),
-                dim=1,
-            ),
-            quaternion_rotation_parallel(cosPhi, sinPhi, axis, b_u0),
-        )
-        return b_u0
-
-    def computeMaterialFrame(self, m_theta, b_u, b_v):
-        """
-        Construct the material frame axes (m1, m2) by rotating the Bishop frame
-        about the edge tangent by angle m_theta.
-
-        From DER paper, Section 4.1, the rotation of the Bishop frame (b_u, b_v)
-        by angle theta forms the material frame.
-
-        Args:
-            m_theta (torch.Tensor): The twist angle about the edge tangent, shape (batch, n_edge).
-            b_u (torch.Tensor): The Bishop 'u' axis, shape (batch, n_edge, 3).
-            b_v (torch.Tensor): The Bishop 'v' axis, shape (batch, n_edge, 3).
-
-        Returns:
-            m1 (torch.Tensor): Material frame axis #1, shape (batch, n_edge, 3).
-            m2 (torch.Tensor): Material frame axis #2, shape (batch, n_edge, 3).
-        """
-        # Reshape for broadcast
-        cosQ = torch.cos(m_theta.clone()).unsqueeze(dim=2)
-        sinQ = torch.sin(m_theta.clone()).unsqueeze(dim=2)
-
-        # Standard 2D rotation about the tangent:
-        # [m1, m2] = [ cosQ * b_u + sinQ * b_v, -sinQ * b_u + cosQ * b_v ]
-        m1 = cosQ * b_u + sinQ * b_v
-        m2 = -sinQ * b_u + cosQ * b_v
-        return m1, m2
-
-    def updateCurrentState(
-        self,
-        current_vert,
-        b_u0,
-        restEdgeL,
-        m_restW1,
-        m_restW2,
-        restRegionL,
-        zero_mask,
-        parent_end_theta,
-        children_end_theta,
-        theta_full,
-        selected_parent_index,
-        selected_children_index,
-        optimization_mask,
-        parent_theta_clamp,
-        inference_1_batch
-    ):
-        """
-        Update the rod's current state (material frames, twist angles, etc.)
-        by computing the energy-minimizing twist angle distribution.
-        Uses a solver that sets dE/dtheta = 0.
-
-        Args:
-            current_vert (torch.Tensor): Current vertex positions, shape (batch, n_vert, 3).
-            b_u0 (torch.Tensor): The Bishop frame 'u' for the first edge, shape (batch, 3).
-            restEdgeL (torch.Tensor): Rest edge lengths, shape (batch, n_edge).
-            m_restW1 (torch.Tensor): Rest material curvature (kappa . m1), shape (batch, n_edge, 2).
-            m_restW2 (torch.Tensor): Rest material curvature (kappa . m2), shape (batch, n_edge, 2).
-            restRegionL (torch.Tensor): Voronoi region lengths, shape (batch, n_edge).
-            zero_mask (torch.Tensor): Mask for valid vertices.
-            parent_end_theta (torch.Tensor): Specified twist angle for the parent rod's end.
-            children_end_theta (torch.Tensor): Specified twist angle for children rods' end.
-            theta_full (torch.Tensor): Initial guess or previously computed distribution of twist angles.
-            selected_parent_index (list): Indices corresponding to parent rods for end conditions.
-            selected_children_index (list): Indices corresponding to child rods for end conditions.
-            optimization_mask (torch.Tensor): Mask that indicates which edges to consider in optimization.
-            parent_theta_clamp (torch.Tensor): Additional clamp information for parent angles.
-            inference_1_batch (bool): If True, uses numpy-based solver for single-batch inference.
-
-        Returns:
-            theta_full (torch.Tensor): Updated twist angle distribution (solution of energy minimization).
-            m1 (torch.Tensor): Material frame axis #1, shape (batch, n_edge, 3).
-            m2 (torch.Tensor): Material frame axis #2, shape (batch, n_edge, 3).
-            kb (torch.Tensor): Curvature binormal after the update, shape (batch, n_edge, 3).
-        """
-        # 1. Compute current edges from current vertex positions
-        current_edges = computeEdges(current_vert, zero_mask)
-
-        # 2. Compute the current Bishop frame based on first-edge bishop 'u0'
-        b_u, b_v, kb = self.computeBishopFrame(b_u0, current_edges, restEdgeL)
-
-        # Prepare boundary conditions for end twist angles
-        # (parent, children, clamp, etc.)
-        children_end_theta = torch.cat(
-            (
-                children_end_theta.unsqueeze(dim=1),
-                torch.zeros_like(
-                    children_end_theta.unsqueeze(dim=1).repeat(1, len(parent_theta_clamp) - 1)
-                ),
-            ),
-            dim=1,
-        )
-        end_theta = torch.empty(
-            len(selected_parent_index) + len(selected_children_index),
-            len(parent_theta_clamp)
-        )
-
-        # Fill in parent and child end angles
-        end_theta[selected_parent_index] = parent_end_theta
-        end_theta[selected_children_index] = children_end_theta
-
-        # 3. Create Theseus Variables for optimization
-        cost_weight_variable = th.ScaleCostWeight(1.0)
-        kb_variable = th.Variable(kb, name="kb")
-        b_u_variable = th.Variable(b_u, name="b_u")
-        b_v_variable = th.Variable(b_v, name="b_v")
-        m_restW1_variable = th.Variable(m_restW1, name="m_restW1")
-        m_restW2_variable = th.Variable(m_restW2, name="m_restW2")
-        restRegionL_variable = th.Variable(restRegionL, name="restRegionL")
-        target_energy_variable = th.Variable(
-            torch.zeros((kb.size()[0], 1)), name="target_energy"
-        )
-        inner_theta_variable = th.Vector(b_u.size()[1], name="inner_theta_variable")
-        end_theta = th.Variable(end_theta, name="end_theta")
-        stiff_threshold_variable = th.Variable(self.stiff_threshold, name="stiff_threshold")
-        bend_stiffness_last_unsq_variable = th.Variable(
-            self.bend_stiffness_last_unsq, name="bend_stiffness_last_unsq"
-        )
-        bend_stiffness_next_unsq_variable = th.Variable(
-            self.bend_stiffness_next_unsq, name="bend_stiffness_next_unsq"
-        )
-        bend_stiffness_variable = th.Variable(self.bend_stiffness, name="bend_stiffness")
-        twist_stiffness_variable = th.Variable(
-            self.twist_stiffness, name="twist_stiffness"
-        )
-
-        # 4. Call the solver to optimize theta_full
-        # Switch between a numpy-based solver or a pure PyTorch-based solver
-        # depending on inference_1_batch
-        if inference_1_batch:
-            theta_full = theta_optimize_numpy(
-                self.n_branch,
-                cost_weight_variable,
-                target_energy_variable,
-                kb_variable,
-                b_u_variable,
-                b_v_variable,
-                m_restW1_variable,
-                m_restW2_variable,
-                restRegionL_variable,
-                inner_theta_variable,
-                theta_full,
-                end_theta,
-                stiff_threshold_variable,
-                bend_stiffness_last_unsq_variable,
-                bend_stiffness_next_unsq_variable,
-                bend_stiffness_variable,
-                twist_stiffness_variable,
-                optimization_mask,
-            )
-        else:
-            theta_full = theta_optimize(
-                self.n_branch,
-                cost_weight_variable,
-                target_energy_variable,
-                kb_variable,
-                b_u_variable,
-                b_v_variable,
-                m_restW1_variable,
-                m_restW2_variable,
-                restRegionL_variable,
-                inner_theta_variable,
-                theta_full,
-                end_theta,
-                stiff_threshold_variable,
-                bend_stiffness_last_unsq_variable,
-                bend_stiffness_next_unsq_variable,
-                bend_stiffness_variable,
-                twist_stiffness_variable,
-                optimization_mask,
-            )
-
-        # 5. Compute final material frames based on optimized twist angles
-        m1, m2 = self.computeMaterialFrame(theta_full, b_u, b_v)
-
-        return theta_full, m1, m2, kb
-
-    def computeGradientKB(self, kb, edges, restEdgeL):
-        """
-        Compute the gradient of the discrete curvature binormal (kb) w.r.t.
-        vertex positions. Used for computing internal forces and Jacobians.
-
-        From DER, eq. (7) and eq. (8).
-
-        Args:
-            kb (torch.Tensor): Curvature binormal, shape (batch, n_edge, 3).
-            edges (torch.Tensor): Edge vectors, shape (batch, n_edge, 3).
-            restEdgeL (torch.Tensor): Undeformed edge lengths, shape (batch, n_edge).
-
-        Returns:
-            o_minusGKB (torch.Tensor): Gradient of kb for the edge i-1 side.
-            o_plusGKB (torch.Tensor): Gradient of kb for the edge i+1 side.
-            o_eqGKB (torch.Tensor): Gradient of kb for edge i itself.
-        """
-        batch, n_edge = edges.size(0), edges.size(1)
-
-        # Prepare containers for partial gradients
-        o_minusGKB = torch.zeros(batch, n_edge, 3, 3).to(self.device)
-        o_plusGKB = torch.zeros(batch, n_edge, 3, 3).to(self.device)
-
-        # Precompute skew-symmetric matrices of edges
-        edgeMatrix = skew_symmetric(edges)
-
-        # scalar_factor includes normalized edge lengths in the denominator
-        scalar_factor = scalar_func(edges, restEdgeL).view(batch, n_edge - 1, 1, 1)
-
-        # Compute partial derivatives for i >= 1
-        o_minusGKB[:, 1:] = (
-            2.0 * edgeMatrix[:, :-1]
-            + torch.einsum("bki,bkj->bkij", kb[:, 1:], edges[:, :-1])
-        )
-        o_plusGKB[:, 1:] = (
-            2.0 * edgeMatrix[:, 1:]
-            - torch.einsum("bki,bkj->bkij", kb[:, 1:], edges[:, 1:])
-        )
-
-        # Divide by scalar_factor except where zero
-        epsilon = 1e-20
-        o_minusGKB[:, 1:] = torch.where(
-            scalar_factor != 0,
-            o_minusGKB[:, 1:].clone() / (scalar_factor + epsilon),
-            torch.zeros_like(o_minusGKB[:, 1:]),
-        )
-        o_plusGKB[:, 1:] = torch.where(
-            scalar_factor != 0,
-            o_plusGKB[:, 1:].clone() / (scalar_factor + epsilon),
-            torch.zeros_like(o_plusGKB[:, 1:]),
-        )
-
-        # o_eqGKB = -(o_minusGKB + o_plusGKB)
-        # Because the sum of the partials must be zero across all edges
-        o_eqGKB = -(o_minusGKB + o_plusGKB)
-        return o_minusGKB, o_plusGKB, o_eqGKB
-
-    def computeGradientHolonomyTerms(self, kb, restEdgeL):
-        """
-        Compute the gradient of the "holonomy term" used in the discrete geometry
-        of the rod (related to twist consistency). See DER eq. (9).
-
-        Args:
-            kb (torch.Tensor): Curvature binormal, shape (batch, n_edge, 3).
-            restEdgeL (torch.Tensor): Rest lengths, shape (batch, n_edge).
-
-        Returns:
-            o_minusGH (torch.Tensor): Partial derivative for i-1 side
-            o_plusGH (torch.Tensor): Partial derivative for i+1 side
-            o_eqGH (torch.Tensor): Partial derivative for edge i
-        """
-        batch, n_edge = kb.size(0), kb.size(1)
-
-        o_minusGH = torch.zeros(batch, n_edge, 3).to(self.device)
-        o_plusGH = torch.zeros(batch, n_edge, 3).to(self.device)
-
-        # +0.5 * kb_i / restEdgeL_i for i >= 1
-        o_minusGH[:, 1:] = 0.5 * kb[:, 1:]
-        o_plusGH[:, 1:] = -0.5 * kb[:, 1:]
-
-        epsilon = 1e-20
-        # Divide by restEdgeL while avoiding division by zero
-        o_minusGH[:, 1:] = torch.where(
-            restEdgeL[:, :-1].unsqueeze(dim=2) != 0,
-            o_minusGH[:, 1:] / (restEdgeL[:, :-1].unsqueeze(dim=2) + epsilon),
-            torch.zeros_like(o_minusGH[:, 1:]),
-        )
-        o_plusGH[:, 1:] = torch.where(
-            restEdgeL[:, 1:].unsqueeze(dim=2) != 0,
-            o_plusGH[:, 1:] / (restEdgeL[:, 1:].unsqueeze(dim=2) + epsilon),
-            torch.zeros_like(o_plusGH[:, 1:]),
-        )
-
-        o_eqGH = -(o_minusGH + o_plusGH)
-        return o_minusGH, o_plusGH, o_eqGH
-
-    def computeGradientHolonomy(self, i, j, minusGH, plusGH, eqGH):
-        """
-        Helper function for distributing the gradient of holonomy terms
-        (i.e. partial derivatives wrt vertex positions for the discrete rod).
-        See DER eqn. (11) for the distribution logic.
-
-        Args:
-            i (int): The current edge index being processed for holonomy gradient.
-            j (int): Some index in the chain of edges.
-            minusGH (torch.Tensor): Holonomy partial derivative for i-1 side.
-            plusGH (torch.Tensor): Holonomy partial derivative for i+1 side.
-            eqGH (torch.Tensor): Holonomy partial derivative for edge i.
-
-        Returns:
-            o_Gh (torch.Tensor): Aggregated partial derivative of the holonomy.
-        """
-        batch = minusGH.size(0)
-        o_Gh = torch.zeros(batch, 3).to(self.device)
-
-        # For edges i-1, i, i+1
-        if j >= (i - 1) and i > 1 and (i - 1) < plusGH.size(1):
-            o_Gh += plusGH[:, i - 1]
-        if j >= i and i < eqGH.size(1):
-            o_Gh += eqGH[:, i]
-        if j >= (i + 1) and (i + 1) < minusGH.size(1):
-            o_Gh += minusGH[:, i + 1]
-
-        return o_Gh
-
-    def computeGradientCurvature(
-        self, i, k, j, m_m1, m_m2, minusGKB, plusGKB, eqGKB, minusGH, plusGH, eqGH, wkj, J
-    ):
-        """
-        Compute gradient of material frame curvature and holonomy
-        for the DER's shape operator, see eq. (11).
-
-        Args:
-            i, k, j (int): Indices in eq. (11) describing edges and adjacency.
-            m_m1, m_m2 (torch.Tensor): Material frames (m1, m2).
-            minusGKB, plusGKB, eqGKB (torch.Tensor): Gradients of curvature binormal.
-            minusGH, plusGH, eqGH (torch.Tensor): Gradients of holonomy terms.
-            wkj (torch.Tensor): Current curvature in the material frame, shape (batch, 2).
-            J (torch.Tensor): Some Jacobian for distribution, shape (batch, 2, 2).
-
-        Returns:
-            o_GW (torch.Tensor): Gradient of the material curvature terms.
-            GH (torch.Tensor): Gradient of the holonomy.
-        """
-        batch = minusGH.size(0)
-
-        # Initialize the gradient of W in material frame
-        o_GW = torch.zeros(batch, 2, 3).to(self.device)
-
-        # If k < i+2, compute partial derivative for curvature:
-        # (m1, m2) cross terms with GKB, etc.
-        if k < i + 2:
-            # Each row in o_GW gets the direction from material frames
-            o_GW[:, 0, 0] = m_m2[:, j, 0]
-            o_GW[:, 0, 1] = m_m2[:, j, 1]
-            o_GW[:, 0, 2] = m_m2[:, j, 2]
-
-            o_GW[:, 1, 0] = -m_m1[:, j, 0]
-            o_GW[:, 1, 1] = -m_m1[:, j, 1]
-            o_GW[:, 1, 2] = -m_m1[:, j, 2]
-
-            # Multiply by GKB part depending on k
-            if k == (i - 1):
-                o_GW = torch.bmm(o_GW, plusGKB[:, k])
-            elif k == i:
-                o_GW = torch.bmm(o_GW, eqGKB[:, k])
-            elif k == i + 1:
-                o_GW = torch.bmm(o_GW, minusGKB[:, k])
-
-        # Compute gradient of holonomy
-        GH = self.computeGradientHolonomy(i, j, minusGH, plusGH, eqGH)
-
-        # Subtract the twist-part from the gradient:
-        # ( GH cross wkj ) scaled by J
-        o_GW -= torch.bmm(
-            J,
-            torch.einsum("bi,bj->bij", wkj.view(batch, 2), GH)
-        )
-        return o_GW, GH
-
-    def computedEdtheta(self, m1, m2, kb, theta, JB, m_restW1, m_restW2, restRegionL):
-        """
-        Compute the gradient of elastic energy wrt the twist angles theta
-        (i.e., dE/dtheta). This is used in optimization steps.
-
-        Args:
-            m1, m2 (torch.Tensor): Material frame axes, shape (batch, n_edge, 3).
-            kb (torch.Tensor): Curvature binormal, shape (batch, n_edge, 3).
-            theta (torch.Tensor): Current twist angles, shape (batch, n_edge).
-            JB (torch.Tensor): The 2x2 block of the "bending" stiffness matrix
-                               (clamped or thresholded).
-            m_restW1 (torch.Tensor): Rest curvature about m1, shape (batch, n_edge, 2).
-            m_restW2 (torch.Tensor): Rest curvature about m2, shape (batch, n_edge, 2).
-            restRegionL (torch.Tensor): Voronoi region lengths for each edge
-                                         (used in twist stiffness distribution).
-
-        Returns:
-            dEdtheta (torch.Tensor): Gradient of elastic energy wrt twist angles,
-                                     shape (batch, n_edge).
-        """
-        # Initialize gradient w.r.t. theta to zero
-        dEdtheta = torch.zeros_like(theta)
-
-        if self.n_edge > 1:
-            # Compute current material curvature
-            # (o_W1, o_W2) relative to m1, m2
-            o_W1, o_W2 = self.computeMaterialCurvature(kb, m1, m2)
-
-            # Bending part:
-            # derivative for edges [:-1]
-            temp = (o_W1[:, 1:] - m_restW1[:, 1:]).unsqueeze(-1)
-            JB_j = JB[:, :-1]  # JB for edges [:-1]
-            JB_wij = torch.matmul(JB_j, temp).squeeze(-1)
-            term1 = (o_W1[:, 1:] * JB_wij).sum(dim=-1)
-            dEdtheta[:, :-1] += term1
-
-            # derivative for edges [1:]
-            temp = (o_W2[:, 1:] - m_restW2[:, 1:]).unsqueeze(-1)
-            JB_j = JB[:, 1:]  # JB for edges [1:]
-            JB_wij = torch.matmul(JB_j, temp).squeeze(-1)
-            term2 = (o_W2[:, 1:] * JB_wij).sum(dim=-1)
-            dEdtheta[:, 1:] += term2
-
-            # Twist part:
-            # clamp twist_stiffness to a minimum threshold
-            twist_stiffness_clamped = torch.clamp(
-                self.twist_stiffness_unsq, min=self.stiff_threshold
-            )
-            # difference in theta among adjacent edges
-            term1 = 2.0 * twist_stiffness_clamped * (theta[:, 1:] - theta[:, :-1])
-
-            valid_mask = restRegionL[:, 1:] != 0
-            term1_result = torch.zeros_like(term1)
-            term1_result[valid_mask] = term1[valid_mask] / restRegionL[:, 1:][valid_mask]
-            term1 = term1_result
-
-            # Add to dEdtheta for edges
-            dEdtheta[:, 1:] += term1
-            dEdtheta[:, :-1] -= term1
-
-        return dEdtheta
diff --git a/DEFT_sim.py b/DEFT_sim.py
deleted file mode 100644
index 1dc9bde..0000000
--- a/DEFT_sim.py
+++ /dev/null
@@ -1,1278 +0,0 @@
-import torch
-import torch.nn as nn
-
-# Import DEFT functions
-from DEFT_func import DEFT_func
-
-# Importing multiple utilities:
-# - rotation_matrix: Helper for creating rotation matrices from angles
-# - computeW, computeLengths, computeEdges: Utility functions for BDLO geometry
-# - visualize_tensors_3d_in_same_plot_no_zeros: For debugging/visualizing results
-from util import rotation_matrix, computeW, computeLengths, computeEdges, visualize_tensors_3d_in_same_plot_no_zeros
-
-# Import constraints solver(s)
-from constraints_solver import constraints_enforcement
-import pytorch3d.transforms.rotation_conversions
-
-# A numba-accelerated version of constraints enforcement
-from constraints_enforcement_numba import constraints_enforcement_numba
-constraints_numba = constraints_enforcement_numba()
-
-# Importing a graph neural network for residual learning
-module_dir = "residual_learning_nn"
-import sys
-import os
-import numpy as np
-sys.path.append(module_dir)
-from GNN_tree import BatchedGNNModel
-
-import time
-
-class DEFT_sim(nn.Module):
-    """
-    This class contains the DEFT simulation logic for BDLOs
-    with the possibility of residual learning using a GNN.
-    """
-    def __init__(
-        self,
-        batch,
-        n_branch,
-        n_vert,
-        cs_n_vert,
-        b_init_n_vert,
-        n_edge,
-        b_undeformed_vert,
-        b_DLO_mass,
-        parent_DLO_MOI,
-        children_DLO_MOI,
-        device,
-        clamped_index,
-        rigid_body_coupling_index,
-        parent_MOI_index1,
-        parent_MOI_index2,
-        parent_clamped_selection,
-        child1_clamped_selection,
-        child2_clamped_selection,
-        clamp_parent,
-        clamp_child1,
-        clamp_child2,
-        index_selection1,
-        index_selection2,
-        bend_stiffness_parent,
-        bend_stiffness_child1,
-        bend_stiffness_child2,
-        twist_stiffness,
-        damping,
-        learning_weight
-    ):
-        super().__init__()
-        """
-        Parameters:
-        ----------
-        batch: int
-            Number of BDLO instances or samples in a single training batch.
-        n_branch: int
-            Number of branches for the BDLO (1 parent branch + 2 children branches).
-        n_vert: int
-            Number of vertices in the parent branch.
-        cs_n_vert: tuple
-            Number of vertices for each child branch.
-        b_init_n_vert: tensor
-            The undeformed positions of all vertices for the BDLO, used as initialization.
-        n_edge: int
-            Number of edges per branch (n_vert - 1).
-        b_undeformed_vert: tensor
-            Reference undeformed shape for the BDLO (parent + child).
-        b_DLO_mass: tensor
-            Mass distribution (diagonal form) for each branch's vertices.
-        parent_DLO_MOI: tensor
-            Moment of inertia for the parent branch (diagonal).
-        children_DLO_MOI: tensor
-            Moment of inertia for the child branches (diagonal).
-        device: str
-            Where to run the simulation ('cpu' only for now).
-        clamped_index: tensor
-            Boolean mask indicating which vertices are clamped (for the inextensibility constraint).
-        rigid_body_coupling_index: list
-            Indices specifying which vertices link child branches to the parent branch.
-        parent_MOI_index1 / parent_MOI_index2: lists
-            Indices used for coupling the parent's MOI with child branches.
-        parent_clamped_selection / child1_clamped_selection / child2_clamped_selection: tensor
-            Indices of vertices that are clamped in the parent or children branches.
-        clamp_parent / clamp_child1 / clamp_child2: bool
-            Whether the parent or child branches are physically clamped in the experiment.
-        index_selection1 / index_selection2: lists
-            Index sets used for referencing sub-portions of the BDLO (internal usage).
-        bend_stiffness_parent / bend_stiffness_child1 / bend_stiffness_child2 / twist_stiffness: nn.Parameters
-            Deformational stiffness parameters for bending and twisting in each branch.
-        damping: nn.Parameter
-            Damping coefficients for dynamic updates.
-        learning_weight: nn.Parameter
-            Scaling factor for the residual correction from the GNN.
-
-        The class holds all states needed to run DEFT simulation + potential GNN-based residual corrections.
-        """
-
-        # Store constructor inputs
-        self.clamped_index = clamped_index
-        self.n_vert = n_vert
-        self.n_edge = n_edge
-        self.device = device
-        self.n_branch = n_branch
-        self.batch = batch
-        self.clamp_parent = clamp_parent
-        self.clamp_child1 = clamp_child1
-        self.clamp_child2 = clamp_child2
-
-        # For parallelization across a batch and multiple branches:
-        # We'll figure out child vs parent branches (indices) in a vectorized way
-        selected_children_index = [i for i in range(1, batch * n_branch) if i % n_branch != 0]
-        self.rigid_body_coupling_index = rigid_body_coupling_index
-
-        # "index_selection_1" / "index_selection_2": used for referencing the parent's edges
-        index_selection_1 = torch.tensor(rigid_body_coupling_index) - 1
-        index_selection_2 = torch.tensor(rigid_body_coupling_index)
-        # fused_rigid_body_coupling_index merges them in some pattern for convenience
-        self.fused_rigid_body_coupling_index = torch.stack((index_selection_1, index_selection_2), dim=1).reshape(-1)
-
-        # For identifying the branches in a batch:
-        # - child1 is 1 mod n_branch
-        # - child2 is 2 mod n_branch
-        # - parent is 0 mod n_branch
-        selected_child1_index = list(range(1, batch * n_branch, n_branch))
-        selected_child2_index = list(range(2, batch * n_branch, n_branch))
-        selected_parent_index = list(range(0, batch * n_branch, n_branch))
-        self.selected_parent_index = torch.tensor(selected_parent_index)
-        self.selected_child1_index = torch.tensor(selected_child1_index)
-        self.selected_child2_index = torch.tensor(selected_child2_index)
-
-        # Expand clamped vertex selection for the parent across the batch
-        batch_indices = self.selected_parent_index.unsqueeze(1).expand(-1, parent_clamped_selection.size(0))
-        parent_indices = parent_clamped_selection.unsqueeze(0).expand(self.selected_parent_index.size(0), -1)
-
-        # Child1/Child2 clamped indices
-        batch_child1_indices = self.selected_child1_index
-        child1_indices = child1_clamped_selection
-        batch_child2_indices = self.selected_child2_index
-        child2_indices = child2_clamped_selection
-
-        # Store index selections for reference
-        self.index_selection1 = index_selection1
-        self.index_selection2 = index_selection2
-
-        # Flatten them for easier indexing
-        self.batch_indices_flat = batch_indices.reshape(-1)
-        self.parent_indices_flat = parent_indices.reshape(-1)
-
-        self.batch_child1_indices_flat = batch_child1_indices.reshape(-1)
-        self.child1_indices_flat = child1_indices.reshape(-1)
-
-        self.batch_child2_indices_flat = batch_child2_indices.reshape(-1)
-        self.child1_indices_flat = child2_indices.reshape(-1)  # reusing variable name but it's for child2
-
-        # Store clamp selections
-        self.parent_clamped_selection = parent_clamped_selection
-        self.child1_clamped_selection = child1_clamped_selection
-        self.child2_clamped_selection = child2_clamped_selection
-
-        # Store inertia (MOI) for parent/child in parameter form
-        self.p_DLO_diagonal = nn.Parameter(parent_DLO_MOI)
-        self.c_DLO_diagonal = nn.Parameter(children_DLO_MOI)
-
-        # Construct MOI matrices for children/parent rods
-        self.children_MOI_matrix = torch.zeros(n_branch-1, 3, 3)
-        self.children_MOI_matrix[:, 0, 0] = self.c_DLO_diagonal[:, 0]
-        self.children_MOI_matrix[:, 1, 1] = self.c_DLO_diagonal[:, 1]
-        self.children_MOI_matrix[:, 2, 2] = self.c_DLO_diagonal[:, 2]
-
-        self.parent_MOI_matrix = torch.zeros((n_branch-1)*2, 3, 3)
-        self.parent_MOI_matrix[:, 0, 0] = self.p_DLO_diagonal[:, 0]
-        self.parent_MOI_matrix[:, 1, 1] = self.p_DLO_diagonal[:, 1]
-        self.parent_MOI_matrix[:, 2, 2] = self.p_DLO_diagonal[:, 2]
-
-        # Integration parameters (how we integrate the dynamic system)
-        self.integration_ratio = nn.Parameter(torch.tensor(1., device=device))
-        self.velocity_ratio = nn.Parameter(torch.tensor(0., device=device))
-
-        # zero_mask: tracks vertices that may not exist (e.g., in shorter child branches)
-        self.zero_mask = torch.all(b_undeformed_vert[:, 1:] == 0, dim=-1)
-
-        # Compute reference lengths of edges and Voronoi region
-        self.m_restEdgeL, self.m_restRegionL = computeLengths(
-            computeEdges(b_undeformed_vert.clone(), self.zero_mask)
-        )
-
-        # Create a mask to handle situations where child branches end sooner
-        m_restRegionL_mask = torch.ones_like(self.m_restRegionL)
-        for i in range(len(cs_n_vert)):
-            m_restRegionL_mask[i+1, cs_n_vert[i]-1:] = 0.
-
-        # Instantiate the DEFT_func object, which does the heavy-lifting for bending, twisting, etc.
-        self.DEFT_func = DEFT_func(
-            batch,
-            n_branch,
-            n_vert,
-            n_edge,
-            m_restRegionL_mask,
-            self.zero_mask,
-            self.m_restEdgeL,
-            bend_stiffness_parent,
-            bend_stiffness_child1,
-            bend_stiffness_child2,
-            twist_stiffness,
-            device=device
-        )
-
-        # Apply the masks so that unused edges are 0
-        self.m_restRegionL = self.m_restRegionL * m_restRegionL_mask
-        self.m_restEdgeL = self.m_restEdgeL * m_restRegionL_mask
-
-        # Repeat across the batch dimension
-        self.batched_m_restEdgeL = self.m_restEdgeL.repeat(self.batch, 1, 1).view(-1, n_edge)
-        self.batched_m_restRegionL = self.m_restRegionL.repeat(self.batch, 1, 1).view(-1, n_edge)
-
-        # Set the BDLO's initial undeformed positions as a trainable parameter
-        self.undeformed_vert = nn.Parameter(b_init_n_vert)
-
-        # Mass diagonal holds mass for each vertex in each branch
-        self.mass_diagonal = nn.Parameter(b_DLO_mass)
-
-        # Construct the mass matrix: shape [batch * n_branch, n_vert, 3, 3]
-        # We replicate the diagonal mass for each vertex, then tile for the batch
-        self.mass_matrix = (
-            torch.eye(3)
-            .unsqueeze(dim=0)
-            .unsqueeze(dim=0)
-            .repeat(n_branch, n_vert, 1, 1)
-            * (self.mass_diagonal.unsqueeze(dim=-1).unsqueeze(dim=-1))
-        ).unsqueeze(dim=0).repeat(batch, 1, 1, 1, 1).view(-1, n_vert, 3, 3)
-
-        # Damping for each branch
-        self.damping = damping
-
-        # zero_mask_num is used for ignoring vertices that don't exist in child branches
-        self.zero_mask_num = 1 - self.zero_mask.repeat(batch, 1).to(torch.uint8)
-
-        # We compute momentum scaling factors for rotation constraints
-        self.parent_MOI_index1 = parent_MOI_index1
-        self.parent_MOI_index2 = parent_MOI_index2
-
-        rod_MOI1, rod_MOI2 = self.parent_MOI_matrix[parent_MOI_index1].repeat(batch, 1, 1), self.children_MOI_matrix.repeat(batch, 1, 1)
-        momentum_scale1 = -rod_MOI2 @ torch.linalg.pinv(rod_MOI1 + rod_MOI2)
-        momentum_scale2 = rod_MOI1 @ torch.linalg.pinv(rod_MOI1 + rod_MOI2)
-        self.momentum_scale_previous = torch.cat((momentum_scale1, momentum_scale2), dim=1).view(-1, 3, 3)
-
-        rod_MOI1, rod_MOI2 = self.parent_MOI_matrix[parent_MOI_index2].repeat(batch, 1, 1), self.children_MOI_matrix.repeat(batch, 1, 1)
-        momentum_scale1 = -rod_MOI2 @ torch.linalg.pinv(rod_MOI1 + rod_MOI2)
-        momentum_scale2 = rod_MOI1 @ torch.linalg.pinv(rod_MOI1 + rod_MOI2)
-        self.momentum_scale_next = torch.cat((momentum_scale1, momentum_scale2), dim=1).view(-1, 3, 3)
-
-        # inext_scale is used for inextensibility enforcement: a high penalty for edges that must remain fixed length
-        inext_scale = clamped_index * 1e20
-        self.inext_scale = (inext_scale + 1.).repeat(batch, 1)
-        self.inext_scale = torch.cat((self.inext_scale[:, :-1], self.inext_scale[:, 1:]), dim=1).view(-1, n_edge)
-
-        # mass_scale is used for local mass-based updates in inextensibility enforcement
-        mass_scale1 = self.mass_matrix[:, 1:] @ torch.linalg.pinv(self.mass_matrix[:, 1:] + self.mass_matrix[:, :-1])
-        mass_scale2 = self.mass_matrix[:, :-1] @ torch.linalg.pinv(self.mass_matrix[:, 1:] + self.mass_matrix[:, :-1])
-        self.mass_scale = torch.cat((mass_scale1, -mass_scale2), dim=1).view(-1, self.n_edge, 3, 3)
-
-        # Next, we compute coupling mass scale for the branching points
-        parent_mass = self.mass_matrix[selected_parent_index][:, rigid_body_coupling_index].view(-1, 3, 3)
-        children_mass = self.mass_matrix[selected_children_index, 0]
-        self.selected_children_index = selected_children_index
-        mass_scale1 = children_mass @ torch.linalg.inv(parent_mass + children_mass)
-        mass_scale2 = parent_mass @ torch.linalg.inv(parent_mass + children_mass)
-        self.coupling_mass_scale = torch.cat((mass_scale1.unsqueeze(dim=1), -mass_scale2.unsqueeze(dim=1)), dim=1)
-
-        # Axis angle representation for rod orientation (parent + children). Typically 3 angles per rod.
-        self.rod_axis_angle = nn.Parameter(torch.zeros(3*n_branch, 3).to(device))
-        self.rod_orientation = pytorch3d.transforms.rotation_conversions.axis_angle_to_quaternion(
-            self.rod_axis_angle.clone()
-        ).unsqueeze(dim=0).repeat(batch, 1, 1)
-
-        # Gravity is another parameter we can tune if desired
-        self.gravity = nn.Parameter(torch.tensor((0, 0, -4.81), device=device))
-
-        # Base timestep
-        self.dt = 1e-2
-
-        # Constraint enforcement object
-        self.constraints_enforcement = constraints_enforcement(n_branch)
-
-        # Precompute masks for vectorizing internal force calculations
-        self.w_masks = torch.zeros(1, n_vert, n_edge, 1).to(device)
-        self.m_masks = torch.zeros(1, n_vert, n_edge, 1, 1).to(device)
-        self.plusGKB_masks = torch.zeros(1, n_vert, n_edge, 1, 1).to(device)
-        self.eqGKB_masks = torch.zeros(1, n_vert, n_edge, 1, 1).to(device)
-        self.minusGKB_masks = torch.zeros(1, n_vert, n_edge, 1, 1).to(device)
-        self.plusGH_masks_1 = torch.zeros(1, n_vert, n_edge, 1).to(device)
-        self.eqGH_masks_1 = torch.zeros(1, n_vert, n_edge, 1).to(device)
-        self.minusGH_masks_1 = torch.zeros(1, n_vert, n_edge, 1).to(device)
-        self.plusGH_masks_2 = torch.zeros(1, n_vert, n_edge, 1).to(device)
-        self.eqGH_masks_2 = torch.zeros(1, n_vert, n_edge, 1).to(device)
-        self.minusGH_masks_2 = torch.zeros(1, n_vert, n_edge, 1).to(device)
-        self.plusGH_masks_n = torch.zeros(1, n_vert, n_edge, 1).to(device)
-        self.eqGH_masks_n = torch.zeros(1, n_vert, n_edge, 1).to(device)
-        self.minusGH_masks_n = torch.zeros(1, n_vert, n_edge, 1).to(device)
-
-        # We fill up these masks in a loop based on adjacency in the chain
-        n = n_edge - 1
-        for i in range(n_vert):
-            for k in range(max(i - 1, 1), n_edge):
-                self.w_masks[:, i, k, :] = 1
-                if k < i + 2:
-                    self.m_masks[:, i, k] = 1
-                    if k == i - 1:
-                        self.plusGKB_masks[:, i, k] = 1
-                    elif k == i:
-                        self.eqGKB_masks[:, i, k] = 1
-                    elif k == i + 1:
-                        self.minusGKB_masks[:, i, k] = 1
-
-                if k - 1 >= (i - 1) and i > 1 and (i - 1) < n_edge:
-                    self.plusGH_masks_1[:, i, k] = 1
-                if k - 1 >= i and i < n_edge:
-                    self.eqGH_masks_1[:, i, k] = 1
-                if k - 1 >= (i + 1) and (i + 1) < n_edge:
-                    self.minusGH_masks_1[:, i, k] = 1
-                if k >= (i - 1) and i > 1 and (i - 1) < n_edge:
-                    self.plusGH_masks_2[:, i, k] = 1
-                if k >= i and i < n_edge:
-                    self.eqGH_masks_2[:, i, k] = 1
-                if k >= (i + 1) and (i + 1) < n_edge:
-                    self.minusGH_masks_2[:, i, k] = 1
-
-            if n >= (i - 1) and i > 1 and (i - 1) < n_edge:
-                self.plusGH_masks_n[:, i, n] = 1
-            if n >= i and i < n_edge:
-                self.eqGH_masks_n[:, i, n] = 1
-            if n >= (i + 1) and (i + 1) < n_edge:
-                self.minusGH_masks_n[:, i, n] = 1
-
-        # JB_n: a helper for bending stiffness (J is the 2D rotation matrix of 90 degrees)
-        J = (
-            torch.tensor([[0., -1.], [1., 0.]])
-            .unsqueeze(0)
-            .unsqueeze(0)
-        ).repeat(self.batch * self.n_branch, self.n_edge, 1, 1)
-        bend_stiffness_clamped = torch.clamp(
-            self.DEFT_func.bend_stiffness,
-            min=self.DEFT_func.stiff_threshold
-        ).repeat(self.batch, 1, 1).view(self.batch * self.n_branch, self.n_edge)
-
-        self.JB_n = (J * bend_stiffness_clamped[:, :, None, None])
-
-        # Setup for residual learning
-        # We store previous and next edge stiffness for parent/child edges
-        self.nn_previous_bend_stiffness = torch.cat(
-            (
-                torch.zeros(self.batch, n_branch, 1),
-                torch.clamp(self.DEFT_func.bend_stiffness, min=self.DEFT_func.stiff_threshold).repeat(self.batch, 1, 1)
-            ),
-            dim=-1
-        ).view(self.batch, -1, 1)
-        self.nn_next_bend_stiffness = torch.cat(
-            (
-                torch.clamp(self.DEFT_func.bend_stiffness, min=self.DEFT_func.stiff_threshold).repeat(self.batch, 1, 1),
-                torch.zeros(self.batch, n_branch, 1)
-            ),
-            dim=-1
-        ).view(self.batch, -1, 1)
-
-        self.nn_previous_twist_stiffness = torch.cat(
-            (
-                torch.zeros(self.batch, n_branch, 1),
-                torch.clamp(self.DEFT_func.twist_stiffness.clone(), min=self.DEFT_func.stiff_threshold).repeat(self.batch, 1, 1)
-            ),
-            dim=-1
-        ).view(self.batch, -1, 1)
-        self.nn_next_twist_stiffness = torch.cat(
-            (
-                torch.clamp(self.DEFT_func.twist_stiffness.clone(), min=self.DEFT_func.stiff_threshold).repeat(self.batch, 1, 1),
-                torch.zeros(self.batch, n_branch, 1)
-            ),
-            dim=-1
-        ).view(self.batch, -1, 1)
-
-        # Instantiate the GNN for residual corrections
-        in_features = 16
-        hidden_features = 64
-        out_features = 3
-
-        self.learning_weight = learning_weight
-        self.GNN_tree = BatchedGNNModel(
-            batch,
-            in_features,
-            hidden_features,
-            out_features,
-            n_vert,
-            cs_n_vert,
-            rigid_body_coupling_index,
-            clamp_parent,
-            clamp_child1,
-            clamp_child2,
-            parent_clamped_selection,
-            child1_clamped_selection,
-            child2_clamped_selection,
-            selected_child1_index,
-            selected_child2_index,
-            selected_parent_index,
-            selected_children_index
-        )
-
-
-    def Rod_Init(self, batch, init_direction, m_restEdgeL, clamped_index, inference_1_batch):
-        """
-        Initialize rod geometry by enforcing inextensibility constraints once,
-        then computing bishop frames and curvature for each edge.
-
-        Returns:
-        --------
-        m_restWprev, m_restWnext: Tensors
-            Material curvatures in the bishop frame for each edge.
-        """
-        # If we are in single-batch inference mode, we use a numba-based approach
-        if inference_1_batch:
-            undeformed_vert = constraints_numba.Inextensibility_Constraint_Enforcement(
-                batch,
-                (self.undeformed_vert.clone()).repeat(batch, 1, 1).detach().cpu().numpy(),
-                m_restEdgeL.detach().cpu().numpy(),
-                self.inext_scale.detach().cpu().numpy(),
-                self.mass_scale.detach().cpu().numpy(),
-                self.zero_mask_num
-            )
-            undeformed_vert = torch.from_numpy(undeformed_vert)
-        else:
-            undeformed_vert = self.constraints_enforcement.Inextensibility_Constraint_Enforcement(
-                batch,
-                (self.undeformed_vert.clone()).repeat(batch, 1, 1),
-                m_restEdgeL,
-                self.mass_matrix,
-                clamped_index,
-                self.inext_scale,
-                self.mass_scale,
-                self.zero_mask_num
-            )
-
-        # Compute edges for the (adjusted) undeformed shape
-        m_edges = computeEdges(undeformed_vert, self.zero_mask.repeat(batch, 1))
-
-        # Use bishop frames for the rod
-        m_u0 = self.DEFT_func.compute_u0(m_edges[:, 0], init_direction.view(-1, 2, 3)[:, 0])
-        m_m1, m_m2, m_kb = self.DEFT_func.computeBishopFrame(m_u0, m_edges, m_restEdgeL)
-        m_restWprev, m_restWnext = self.DEFT_func.computeMaterialCurvature(m_kb, m_m1, m_m2)
-
-        return m_restWprev, m_restWnext
-
-    def Internal_Force_Vectorize(
-        self,
-        m_edges,
-        clamped_index,
-        m_restEdgeL,
-        m_restRegionL,
-        m_kb,
-        m_restWprev,
-        m_restWnext,
-        theta_full,
-        m_m1,
-        m_m2
-    ):
-        """
-        Compute internal forces arising from bending, twisting, and curvature
-        using the vectorized DEFT approach.
-
-        Returns:
-        --------
-        o_forces: tensor [batch * n_branch, n_vert, 3]
-            The resultant internal forces for each vertex.
-        """
-        batch = m_kb.size()[0]
-        m_theta = theta_full
-
-        # Compute gradient of the curvature binormal wrt each vertex
-        minusGKB, plusGKB, eqGKB = self.DEFT_func.computeGradientKB(m_kb, m_edges, m_restEdgeL)
-
-        # Compute gradient of the holonomy terms
-        minusGH, plusGH, eqGH = self.DEFT_func.computeGradientHolonomyTerms(m_kb, m_restEdgeL)
-
-        # J is the 2D rotation matrix for 90 degrees
-        J = rotation_matrix(torch.pi / 2. * torch.ones(batch)).to(self.device)
-
-        # dEdtheta: derivative of energy wrt twist angle
-        dEdtheta = self.DEFT_func.computedEdtheta(
-            m_m1,
-            m_m2,
-            m_kb,
-            m_theta,
-            self.JB_n,
-            m_restWprev,
-            m_restWnext,
-            m_restRegionL
-        )
-
-        # b_w1, b_w2 are the material curvature vectors for edges
-        b_w1 = (
-            self.w_masks
-            * computeW(m_kb, torch.cat((torch.zeros(batch, 1, 3).to(self.device), m_m1[:, :-1]), dim=1),
-                       torch.cat((torch.zeros(batch, 1, 3).to(self.device), m_m2[:, :-1]), dim=1))
-              .unsqueeze(dim=1)
-              .repeat(1, self.n_vert, 1, 1)
-        )
-        b_w2 = (
-            self.w_masks
-            * computeW(m_kb, torch.cat((torch.zeros(batch, 1, 3).to(self.device), m_m1[:, 1:]), dim=1),
-                       torch.cat((torch.zeros(batch, 1, 3).to(self.device), m_m2[:, 1:]), dim=1))
-              .unsqueeze(dim=1)
-              .repeat(1, self.n_vert, 1, 1)
-        )
-
-        # O_GW1, O_GW2 are the gradient of W wrt the curvature binormal for adjacent edges
-        # We do partial expansions using masks to accumulate relevant terms
-
-        # Construct the bishop frames b_m1, b_m2 for edges
-        b_m1 = torch.cat(
-            (
-                torch.zeros(batch, self.n_vert, 1, 2, 3).to(self.device),
-                torch.cat(
-                    (
-                        m_m2.unsqueeze(dim=1).unsqueeze(dim=-2).repeat(1, self.n_vert, 1, 1, 1),
-                        -m_m1.unsqueeze(dim=1).unsqueeze(dim=-2).repeat(1, self.n_vert, 1, 1, 1)
-                    ),
-                    -2
-                )[:, :, :-1]
-            ),
-            dim=2
-        ) * self.m_masks
-
-        # O_GWplus1, O_GWeq1, O_GWminus1 accumulate the partial derivatives
-        O_GWplus1 = torch.bmm(
-            b_m1.view(-1, 2, 3),
-            (plusGKB.unsqueeze(dim=1).repeat(1, self.n_vert, 1, 1, 1)).view(-1, 3, 3)
-        ).view(batch, self.n_vert, self.n_edge, 2, 3) * self.plusGKB_masks
-
-        O_GWeq1 = torch.bmm(
-            b_m1.view(-1, 2, 3),
-            (eqGKB.unsqueeze(dim=1).repeat(1, self.n_vert, 1, 1, 1)).view(-1, 3, 3)
-        ).view(batch, self.n_vert, self.n_edge, 2, 3) * self.eqGKB_masks
-
-        O_GWminus1 = torch.bmm(
-            b_m1.view(-1, 2, 3),
-            (minusGKB.unsqueeze(dim=1).repeat(1, self.n_vert, 1, 1, 1)).view(-1, 3, 3)
-        ).view(batch, self.n_vert, self.n_edge, 2, 3) * self.minusGKB_masks
-
-        O_GW1 = O_GWplus1 + O_GWeq1 + O_GWminus1
-
-        # Similarly for b_m2
-        b_m2 = torch.cat(
-            (
-                m_m2.unsqueeze(dim=1).unsqueeze(dim=-2).repeat(1, self.n_vert, 1, 1, 1),
-                -m_m1.unsqueeze(dim=1).unsqueeze(dim=-2).repeat(1, self.n_vert, 1, 1, 1)
-            ),
-            -2
-        ) * self.m_masks
-
-        O_GWplus2 = torch.bmm(
-            b_m2.view(-1, 2, 3),
-            (plusGKB.unsqueeze(dim=1).repeat(1, self.n_vert, 1, 1, 1)).view(-1, 3, 3)
-        ).view(batch, self.n_vert, self.n_edge, 2, 3) * self.plusGKB_masks
-
-        O_GWeq2 = torch.bmm(
-            b_m2.view(-1, 2, 3),
-            (eqGKB.unsqueeze(dim=1).repeat(1, self.n_vert, 1, 1, 1)).view(-1, 3, 3)
-        ).view(batch, self.n_vert, self.n_edge, 2, 3) * self.eqGKB_masks
-
-        O_GWminus2 = torch.bmm(
-            b_m2.view(-1, 2, 3),
-            (minusGKB.unsqueeze(dim=1).repeat(1, self.n_vert, 1, 1, 1)).view(-1, 3, 3)
-        ).view(batch, self.n_vert, self.n_edge, 2, 3) * self.minusGKB_masks
-
-        O_GW2 = O_GWplus2 + O_GWeq2 + O_GWminus2
-
-        # b_plusGH / b_eqGH / b_minusGH handle the holonomy gradients
-        b_plusGH = torch.cat((torch.zeros(batch, 1, 3).to(self.device), plusGH), dim=1).unsqueeze(-2).repeat(1, 1, self.n_edge, 1)
-        b_eqGH   = torch.cat((eqGH, torch.zeros(batch, 1, 3).to(self.device)), dim=1).unsqueeze(-2).repeat(1, 1, self.n_edge, 1)
-        b_minusGH= torch.cat((minusGH[:, 1:], torch.zeros(batch, 2, 3).to(self.device)), dim=1).unsqueeze(-2).repeat(1, 1, self.n_edge, 1)
-
-        b_GH1 = b_plusGH * self.plusGH_masks_1 + b_eqGH * self.eqGH_masks_1 + b_minusGH * self.minusGH_masks_1
-        b_GH2 = b_plusGH * self.plusGH_masks_2 + b_eqGH * self.eqGH_masks_2 + b_minusGH * self.minusGH_masks_2
-        b_GHn = b_plusGH * self.plusGH_masks_n + b_eqGH * self.eqGH_masks_n + b_minusGH * self.minusGH_masks_n
-
-        # Subtract J * W from O_GW for twisting
-        O_GW1 = O_GW1 - torch.bmm(
-            (J.unsqueeze(dim=1).unsqueeze(dim=1).repeat(1, self.n_vert, self.n_edge, 1, 1)).view(-1, 2, 2),
-            torch.einsum('bijc,bijd->bijcd', b_w1, b_GH1).view(-1, 2, 3)
-        ).view(batch, self.n_vert, self.n_edge, 2, 3)
-
-        O_GW2 = O_GW2 - torch.bmm(
-            (J.unsqueeze(dim=1).unsqueeze(dim=1).repeat(1, self.n_vert, self.n_edge, 1, 1)).view(-1, 2, 2),
-            torch.einsum('bijc,bijd->bijcd', b_w2, b_GH2).view(-1, 2, 3)
-        ).view(batch, self.n_vert, self.n_edge, 2, 3)
-
-        # Combine the two edges to get final forces
-        b_m_restRegionL = (
-            m_restRegionL.unsqueeze(dim=1)
-            .unsqueeze(dim=-1)
-            .repeat(1, self.n_vert, 1, 3)
-            * self.w_masks
-        )
-
-        b_bend_stiffness1 = (
-            torch.cat(
-                (
-                    torch.zeros(1, self.n_branch, 1).to(self.device),
-                    self.DEFT_func.bend_stiffness[:, :, :-1]
-                ),
-                dim=2
-            ).repeat(self.batch, 1, 1)
-        ).view(-1, 1, self.n_edge, 1).repeat(1, self.n_vert, 1, 1)
-
-        b_m_restWprev = m_restWprev.unsqueeze(dim=1).repeat(1, self.n_vert, 1, 1) * self.w_masks
-        term1 = torch.bmm(
-            torch.transpose(O_GW1.view(-1, 2, 3), 2, 1),
-            (
-                torch.clamp(b_bend_stiffness1, self.DEFT_func.stiff_threshold)
-                * (b_w1 - b_m_restWprev)
-            ).view(-1, 2, 1)
-        ).view(batch, self.n_vert, self.n_edge, 3)
-
-        b_bend_stiffness2 = (
-            torch.cat(
-                (
-                    torch.zeros(1, self.n_branch, 1).to(self.device),
-                    self.DEFT_func.bend_stiffness[:, :, 1:]
-                ),
-                dim=2
-            ).repeat(self.batch, 1, 1)
-        ).view(-1, 1, self.n_edge, 1).repeat(1, self.n_vert, 1, 1)
-
-        b_m_restWnext = m_restWnext.unsqueeze(dim=1).repeat(1, self.n_vert, 1, 1) * self.w_masks
-        term2 = torch.bmm(
-            torch.transpose(O_GW2.view(-1, 2, 3), 2, 1),
-            (
-                torch.clamp(b_bend_stiffness2, self.DEFT_func.stiff_threshold)
-                * (b_w2 - b_m_restWnext)
-            ).view(-1, 2, 1)
-        ).view(batch, self.n_vert, self.n_edge, 3)
-
-        o_forces = torch.div(
-            -(term1 + term2),
-            b_m_restRegionL.where(b_m_restRegionL != 0, torch.tensor(1.).to(self.device))
-        )
-        o_forces[b_m_restRegionL == 0] = 0.
-
-        # Add twist contribution from the last edge
-        o_forces = torch.sum(o_forces, -2)
-        o_forces += b_GHn[:, :, -1] * dEdtheta[:, -1].unsqueeze(dim=1).unsqueeze(dim=1)
-
-        # Multiply by (1 - clamped_index) to zero out forces where vertices are fully clamped
-        o_forces = o_forces * (
-            1 - clamped_index.to(self.device)
-        ).repeat(self.batch, 1).unsqueeze(dim=-1)
-
-        return o_forces
-
-    def External_Force(self, mass_matrix):
-        """
-        Compute external force contributions (like gravity, damping, etc.).
-        Here we only account for gravity (and possibly velocity compensation, if used).
-        """
-        # Gravity
-        forces = mass_matrix @ self.gravity.clone()
-        # Mask out non-existent vertices
-        forces[:, 1:] *= (1 - self.zero_mask.to(torch.uint8)).repeat(self.batch, 1).unsqueeze(-1)
-
-        return forces
-
-    def Numerical_Integration(
-        self,
-        mass_matrix,
-        Total_force,
-        b_DLOs_velocity,
-        b_DLOs_vertices,
-        damping,
-        integration_ratio,
-        dt
-    ):
-        """
-        Update positions and velocities in a forward-Euler style integration.
-        The velocity is updated with (Total_force / mass) * dt, then positions are integrated.
-        """
-        # velocity update
-        b_DLOs_velocity = b_DLOs_velocity.clone() + (
-            (
-                Total_force.unsqueeze(dim=-2)
-                - b_DLOs_velocity.unsqueeze(dim=-2) * damping.repeat(self.batch).clone().view(-1, 1, 1, 1)
-                  * self.mass_diagonal.repeat(self.batch, 1).unsqueeze(dim=-1).unsqueeze(dim=-1)
-            )
-            @ torch.linalg.pinv(mass_matrix)
-            * dt
-        ).reshape(-1, b_DLOs_velocity.size()[1], 3)
-
-        # position update
-        b_DLOs_vertices = b_DLOs_vertices.clone() + b_DLOs_velocity * dt * integration_ratio.clone()
-
-        return b_DLOs_vertices, b_DLOs_velocity
-
-    def branch_forward(
-        self,
-        current_vert,
-        init_direction,
-        clamped_index,
-        m_u0,
-        theta_full,
-        children_control_theta,
-        selected_parent_index,
-        selected_children_index,
-        parent_theta_clamp,
-        optimization_mask,
-        inference_1_batch
-    ):
-        """
-        Forward pass for computing internal + external forces for each branch,
-        then returns total force and updated twist angles.
-        """
-        # If in single-batch inference, use stored material curvatures
-        if inference_1_batch:
-            m_restWprev, m_restWnext = self.m_restWprev, self.m_restWnext
-        else:
-            # Otherwise, re-initialize rod geometry
-            m_restWprev, m_restWnext = self.Rod_Init(
-                self.batch,
-                init_direction,
-                self.batched_m_restEdgeL,
-                torch.zeros_like(clamped_index),
-                inference_1_batch
-            )
-
-        # Compute current edges
-        current_edges = computeEdges(current_vert, self.zero_mask.repeat(self.batch, 1))
-
-        # Parent twist from theta_full, restricted by clamp
-        parent_control_theta = theta_full[selected_parent_index][:, parent_theta_clamp]
-
-        # Update the DEFT model state (curvature, bishop frames, etc.)
-        theta_full, material_m1, material_m2, m_kb = self.DEFT_func.updateCurrentState(
-            current_vert,
-            m_u0,
-            self.batched_m_restEdgeL,
-            m_restWprev,
-            m_restWnext,
-            self.batched_m_restRegionL,
-            self.zero_mask.repeat(self.batch, 1),
-            parent_control_theta,
-            children_control_theta,
-            theta_full,
-            selected_parent_index,
-            selected_children_index,
-            optimization_mask,
-            parent_theta_clamp,
-            inference_1_batch
-        )
-
-        # Compute internal forces
-        Internal_force = self.Internal_Force_Vectorize(
-            current_edges,
-            clamped_index,
-            self.batched_m_restEdgeL,
-            self.batched_m_restRegionL,
-            m_kb,
-            m_restWprev,
-            m_restWnext,
-            theta_full,
-            material_m1,
-            material_m2
-        )
-
-        # Build mask for clamped vertices
-        batch_clamped_index = 1 - clamped_index.unsqueeze(0).repeat(self.batch, 1, 1).view(-1, self.n_vert, 1)
-
-        # Combine with external forces
-        External_force = self.External_Force(self.mass_matrix)
-        return (External_force[:, :self.n_vert] + Internal_force) * batch_clamped_index, theta_full
-
-    def iterative_sim(
-        self,
-        time_horizon,
-        b_DLOs_vertices_traj,
-        previous_b_DLOs_vertices_traj,
-        target_b_DLOs_vertices_traj,
-        loss_func,
-        dt,
-        parent_theta_clamp,
-        child1_theta_clamp,
-        child2_theta_clamp,
-        inference_1_batch,
-        vis_type,
-        vis=False,
-    ):
-        """
-        Perform iterative simulation for 'time_horizon' steps, updating positions and velocities at each step.
-        Also, apply GNN-based residual corrections and enforce constraints.
-
-        Parameters:
-        -----------
-        time_horizon: int
-            Number of timesteps to simulate forward.
-        b_DLOs_vertices_traj: tensor
-            The current BDLO trajectory data (positions).
-        previous_b_DLOs_vertices_traj: tensor
-            BDLO vertices from the previous timeframe (needed for velocity or continuity).
-        target_b_DLOs_vertices_traj: tensor
-            Ground truth reference positions for computing loss.
-        loss_func: callable
-            A PyTorch loss function, e.g. MSELoss.
-        dt: float
-            Timestep size.
-        parent_theta_clamp / child1_theta_clamp / child2_theta_clamp:
-            Indices for controlling which twist angles are clamped in parent/child branches.
-        inference_1_batch: bool
-            If True, uses the numba-based single-batch approach for constraints.
-        vis_type: str
-            Descriptor string used for naming plots or debugging visuals.
-        vis: bool
-            Whether or not to visualize each timestep.
-
-        Returns:
-        --------
-        traj_loss_eval: float
-            Accumulated position loss over all timesteps.
-        total_loss: float
-            Accumulated total loss (position + velocity) over all timesteps.
-        """
-        # Number of constraint solution iterations per timestep
-        constraint_loop = 20
-
-        # Prepare input to GNN
-        inputs = torch.zeros_like(target_b_DLOs_vertices_traj)
-
-        # If branches are clamped, copy the ground-truth clamp positions
-        parent_fix_point = None
-        child1_fix_point = None
-        child2_fix_point = None
-
-        if self.clamp_parent:
-            parent_fix_point = target_b_DLOs_vertices_traj[:, :, 0, self.parent_clamped_selection]
-            inputs[:, :, 0, self.parent_clamped_selection] = parent_fix_point
-
-        if self.clamp_child1:
-            child1_fix_point = target_b_DLOs_vertices_traj[:, :, 1, self.child1_clamped_selection]
-            inputs[:, :, 1, self.child1_clamped_selection] = child1_fix_point
-
-        if self.clamp_child2:
-            child2_fix_point = target_b_DLOs_vertices_traj[:, :, 2, self.child2_clamped_selection]
-            inputs[:, :, 2, self.child2_clamped_selection] = child2_fix_point
-
-        # Initialize accumulators for losses
-        traj_loss_eval = 0.0
-        total_loss = 0.0
-
-        # Initialize orientation/twist states
-        parent_rod_orientation = None
-        children_rod_orientation = None
-        theta_full = None
-        optimization_mask = None
-
-        # For parent-child constraints iteration
-        previous_parent_vertices_iteration_edge1 = None
-        previous_parent_vertices_iteration_edge2 = None
-        previous_children_vertices_iteration_edge = None
-
-        # For storing the updated states after each iteration
-        b_DLOs_vertices_old = None
-        b_DLOs_velocity = None
-        m_u0 = None
-
-        # Precompute zero mask repeated for the batch
-        zero_mask_batched = self.zero_mask.repeat(self.batch, 1)
-
-        # Initialize bishop frames for the first time
-        self.m_restWprev, self.m_restWnext = self.Rod_Init(
-            self.batch,
-            torch.tensor([[0.0, 0.6, 0.8], [0.0, 0.0, 1.0]])  # example initial directions
-                .unsqueeze(dim=0)
-                .repeat(self.batch, self.n_branch, 1, 1),
-            self.batched_m_restEdgeL,
-            torch.zeros_like(self.clamped_index),
-            inference_1_batch
-        )
-
-        # Main loop over timesteps
-        for ith in range(time_horizon):
-            # 1) Retrieve current/previous BDLO states
-            if ith == 0:
-                b_DLOs_vertices = b_DLOs_vertices_traj[:, ith].reshape(-1, self.n_vert, 3)
-                prev_b_DLOs_vertices = previous_b_DLOs_vertices_traj[:, ith].reshape(-1, self.n_vert, 3)
-            else:
-                prev_b_DLOs_vertices = b_DLOs_vertices_old.clone()
-
-            # 2) Initialize or parallel transport the material-frame directions m_u0
-            if ith == 0:
-                rest_edges = computeEdges(b_DLOs_vertices, zero_mask_batched)
-                init_direction = torch.tensor([[0.0, 0.6, 0.8], [0.0, 0.0, 1.0]]) \
-                    .unsqueeze(dim=0) \
-                    .repeat(self.n_branch, 1, 1)
-                m_u0 = self.DEFT_func.compute_u0(
-                    rest_edges[:, 0],
-                    init_direction.repeat(self.batch, 1, 1)[:, 0]
-                )
-
-                # Initialize rod orientation for parent + children
-                parent_rod_axis_angle = torch.zeros(1, 3)
-                parent_rod_orientation = pytorch3d.transforms.rotation_conversions.axis_angle_to_quaternion(
-                    parent_rod_axis_angle
-                ).unsqueeze(dim=0).repeat(self.batch, self.n_vert - 1, 1)
-
-                child_rod_axis_angle = torch.zeros(1, 3)
-                children_rod_orientation = pytorch3d.transforms.rotation_conversions.axis_angle_to_quaternion(
-                    child_rod_axis_angle
-                ).unsqueeze(dim=0).repeat(self.batch, len(self.rigid_body_coupling_index), 1)
-
-                # Initialize twist angles along the branches
-                rigid_body_orientation_axis_angle = pytorch3d.transforms.rotation_conversions \
-                    .quaternion_to_axis_angle(parent_rod_orientation[:, self.fused_rigid_body_coupling_index]) \
-                    .view(-1, 2, 3)
-                angles = torch.norm(rigid_body_orientation_axis_angle, dim=2) + 1e-20
-                axes = rigid_body_orientation_axis_angle / angles.unsqueeze(2)
-                children_axis = torch.nn.functional.normalize(
-                    b_DLOs_vertices[self.selected_children_index, 1] - b_DLOs_vertices[self.selected_children_index, 0],
-                    dim=1
-                ).unsqueeze(dim=1).repeat(1, 2, 1)
-                children_rotation_angles = ((children_axis * axes).sum(-1) * angles).sum(-1)
-
-                # Build theta_full and an optimization_mask
-                theta_full = torch.zeros(self.batch * self.n_branch, self.n_vert - 1)
-                theta_full[self.selected_children_index, 0] = children_rotation_angles
-
-                optimization_mask = 1 - torch.zeros_like(theta_full).unsqueeze(1)
-
-                # Apply clamp for the parent branch angles
-                if self.clamp_parent:
-                    for p_idx in parent_theta_clamp:
-                        optimization_mask[self.selected_parent_index, :, int(p_idx)] = 0
-
-                # The first child edge is zero => no update
-                optimization_mask[self.selected_children_index, :, 0] = 0
-
-                # Child1 clamp
-                if self.clamp_child1:
-                    optimization_mask[self.selected_child1_index, :, child1_theta_clamp] = 0
-
-                # Child2 clamp
-                if self.clamp_child2:
-                    optimization_mask[self.selected_child2_index, :, child2_theta_clamp] = 0
-
-            else:
-                # Parallel transport bishop frames
-                previous_edge = computeEdges(prev_b_DLOs_vertices, zero_mask_batched)
-                current_edge = computeEdges(b_DLOs_vertices, zero_mask_batched)
-                m_u0 = self.DEFT_func.parallelTransportFrame(
-                    previous_edge[:, 0],
-                    current_edge[:, 0],
-                    m_u0
-                )
-
-                # Update children rotation angles
-                rigid_body_orientation_axis_angle = pytorch3d.transforms.rotation_conversions \
-                    .quaternion_to_axis_angle(
-                        parent_rod_orientation[:, self.fused_rigid_body_coupling_index]
-                    ).view(-1, 2, 3)
-                angles = torch.norm(rigid_body_orientation_axis_angle, dim=2) + 1e-20
-                axes = rigid_body_orientation_axis_angle / angles.unsqueeze(2)
-                children_axis = torch.nn.functional.normalize(
-                    b_DLOs_vertices[self.selected_children_index, 1] - b_DLOs_vertices[self.selected_children_index, 0],
-                    dim=1
-                ).unsqueeze(dim=1).repeat(1, 2, 1)
-                children_rotation_angles = ((children_axis * axes).sum(-1) * angles).sum(-1)
-                theta_full[self.selected_children_index, 0] = children_rotation_angles
-
-            # 3) DEFT forward pass to get total forces + updated twist angles
-            Total_force, theta_full = self.branch_forward(
-                b_DLOs_vertices,
-                torch.tensor([[0.0, 0.6, 0.8], [0.0, 0.0, 1.0]])
-                    .unsqueeze(dim=0)
-                    .repeat(self.batch, self.n_branch, 1, 1),
-                self.clamped_index,
-                m_u0,
-                theta_full,
-                -children_rotation_angles if ith > 0 else -children_rotation_angles,
-                self.selected_parent_index,
-                self.selected_children_index,
-                parent_theta_clamp,
-                optimization_mask,
-                inference_1_batch
-            )
-
-            # Initialize velocity (from difference) for the first frame
-            if ith == 0:
-                b_DLOs_velocity = (b_DLOs_vertices - prev_b_DLOs_vertices) / dt
-
-            # Perform numerical integration
-            prev_b_DLOs_vertices_copy = b_DLOs_vertices.clone()
-            b_DLOs_vertices, b_DLOs_velocity = self.Numerical_Integration(
-                self.mass_matrix,
-                Total_force,
-                b_DLOs_velocity,
-                b_DLOs_vertices,
-                self.damping,
-                self.integration_ratio,
-                dt
-            )
-
-            # 4) GNN-based residual correction
-            current_input = inputs[:, ith].reshape(self.batch, -1, 3)
-            gnn_input = torch.cat([
-                b_DLOs_vertices.view(self.batch, -1, 3),
-                prev_b_DLOs_vertices.view(self.batch, -1, 3),
-                current_input,
-                self.nn_previous_bend_stiffness,
-                self.nn_next_bend_stiffness,
-                self.nn_previous_twist_stiffness,
-                self.nn_next_twist_stiffness,
-                self.undeformed_vert.unsqueeze(0).repeat(self.batch, 1, 1, 1).view(self.batch, -1, 3),
-            ], dim=-1)
-
-            delta_b_DLOs_vertices = self.GNN_tree.inference(gnn_input, current_input) * self.learning_weight * dt
-            delta_b_DLOs_vertices = delta_b_DLOs_vertices.view(-1, self.n_vert, 3)
-
-            # Enforce clamp constraints on the GNN delta
-            if self.clamp_parent:
-                parent_fix = parent_fix_point[:, ith].reshape(-1, 3)
-                b_DLOs_vertices[self.batch_indices_flat, self.parent_indices_flat] = parent_fix
-                delta_b_DLOs_vertices[self.batch_indices_flat, self.parent_indices_flat] = 0
-
-            if self.clamp_child1:
-                c1_fix = child1_fix_point[:, ith].reshape(-1, 3)
-                b_DLOs_vertices[self.batch_child1_indices_flat, self.child1_indices_flat] = c1_fix
-                delta_b_DLOs_vertices[self.batch_child1_indices_flat, self.child1_indices_flat] = 0
-
-            if self.clamp_child2:
-                c2_fix = child2_fix_point[:, ith].reshape(-1, 3)
-                b_DLOs_vertices[self.batch_child2_indices_flat, self.child2_indices_flat] = c2_fix
-                delta_b_DLOs_vertices[self.batch_child2_indices_flat, self.child2_indices_flat] = 0
-
-            # Apply the GNN correction
-            b_DLOs_vertices = b_DLOs_vertices + delta_b_DLOs_vertices
-
-            # 5) Constraints Enforcement (rotational and inextensibility)
-            if ith == 0:
-                previous_parent_vertices_iteration_edge1 = b_DLOs_vertices[self.selected_parent_index].clone()
-                previous_parent_vertices_iteration_edge2 = b_DLOs_vertices[self.selected_parent_index].clone()
-                previous_children_vertices_iteration_edge = b_DLOs_vertices[self.selected_children_index].view(self.batch, -1, self.n_vert, 3).clone()
-
-                if inference_1_batch:
-                    previous_parent_vertices_iteration_edge1 = previous_parent_vertices_iteration_edge1.detach().cpu().numpy().copy()
-                    previous_parent_vertices_iteration_edge2 = previous_parent_vertices_iteration_edge2.detach().cpu().numpy().copy()
-                    previous_children_vertices_iteration_edge = previous_children_vertices_iteration_edge.detach().cpu().numpy().copy()
-
-            if inference_1_batch:
-                parent_rod_orientation = parent_rod_orientation.detach().cpu().numpy().copy()
-                children_rod_orientation = children_rod_orientation.detach().cpu().numpy().copy()
-
-                b_DLOs_vertices = b_DLOs_vertices.detach().cpu().numpy().copy()
-                rotation_constraints_index1 = torch.linspace(0, (self.n_branch-1) * 2 - 2, len(self.rigid_body_coupling_index)).to(torch.int).detach().cpu().numpy().copy()
-                rotation_constraints_index2 = torch.linspace(1, ((self.n_branch-1) * 2 - 1), len(self.rigid_body_coupling_index)).to(torch.int).detach().cpu().numpy().copy()
-                parent_MOI_matrix_numpy = self.parent_MOI_matrix.detach().cpu().numpy().copy()
-                children_MOI_matrix_numpy = self.children_MOI_matrix.detach().cpu().numpy().copy()
-                momentum_scale_previous_numpy = self.momentum_scale_previous.detach().cpu().numpy().copy()
-                momentum_scale_next_numpy = self.momentum_scale_next.detach().cpu().numpy().copy()
-                coupling_mass_scale_numpy = self.coupling_mass_scale.detach().cpu().numpy().copy()
-                batched_m_restEdgeL_numpy = self.batched_m_restEdgeL.detach().cpu().numpy().copy()
-                inext_scale_numpy = self.inext_scale.detach().cpu().numpy().copy()
-                mass_scale_numpy = self.mass_scale.detach().cpu().numpy().copy()
-
-                # Repeatedly enforce rotation and inextensibility constraints
-                for constraint_loop_i in range(constraint_loop):
-                    parent_vertices = b_DLOs_vertices[self.selected_parent_index].reshape((self.batch, self.n_vert, 3))
-                    children_vertices = b_DLOs_vertices[self.selected_children_index].reshape((self.batch, -1, self.n_vert, 3))
-
-                    # Edge1
-                    parent_vertices, parent_rod_orientation, children_vertices, children_rod_orientation = \
-                        constraints_numba.Rotation_Constraints_Enforcement_Parent_Children(
-                            parent_vertices,
-                            parent_rod_orientation,
-                            previous_parent_vertices_iteration_edge1,
-                            children_vertices,
-                            children_rod_orientation,
-                            previous_children_vertices_iteration_edge,
-                            parent_MOI_matrix_numpy,
-                            children_MOI_matrix_numpy,
-                            np.array(self.rigid_body_coupling_index) - 1,
-                            rotation_constraints_index1,
-                            momentum_scale_previous_numpy
-                        )
-
-                    previous_parent_vertices_iteration_edge1 = parent_vertices.copy()
-                    previous_children_vertices_iteration_edge = children_vertices.copy()
-
-                    # Edge2
-                    parent_vertices, parent_rod_orientation, children_vertices, children_rod_orientation = \
-                        constraints_numba.Rotation_Constraints_Enforcement_Parent_Children(
-                            parent_vertices,
-                            parent_rod_orientation,
-                            previous_parent_vertices_iteration_edge2,
-                            children_vertices,
-                            children_rod_orientation,
-                            previous_children_vertices_iteration_edge,
-                            parent_MOI_matrix_numpy,
-                            children_MOI_matrix_numpy,
-                            np.array(self.rigid_body_coupling_index),
-                            rotation_constraints_index2,
-                            momentum_scale_next_numpy
-                        )
-
-                    previous_parent_vertices_iteration_edge2 = parent_vertices.copy()
-                    previous_children_vertices_iteration_edge = children_vertices.copy()
-
-                    # Coupling constraints among parent and child
-                    children_vertices = children_vertices.reshape((-1, self.n_vert, 3))
-                    b_DLOs_vertices = constraints_numba.Inextensibility_Constraint_Enforcement_Coupling(
-                        parent_vertices,
-                        children_vertices,
-                        np.array(self.rigid_body_coupling_index),
-                        coupling_mass_scale_numpy,
-                        self.selected_parent_index,
-                        self.selected_children_index
-                    )
-
-                    b_DLOs_vertices = constraints_numba.Inextensibility_Constraint_Enforcement(
-                        self.batch,
-                        b_DLOs_vertices,
-                        batched_m_restEdgeL_numpy,
-                        inext_scale_numpy,
-                        mass_scale_numpy,
-                        self.zero_mask_num
-                    )
-
-                b_DLOs_vertices = torch.from_numpy(b_DLOs_vertices)
-                parent_rod_orientation = torch.from_numpy(parent_rod_orientation)
-                children_rod_orientation = torch.from_numpy(children_rod_orientation)
-            else:
-                for _ in range(constraint_loop):
-                    parent_vertices = b_DLOs_vertices[self.selected_parent_index]
-                    children_vertices = b_DLOs_vertices[self.selected_children_index].view(self.batch, -1, self.n_vert, 3)
-
-                    # Edge1
-                    parent_vertices, parent_rod_orientation, children_vertices, children_rod_orientation = \
-                        self.constraints_enforcement.Rotation_Constraints_Enforcement_Parent_Children(
-                            parent_vertices,
-                            parent_rod_orientation,
-                            previous_parent_vertices_iteration_edge1,
-                            children_vertices,
-                            children_rod_orientation,
-                            previous_children_vertices_iteration_edge,
-                            self.parent_MOI_matrix,
-                            self.children_MOI_matrix,
-                            torch.tensor(self.rigid_body_coupling_index) - 1,
-                            torch.linspace(0, (children_vertices.size(1) * 2 - 2), len(self.rigid_body_coupling_index)).to(torch.int),
-                            self.momentum_scale_previous
-                        )
-
-                    previous_parent_vertices_iteration_edge1 = parent_vertices.clone()
-                    previous_children_vertices_iteration_edge = children_vertices.clone()
-
-                    # Edge2
-                    parent_vertices, parent_rod_orientation, children_vertices, children_rod_orientation = \
-                        self.constraints_enforcement.Rotation_Constraints_Enforcement_Parent_Children(
-                            parent_vertices,
-                            parent_rod_orientation,
-                            previous_parent_vertices_iteration_edge2,
-                            children_vertices,
-                            children_rod_orientation,
-                            previous_children_vertices_iteration_edge,
-                            self.parent_MOI_matrix,
-                            self.children_MOI_matrix,
-                            torch.tensor(self.rigid_body_coupling_index),
-                            torch.linspace(1, (children_vertices.size(1) * 2 - 1), len(self.rigid_body_coupling_index)).to(torch.int),
-                            self.momentum_scale_next
-                        )
-                    previous_parent_vertices_iteration_edge2 = parent_vertices.clone()
-                    previous_children_vertices_iteration_edge = children_vertices.clone()
-
-                    # Coupling constraints (parent <-> children rods)
-                    children_vertices = children_vertices.view(-1, self.n_vert, 3)
-                    b_DLOs_vertices = self.constraints_enforcement.Inextensibility_Constraint_Enforcement_Coupling(
-                        parent_vertices,
-                        children_vertices,
-                        self.rigid_body_coupling_index,
-                        self.coupling_mass_scale,
-                        self.selected_parent_index,
-                        self.selected_children_index
-                    )
-
-                    # Finally, general inextensibility constraints along each branch
-                    b_DLOs_vertices = self.constraints_enforcement.Inextensibility_Constraint_Enforcement(
-                        self.batch,
-                        b_DLOs_vertices,
-                        self.batched_m_restEdgeL,
-                        self.mass_matrix,
-                        self.clamped_index,
-                        self.inext_scale,
-                        self.mass_scale,
-                        self.zero_mask_num
-                    )
-
-            # 6) Update velocities based on final positions + compute losses
-            b_DLOs_velocity = (b_DLOs_vertices - prev_b_DLOs_vertices_copy) / dt
-
-            gt_vertices = target_b_DLOs_vertices_traj[:, ith].reshape(-1, self.n_vert, 3)
-            gt_velocity = (
-                (target_b_DLOs_vertices_traj[:, ith] - b_DLOs_vertices_traj[:, ith]).view(-1, self.n_vert, 3) / dt
-            )
-
-            # Position and velocity loss
-            step_loss_pos = loss_func(gt_vertices, b_DLOs_vertices)
-            step_loss_vel = loss_func(b_DLOs_velocity, gt_velocity)
-            traj_loss_eval += step_loss_pos
-            total_loss += (step_loss_pos + step_loss_vel)
-
-            # Visualization if requested
-            if vis:
-                vis_batch = self.batch  # how many samples we visualize
-                for i_eval_batch in range(vis_batch):
-                    parent_vertices_traj_vis = target_b_DLOs_vertices_traj[i_eval_batch][:, 0]
-                    child1_vertices_traj_vis = target_b_DLOs_vertices_traj[i_eval_batch][:, 1]
-                    child2_vertices_traj_vis = target_b_DLOs_vertices_traj[i_eval_batch][:, 2]
-
-                    child1_vertices_vis = torch.cat(
-                        (
-                            parent_vertices_traj_vis[ith, self.rigid_body_coupling_index[0]].unsqueeze(0),
-                            child1_vertices_traj_vis[ith]
-                        ),
-                        dim=0
-                    )
-                    child2_vertices_vis = torch.cat(
-                        (
-                            parent_vertices_traj_vis[ith, self.rigid_body_coupling_index[1]].unsqueeze(0),
-                            child2_vertices_traj_vis[ith]
-                        ),
-                        dim=0
-                    )
-
-                    parent_vertices_pred = b_DLOs_vertices[self.selected_parent_index]
-                    children_vertices_pred = b_DLOs_vertices[self.selected_children_index].view(self.batch, -1, 3)
-
-                    visualize_tensors_3d_in_same_plot_no_zeros(
-                        self.parent_clamped_selection,
-                        parent_vertices_pred[i_eval_batch],
-                        children_vertices_pred[i_eval_batch],
-                        ith,
-                        0,
-                        self.clamp_parent,
-                        self.clamp_child1,
-                        self.clamp_child2,
-                        parent_fix_point[:, ith].reshape(-1, 3) if self.clamp_parent else None,
-                        child1_fix_point[:, ith].reshape(-1, 3) if self.clamp_child1 else None,
-                        child2_fix_point[:, ith].reshape(-1, 3) if self.clamp_child2 else None,
-                        parent_vertices_traj_vis[ith],
-                        child1_vertices_vis,
-                        child2_vertices_vis,
-                        i_eval_batch,
-                        vis_type
-                    )
-
-            # Save updated positions for the next iteration
-            b_DLOs_vertices_old = b_DLOs_vertices.clone()
-
-        # Return the accumulated losses
-        return traj_loss_eval, total_loss
diff --git a/DEFT_train.py b/DEFT_train.py
deleted file mode 100644
index aef8ec3..0000000
--- a/DEFT_train.py
+++ /dev/null
@@ -1,747 +0,0 @@
-# Importing necessary libraries and modules
-import torch
-import torch.nn as nn
-from torch.utils.data import DataLoader
-import torch.optim as optim
-import numpy as np
-# Importing custom utility functions and classes
-# DEFT_initialization: Initializes mass, MOI, rod orientation, etc. for the BDLO
-# construct_b_DLOs: Constructs undeformed states for the BDLO
-# clamp_index: Builds the necessary clamp indices for boundary condition enforcement
-# index_init: Initializes certain indexing variables for the model
-# save_pickle: Utility function to save data (e.g., losses) to a pickle file
-# Train_DEFTData / Eval_DEFTData: Custom dataset classes to load training/evaluation data
-# DEFT_sim: Simulation model class
-from util import DEFT_initialization, construct_b_DLOs, clamp_index, index_init, save_pickle, Train_DEFTData, \
-    Eval_DEFTData
-from DEFT_sim import DEFT_sim
-from tqdm import tqdm
-import os
-import argparse
-import matplotlib.pyplot as plt
-
-
-def train(train_batch, BDLO_type, total_time, train_time_horizon, undeform_vis, inference_vis, inference_1_batch,
-          residual_learning, clamp_type, load_model):
-    # The total_time parameter is the maximum timesteps of the loaded data
-    # The train_time_horizon is how many timesteps to unroll the simulation during training
-    # The function trains or partially fine-tunes a DEFT model for a specific branched BDLO type
-
-    eval_time_horizon = total_time - 2  # Number of timesteps for evaluation
-
-    # Explanation of notation in the code:
-    # - undeformed_BDLO: A tensor containing the initial (undeformed) vertex positions of the branched BDLO
-    # - n_parent_vertices / n_child1_vertices / n_child2_vertices: The number of vertices for the main branch, child1, and child2, respectively
-
-    # Prepare BDLO-specific data depending on BDLO_type
-    if BDLO_type == 1:
-        # Set the undeformed shape of BDLO1 as a tensor of shape [1, 20, 3], then permute to [n_parent_vertices+..., 3]
-        undeformed_BDLO = torch.tensor([[[-0.6790, -0.6355, -0.5595, -0.4539, -0.3688, -0.2776, -0.1857,
-                                          -0.0991, 0.0102, 0.0808, 0.1357, 0.2081, 0.2404, -0.4279,
-                                          -0.4880, -0.5394, -0.5559, 0.0698, 0.0991, 0.1125]],
-                                        [[0.0035, -0.0066, -0.0285, -0.0349, -0.0704, -0.0663, -0.0744,
-                                          -0.0957, -0.0702, -0.0592, -0.0452, -0.0236, -0.0134, -0.0813,
-                                          -0.1233, -0.1875, -0.2178, -0.1044, -0.1858, -0.2165]],
-                                        [[0.0108, 0.0104, 0.0083, 0.0104, 0.0083, 0.0145, 0.0133,
-                                          0.0198, 0.0155, 0.0231, 0.0199, 0.0154, 0.0169, 0.0160,
-                                          0.0153, 0.0090, 0.0121, 0.0205, 0.0155, 0.0148]]]).permute(1, 2, 0)
-
-        # Number of vertices along the parent branch and the two child branches
-        n_parent_vertices = 13
-        n_child1_vertices = 5
-        n_child2_vertices = 4
-
-        # Depending on clamp_type, we set the train/eval dataset sizes and the selection of clamped vertices
-        if clamp_type == "ends":
-            train_set_number = 77
-            eval_set_number = 24
-            parent_clamped_selection = torch.tensor((0, 1, -2, -1))
-            child1_clamped_selection = torch.tensor((2))
-            child2_clamped_selection = torch.tensor((2))
-        else:
-            train_set_number = 71
-            eval_set_number = 18
-            parent_clamped_selection = torch.tensor((2, -2, -1))
-            child1_clamped_selection = torch.tensor((2))
-            child2_clamped_selection = torch.tensor((2))
-
-        # cs_n_vert holds the number of child1 and child2 vertices
-        cs_n_vert = (n_child1_vertices, n_child2_vertices)
-        # n_vert is the parent branch vertex count
-        n_vert = n_parent_vertices
-        # Number of edges in the parent branch is n_vert - 1
-        n_edge = n_vert - 1
-
-        # Sanity check: parent branch should have more vertices than any child branch
-        if n_parent_vertices <= max(cs_n_vert):
-            raise Exception("warning: number of parent's vertices is larger than children's!")
-
-        # Define the stiffness parameters as nn.Parameters for optimization or subsequent usage
-        bend_stiffness_parent = nn.Parameter(4e-3 * torch.ones((1, 1, n_edge), device=device))
-        bend_stiffness_child1 = nn.Parameter(4e-3 * torch.ones((1, 1, n_edge), device=device))
-        bend_stiffness_child2 = nn.Parameter(4e-3 * torch.ones((1, 1, n_edge), device=device))
-        twist_stiffness = nn.Parameter(1e-4 * torch.ones((1, n_branch, n_edge), device=device))
-
-        # Damping parameters for each branch
-        damping = nn.Parameter(torch.tensor((2.5, 2.5, 2.5), device=device))
-
-        # If we use residual learning, learning_weight is used to scale the residual from the GNN
-        if residual_learning:
-            learning_weight = nn.Parameter(torch.tensor(0.02, device=device))
-        else:
-            learning_weight = nn.Parameter(torch.tensor(0.00, device=device))
-
-        # Indices that define which vertices couple the child branches to the parent
-        rigid_body_coupling_index = [4, 8]
-
-        # Mass and moment-of-inertia scaling factors
-        parent_mass_scale = 1.
-        parent_moment_scale = 10.
-        moment_ratio = 0.1
-        children_moment_scale = (0.5, 0.5)
-        children_mass_scale = (1, 1)
-
-    if BDLO_type == 2:
-        # Similar initialization for BDLO2
-        undeformed_BDLO = torch.tensor([
-            [[0.0150, 0.0157, 0.0125, 0.0109, 0.0164, 0.0131, 0.0104,
-              0.0081, 0.0083, 0.0079, 0.0093, 0.0108, 0.0150, 0.0109,
-              0.0116, 0.0110, 0.0111, 0.0084, 0.0103, 0.0097]],
-            [[0.1521, 0.1426, 0.1021, 0.0928, 0.0882, 0.0711, 0.0678,
-              0.0894, 0.1109, 0.1374, 0.1708, 0.1855, 0.0339, -0.0410,
-              -0.1058, -0.1266, 0.0465, -0.0155, -0.0733, -0.0954]],
-            [[-0.1706, -0.1409, -0.0875, -0.0018, 0.0702, 0.1685, 0.2583,
-              0.3363, 0.3894, 0.4529, 0.5106, 0.5355, 0.0704, 0.0615,
-              0.0093, -0.0080, 0.3405, 0.3217, 0.2929, 0.2834]]
-        ]).permute(1, 2, 0)
-
-        n_parent_vertices = 12
-        n_child1_vertices = 5
-        n_child2_vertices = 5
-        train_set_number = 110
-        eval_set_number = 37
-
-        cs_n_vert = (n_child1_vertices, n_child2_vertices)
-        n_vert = n_parent_vertices
-        n_edge = n_vert - 1
-        if n_parent_vertices <= max(cs_n_vert):
-            raise Exception("warning: number of parent's vertices is larger than children's!")
-
-        # Stiffness parameters
-        bend_stiffness_parent = nn.Parameter(2e-3 * torch.ones((1, 1, n_edge), device=device))
-        bend_stiffness_child1 = nn.Parameter(1.5e-3 * torch.ones((1, 1, n_edge), device=device))
-        bend_stiffness_child2 = nn.Parameter(1.5e-3 * torch.ones((1, 1, n_edge), device=device))
-        twist_stiffness = nn.Parameter(1e-4 * torch.ones((1, n_branch, n_edge), device=device))
-
-        # Damping parameters
-        damping = nn.Parameter(torch.tensor((2.5, 2., 2.), device=device))
-
-        if residual_learning:
-            learning_weight = nn.Parameter(torch.tensor(0.02, device=device))
-        else:
-            learning_weight = nn.Parameter(torch.tensor(0.00, device=device))
-
-        # Rigid body coupling index: the parent-children connection points
-        rigid_body_coupling_index = [4, 7]
-
-        # Mass, MOI scaling, etc.
-        parent_mass_scale = 1.
-        parent_moment_scale = 10.
-        moment_ratio = 0.1
-        children_moment_scale = (0.5, 0.5)
-        children_mass_scale = (1, 1)
-
-        # Which vertices are clamped in the dataset
-        parent_clamped_selection = torch.tensor((0, 1, -2, -1))
-        child1_clamped_selection = torch.tensor((2))
-        child2_clamped_selection = torch.tensor((2))
-
-    if BDLO_type == 3:
-        # Initialization for BDLO3
-        undeformed_BDLO = torch.tensor([
-            [[0.0099, 0.0114, 0.0109, 0.0084, 0.0130, 0.0143, 0.0119,
-              0.0133, 0.0135, 0.0136, 0.0136, 0.0151, 0.0124, 0.0093,
-              0.0120, 0.0132, 0.0121]],
-            [[-0.0444, -0.0684, -0.1235, -0.1722, -0.1973, -0.2265, -0.2232,
-              -0.1956, -0.1675, -0.1150, -0.0544, -0.0249, -0.2632, -0.3340,
-              -0.2580, -0.3370, -0.3594]],
-            [[-0.5656, -0.5434, -0.4977, -0.4399, -0.3552, -0.2506, -0.1563,
-              -0.0530, 0.0092, 0.0709, 0.1222, 0.1390, -0.3781, -0.4082,
-              -0.0169, -0.0347, -0.0420]]
-        ]).permute(1, 2, 0)
-
-        n_parent_vertices = 12
-        n_child1_vertices = 3
-        n_child2_vertices = 4
-
-        if clamp_type == "ends":
-            train_set_number = 103
-            eval_set_number = 26
-            parent_clamped_selection = torch.tensor((0, 1, -2, -1))
-            child1_clamped_selection = torch.tensor((2))
-            child2_clamped_selection = torch.tensor((2))
-        else:
-            train_set_number = 39
-            eval_set_number = 12
-            parent_clamped_selection = torch.tensor((3, -2, -1))
-            child1_clamped_selection = torch.tensor((2))
-            child2_clamped_selection = torch.tensor((2))
-
-        cs_n_vert = (n_child1_vertices, n_child2_vertices)
-        n_vert = n_parent_vertices
-        n_edge = n_vert - 1
-        if n_parent_vertices <= max(cs_n_vert):
-            raise Exception("warning: number of parent's vertices is larger than children's!")
-
-        # Stiffness parameters
-        bend_stiffness_parent = nn.Parameter(2.5e-3 * torch.ones((1, 1, n_edge), device=device))
-        bend_stiffness_child1 = nn.Parameter(2.5e-3 * torch.ones((1, 1, n_edge), device=device))
-        bend_stiffness_child2 = nn.Parameter(2.5e-3 * torch.ones((1, 1, n_edge), device=device))
-        twist_stiffness = nn.Parameter(1e-4 * torch.ones((1, n_branch, n_edge), device=device))
-        damping = nn.Parameter(torch.tensor((2., 2., 2.), device=device))
-
-        if residual_learning:
-            learning_weight = nn.Parameter(torch.tensor(0.02, device=device))
-        else:
-            learning_weight = nn.Parameter(torch.tensor(0.00, device=device))
-
-        rigid_body_coupling_index = [4, 7]
-        parent_mass_scale = 1.
-        parent_moment_scale = 10.
-        moment_ratio = 0.1
-        children_moment_scale = (0.5, 0.5)
-        children_mass_scale = (1, 1)
-
-    if BDLO_type == 4:
-        # Initialization for BDLO4
-        undeformed_BDLO = torch.tensor([
-            [[0.0108, 0.0122, 0.0112, 0.0116, 0.0116, 0.0169, 0.0122,
-              0.0198, 0.0173, 0.0140, 0.0152, 0.0156, 0.0120, 0.0107,
-              0.0163, 0.0154]],
-            [[-0.1680, -0.1938, -0.2439, -0.2991, -0.3230, -0.3345, -0.3376,
-              -0.3248, -0.3100, -0.2727, -0.2182, -0.1878, -0.3922, -0.4643,
-              -0.3866, -0.4500]],
-            [[-0.5774, -0.5491, -0.4909, -0.4085, -0.3219, -0.2371, -0.1568,
-              -0.0645, 0.0231, 0.0828, 0.1411, 0.1664, -0.3430, -0.3652,
-              0.0434, 0.0658]]
-        ]).permute(1, 2, 0)
-
-        n_parent_vertices = 12
-        n_child1_vertices = 3
-        n_child2_vertices = 3
-        train_set_number = 74
-        eval_set_number = 25
-
-        cs_n_vert = (n_child1_vertices, n_child2_vertices)
-        n_vert = n_parent_vertices
-        n_edge = n_vert - 1
-        if n_parent_vertices <= max(cs_n_vert):
-            raise Exception("warning: number of parent's vertices is larger than children's!")
-
-        # Stiffness parameters
-        bend_stiffness_parent = nn.Parameter(3e-3 * torch.ones((1, 1, n_edge), device=device))
-        bend_stiffness_child1 = nn.Parameter(4e-3 * torch.ones((1, 1, n_edge), device=device))
-        bend_stiffness_child2 = nn.Parameter(4e-3 * torch.ones((1, 1, n_edge), device=device))
-        twist_stiffness = nn.Parameter(1e-4 * torch.ones((1, n_branch, n_edge), device=device))
-
-        # Damping for each of the 3 branches
-        damping = nn.Parameter(torch.tensor((3., 4, 4.), device=device))
-
-        if residual_learning:
-            learning_weight = nn.Parameter(torch.tensor(0.02, device=device))
-        else:
-            learning_weight = nn.Parameter(torch.tensor(0.00, device=device))
-
-        # Connection indices for the child branches
-        rigid_body_coupling_index = [4, 8]
-
-        parent_mass_scale = 1.
-        parent_moment_scale = 10.
-        moment_ratio = 0.1
-        children_moment_scale = (0.5, 0.5)
-        children_mass_scale = (1, 1)
-
-        parent_clamped_selection = torch.tensor((0, 1, -2, -1))
-        child1_clamped_selection = torch.tensor((2))
-        child2_clamped_selection = torch.tensor((2))
-
-    # Decide how many batches we use in evaluation (1 batch if inference_1_batch is True, else the entire eval_set_number)
-    if inference_1_batch:
-        eval_batch = 1
-    else:
-        eval_batch = eval_set_number
-
-    # Number of vertices in the child branches
-    n_children_vertices = (n_child1_vertices, n_child2_vertices)
-
-    # Extract parent and child vertices from the undeformed BDLO
-    parent_vertices_undeform = undeformed_BDLO[:, :n_parent_vertices]
-    child1_vertices_undeform = undeformed_BDLO[:, n_parent_vertices: n_parent_vertices + n_children_vertices[0] - 1]
-    child2_vertices_undeform = undeformed_BDLO[:, n_parent_vertices + n_children_vertices[0] - 1:]
-
-    # DEFT_initialization returns scaled mass, MOI, rod orientations, nominal length, etc.
-    b_DLO_mass, parent_MOI, children_MOI, parent_rod_orientation, children_rod_orientation, b_nominal_length = DEFT_initialization(
-        parent_vertices_undeform,
-        child1_vertices_undeform,
-        child2_vertices_undeform,
-        n_branch,
-        n_parent_vertices,
-        cs_n_vert,
-        rigid_body_coupling_index,
-        parent_mass_scale,
-        parent_moment_scale,
-        children_moment_scale,
-        children_mass_scale,
-        moment_ratio
-    )
-
-    # Construct the branched BDLO from data for the training batch
-    # b_DLOs_vertices_undeform_untransform is the original set of undeformed states across the batch
-    # The second return is an optional placeholder for transformations or expansions
-    b_DLOs_vertices_undeform_untransform, _ = construct_b_DLOs(
-        train_batch,
-        rigid_body_coupling_index,
-        n_parent_vertices,
-        cs_n_vert,
-        n_branch,
-        parent_vertices_undeform,
-        parent_vertices_undeform,
-        child1_vertices_undeform,
-        child1_vertices_undeform,
-        child2_vertices_undeform,
-        child2_vertices_undeform
-    )
-
-    # Transform the axis from local coordinate to global by re-indexing the coordinate axes
-    b_DLOs_vertices_undeform_transform = torch.zeros_like(b_DLOs_vertices_undeform_untransform)
-    b_DLOs_vertices_undeform_transform[:, :, :, 0] = -b_DLOs_vertices_undeform_untransform[:, :, :, 2]
-    b_DLOs_vertices_undeform_transform[:, :, :, 1] = -b_DLOs_vertices_undeform_untransform[:, :, :, 0]
-    b_DLOs_vertices_undeform_transform[:, :, :, 2] = b_DLOs_vertices_undeform_untransform[:, :, :, 1]
-
-    # The first sample in the batch of undeformed vertices (reshape to [n_branch, n_vert, 3])
-    b_undeformed_vert = b_DLOs_vertices_undeform_transform[0].view(n_branch, -1, 3)
-
-    # Initialize index selection for parent MOI indices, etc.
-    index_selection1, index_selection2, parent_MOI_index1, parent_MOI_index2 = index_init(
-        rigid_body_coupling_index,
-        n_branch
-    )
-
-    # Decide which vertices get clamped (i.e., fixed in space/rotation) for the training and evaluation sets
-    clamped_index, parent_theta_clamp, child1_theta_clamp, child2_theta_clamp = clamp_index(
-        train_batch,
-        parent_clamped_selection,
-        child1_clamped_selection,
-        child2_clamped_selection,
-        n_branch,
-        n_parent_vertices,
-        clamp_parent,
-        clamp_child1,
-        clamp_child2
-    )
-    eval_clamped_index, eval_parent_theta_clamp, eval_child1_theta_clamp, eval_child2_theta_clamp = clamp_index(
-        eval_batch,
-        parent_clamped_selection,
-        child1_clamped_selection,
-        child2_clamped_selection,
-        n_branch,
-        n_parent_vertices,
-        clamp_parent,
-        clamp_child1,
-        clamp_child2
-    )
-
-    # Timestep for simulation
-    dt = 0.01
-
-    # Instantiate DEFT_sim objects for training and evaluation
-    DEFT_sim_train = DEFT_sim(
-        batch=train_batch,
-        n_branch=n_branch,
-        n_vert=n_vert,
-        cs_n_vert=cs_n_vert,
-        b_init_n_vert=b_undeformed_vert,
-        n_edge=n_vert - 1,
-        b_undeformed_vert=b_undeformed_vert,
-        b_DLO_mass=b_DLO_mass,
-        parent_DLO_MOI=parent_MOI,
-        children_DLO_MOI=children_MOI,
-        device=device,
-        clamped_index=clamped_index,
-        rigid_body_coupling_index=rigid_body_coupling_index,
-        parent_MOI_index1=parent_MOI_index1,
-        parent_MOI_index2=parent_MOI_index2,
-        parent_clamped_selection=parent_clamped_selection,
-        child1_clamped_selection=child1_clamped_selection,
-        child2_clamped_selection=child2_clamped_selection,
-        clamp_parent=clamp_parent,
-        clamp_child1=clamp_child1,
-        clamp_child2=clamp_child2,
-        index_selection1=index_selection1,
-        index_selection2=index_selection2,
-        bend_stiffness_parent=bend_stiffness_parent,
-        bend_stiffness_child1=bend_stiffness_child1,
-        bend_stiffness_child2=bend_stiffness_child2,
-        twist_stiffness=twist_stiffness,
-        damping=damping,
-        learning_weight=learning_weight
-    )
-    DEFT_sim_eval = DEFT_sim(
-        batch=eval_batch,
-        n_branch=n_branch,
-        n_vert=n_vert,
-        cs_n_vert=cs_n_vert,
-        b_init_n_vert=b_undeformed_vert,
-        n_edge=n_vert - 1,
-        b_undeformed_vert=b_undeformed_vert,
-        b_DLO_mass=b_DLO_mass,
-        parent_DLO_MOI=parent_MOI,
-        children_DLO_MOI=children_MOI,
-        device=device,
-        clamped_index=eval_clamped_index,
-        rigid_body_coupling_index=rigid_body_coupling_index,
-        parent_MOI_index1=parent_MOI_index1,
-        parent_MOI_index2=parent_MOI_index2,
-        parent_clamped_selection=parent_clamped_selection,
-        child1_clamped_selection=child1_clamped_selection,
-        child2_clamped_selection=child2_clamped_selection,
-        clamp_parent=clamp_parent,
-        clamp_child1=clamp_child1,
-        clamp_child2=clamp_child2,
-        index_selection1=index_selection1,
-        index_selection2=index_selection2,
-        bend_stiffness_parent=bend_stiffness_parent,
-        bend_stiffness_child1=bend_stiffness_child1,
-        bend_stiffness_child2=bend_stiffness_child2,
-        twist_stiffness=twist_stiffness,
-        damping=damping,
-        learning_weight=learning_weight
-    )
-
-    # Load pretrained models for initialization depending on BDLO_type and clamp_type
-    if load_model:
-        if BDLO_type == 1 and clamp_type == "ends":
-            DEFT_sim_train.load_state_dict(torch.load("save_model/BDLO1/DEFT_1_780_1.pth"), strict=False)
-        if BDLO_type == 1 and clamp_type == "middle":
-            DEFT_sim_train.load_state_dict(torch.load("save_model/BDLO1/DEFT_middle_1_2260_1.pth"), strict=False)
-        if BDLO_type == 2:
-            DEFT_sim_train.load_state_dict(torch.load("save_model/BDLO2/DEFT_2_820_2.pth"), strict=False)
-        if BDLO_type == 3:
-            DEFT_sim_train.load_state_dict(torch.load("save_model/BDLO3/DEFT_3_40_3.pth"), strict=False)
-        if BDLO_type == 3 and clamp_type == "middle":
-            DEFT_sim_train.load_state_dict(torch.load("save_model/BDLO3/DEFT_middle_3_2320_1.pth"), strict=False)
-        if BDLO_type == 4:
-            DEFT_sim_train.load_state_dict(torch.load("save_model/BDLO4/DEFT_4_40_3.pth"), strict=False)
-
-    # If we want to visualize the undeformed states
-    if undeform_vis:
-        # Visualize the first batch's undeformed state
-        first_batch_vertices = b_DLOs_vertices_undeform_transform[0]  # shape: [3, n_vert, 3]
-        colors = ['red', 'green', 'blue']
-
-        fig = plt.figure(figsize=(12, 9))
-        ax = fig.add_subplot(111, projection='3d')
-
-        # For each branch, plot all vertex positions (here, just one set since it's "undeformed_vis")
-        for branch_idx in range(3):
-            branch_positions = first_batch_vertices[branch_idx, :, :]
-
-            for vertex_idx in range(branch_positions.shape[0]):
-                vertex_positions = branch_positions[vertex_idx, :]
-                x = vertex_positions[0].unsqueeze(dim=0).numpy()
-                y = vertex_positions[1].unsqueeze(dim=0).numpy()
-                z = vertex_positions[2].unsqueeze(dim=0).numpy()
-                ax.scatter(x, y, z, color=colors[branch_idx], alpha=1.)
-
-        ax.set_xlim(-0.5, 1.0)
-        ax.set_ylim(-0.5, 1.0)
-        ax.set_zlim(-0.25, 1.25)
-        ax.set_xlabel('X Axis')
-        ax.set_ylabel('Y Axis')
-        ax.set_zlabel('Z Axis')
-        ax.set_title('Trajectories of Vertices Over Time (First Batch)')
-
-        from matplotlib.lines import Line2D
-        legend_elements = [Line2D([0], [0], color=colors[i], lw=2, label=f'Branch {i}') for i in range(3)]
-        ax.legend(handles=legend_elements)
-        plt.show()
-
-    # Scale factor for learning rate
-    lr_scale = 10
-
-    # Define loss function
-    loss_func = torch.nn.MSELoss()
-
-    # We separate parameter sets based on whether we are doing residual learning or not
-    gnn_params = DEFT_sim_train.GNN_tree.parameters()
-
-    if not residual_learning:
-        # If not using residual learning, we optimize all or most DEFT parameters
-        parameters_to_update = [
-            {"params": DEFT_sim_train.p_DLO_diagonal, "lr": 1e-5 * lr_scale},
-            {"params": DEFT_sim_train.c_DLO_diagonal, "lr": 1e-5 * lr_scale},
-            {"params": DEFT_sim_train.integration_ratio, "lr": 1e-5 * lr_scale},
-            {"params": DEFT_sim_train.velocity_ratio, "lr": 1e-5 * lr_scale},
-            {"params": DEFT_sim_train.undeformed_vert, "lr": 1e-5 * lr_scale},
-            {"params": DEFT_sim_train.mass_diagonal, "lr": 1e-5 * lr_scale},
-            {"params": DEFT_sim_train.damping, "lr": 1e-5 * lr_scale},
-            {"params": DEFT_sim_train.gravity, "lr": 1e-5 * lr_scale},
-            {"params": DEFT_sim_train.DEFT_func.twist_stiffness, "lr": 1e-5 * lr_scale},
-            {"params": DEFT_sim_train.DEFT_func.bend_stiffness_parent, "lr": 1e-9 * lr_scale},
-            {"params": DEFT_sim_train.DEFT_func.bend_stiffness_child1, "lr": 1e-9 * lr_scale},
-            {"params": DEFT_sim_train.DEFT_func.bend_stiffness_child2, "lr": 1e-9 * lr_scale},
-        ]
-    else:
-        # If using residual learning, we mainly update the GNN and the residual learning weight
-        parameters_to_update = [
-            {"params": DEFT_sim_train.learning_weight, "lr": 1e-6 * lr_scale},
-            {"params": gnn_params, "lr": 1e-5 * lr_scale}
-        ]
-
-    # Define the optimizer (here, SGD) with the chosen parameters
-    optimizer = optim.SGD(parameters_to_update)
-
-    # We'll store evaluation results after certain intervals
-    eval_epochs = []
-    eval_losses = []
-
-    # We'll store training results as well
-    training_epochs = []
-    training_losses = []
-
-    # Loading training / evaluation data from custom datasets
-    if clamp_type == "ends":
-        eval_dataset = Eval_DEFTData(
-            BDLO_type,
-            n_parent_vertices,
-            n_children_vertices,
-            n_branch,
-            rigid_body_coupling_index,
-            eval_set_number,
-            total_time,
-            eval_time_horizon,
-            device
-        )
-        eval_data_len = len(eval_dataset)
-        train_dataset = Train_DEFTData(
-            BDLO_type,
-            n_parent_vertices,
-            n_children_vertices,
-            n_branch,
-            rigid_body_coupling_index,
-            train_set_number,
-            total_time,
-            train_time_horizon,
-            device
-        )
-        train_data_loader = DataLoader(train_dataset, batch_size=train_batch, shuffle=True, drop_last=True)
-
-    if clamp_type == "middle":
-        # We load data from the dataset variant with middle clamps
-        eval_dataset = Eval_DEFTData(
-            str(BDLO_type) + "_mid_clamp",
-            n_parent_vertices,
-            n_children_vertices,
-            n_branch,
-            rigid_body_coupling_index,
-            eval_set_number,
-            total_time,
-            eval_time_horizon,
-            device
-        )
-        eval_data_len = len(eval_dataset)
-        train_dataset = Train_DEFTData(
-            str(BDLO_type) + "_mid_clamp",
-            n_parent_vertices,
-            n_children_vertices,
-            n_branch,
-            rigid_body_coupling_index,
-            train_set_number,
-            total_time,
-            train_time_horizon,
-            device
-        )
-        train_data_loader = DataLoader(train_dataset, batch_size=train_batch, shuffle=True, drop_last=True)
-
-    # Define number of epochs to train
-    train_epoch = 100
-    save_steps = 0
-    evaluate_period = 20
-    model = "DEFT"
-    training_case = 1
-
-    # The main training loop
-    if model == "DEFT":
-        training_iteration = 0
-        for epoch in range(train_epoch):
-            bar = tqdm(train_data_loader)
-            for data in bar:
-                # Evaluate the model on the eval set periodically
-                if save_steps % evaluate_period == 0:
-                    part_eval = eval_set_number
-                    # Random split for partial evaluation if desired
-                    eval_set, test_set = torch.utils.data.random_split(eval_dataset,
-                                                                       [part_eval, eval_data_len - part_eval])
-                    eval_data_loader = DataLoader(eval_set, batch_size=eval_batch, shuffle=True, drop_last=True)
-
-                    # Save the current model
-                    torch.save(
-                        DEFT_sim_train.state_dict(),
-                        os.path.join("save_model/", "DEFT_%s_%s_%s_%s.pth" % (
-                        clamp_type, BDLO_type, str(training_iteration), training_case))
-                    )
-                    # Load the saved model into the evaluation simulation object
-                    DEFT_sim_eval.load_state_dict(
-                        torch.load("save_model/DEFT_%s_%s_%s_%s.pth" % (
-                        clamp_type, BDLO_type, str(training_iteration), training_case))
-                    )
-
-                    eval_bar = tqdm(eval_data_loader)
-                    with torch.no_grad():
-                        for eval_data in eval_bar:
-                            # The evaluation data has previous, current, and target states
-                            previous_b_DLOs_vertices_traj, b_DLOs_vertices_traj, target_b_DLOs_vertices_traj = eval_data
-                            vis_type = "DEFT_%s" % BDLO_type
-                            # Visualize on first iteration if inference_vis is True
-                            if training_iteration == 0:
-                                vis = inference_vis
-                            else:
-                                vis = False
-                            # Perform iterative simulation over eval_time_horizon
-                            traj_loss_eval, _ = DEFT_sim_eval.iterative_sim(
-                                eval_time_horizon,
-                                b_DLOs_vertices_traj,
-                                previous_b_DLOs_vertices_traj,
-                                target_b_DLOs_vertices_traj,
-                                loss_func,
-                                dt,
-                                parent_theta_clamp,
-                                child1_theta_clamp,
-                                child2_theta_clamp,
-                                inference_1_batch,
-                                vis_type=vis_type,
-                                vis=vis
-                            )
-                            # Print and record the average loss
-                            print(np.sqrt(traj_loss_eval.cpu().detach().numpy() / total_time))
-                            eval_losses.append(traj_loss_eval.cpu().detach().numpy() / total_time)
-                            eval_epochs.append(training_iteration)
-
-                            # Save the evaluation losses to pickle
-                            save_pickle(eval_losses, "training_record/eval_%s_loss_DEFT_%s_%s.pkl" % (
-                            clamp_type, training_case, BDLO_type))
-                            save_pickle(eval_epochs, "training_record/eval_%s_epoches_DEFT_%s_%s.pkl" % (
-                            clamp_type, training_case, BDLO_type))
-
-                # Increment steps and iteration
-                save_steps += 1
-                training_iteration += 1
-
-                # Get the input data from the loader
-                vis = False
-                previous_b_DLOs_vertices_traj, b_DLOs_vertices_traj, target_b_DLOs_vertices_traj, m_u0_traj = data
-
-                # Forward pass through the DEFT model for train_time_horizon timesteps
-                traj_loss, total_loss = DEFT_sim_train.iterative_sim(
-                    train_time_horizon,
-                    b_DLOs_vertices_traj,
-                    previous_b_DLOs_vertices_traj,
-                    target_b_DLOs_vertices_traj,
-                    loss_func,
-                    dt,
-                    parent_theta_clamp,
-                    child1_theta_clamp,
-                    child2_theta_clamp,
-                    inference_1_batch,
-                    vis_type=vis_type,
-                    vis=vis
-                )
-
-                # Record and print training loss
-                training_losses.append(traj_loss.cpu().detach().numpy() / train_time_horizon)
-                training_epochs.append(training_iteration)
-
-                # Backprop through the total loss
-                total_loss.backward(retain_graph=True)
-                optimizer.step()
-                optimizer.zero_grad()
-
-                # Save training losses to pickle
-                save_pickle(training_losses,
-                            "training_record/train_%s_loss_DEFT_%s_%s.pkl" % (clamp_type, training_case, BDLO_type))
-                save_pickle(training_epochs,
-                            "training_record/train_%s_step_DEFT_%s_%s.pkl" % (clamp_type, training_case, BDLO_type))
-
-
-if __name__ == "__main__":
-    # Setting up a command-line interface for hyperparameters and options
-
-    # Make sure to use double precision for stability in the DEFT simulations
-    torch.set_default_dtype(torch.float64)
-    torch.manual_seed(1)
-
-    # Limit the number of threads used by PyTorch and underlying libraries for reproducibility
-    os.environ["OMP_NUM_THREADS"] = "1"
-    os.environ["MKL_NUM_THREADS"] = "1"
-    torch.set_num_threads(1)
-    torch.set_num_interop_threads(1)
-
-    # Initialize argument parser
-    parser = argparse.ArgumentParser()
-
-    # BDLO_type controls which BDLO dataset (and initial parameter sets) to use
-    parser.add_argument("--BDLO_type", type=int, default=1)
-
-    # clamp_type indicates how the BDLO is clamped (ends or middle)
-    parser.add_argument("--clamp_type", type=str, default="ends")
-
-    # total_time is the maximum number of timesteps we have in the dataset (e.g. 500)
-    parser.add_argument("--total_time", type=int, default=500)
-
-    # train_time_horizon is how many timesteps we simulate in each training iteration
-    parser.add_argument("--train_time_horizon", type=int, default=100)
-
-    # Whether to visualize the initial undeformed vertices
-    parser.add_argument("--undeform_vis", type=bool, default=False)
-
-    # Whether we do inference only for 1 batch (for speed) or for all eval sets
-    parser.add_argument("--inference_1_batch", type=bool, default=False)
-
-    # Whether to enable residual learning: if True, GNN-based updates are used
-    parser.add_argument("--residual_learning", type=bool, default=False)
-
-    # Training batch size
-    parser.add_argument("--train_batch", type=int, default=32)
-
-    # Whether to visualize inference results (for debugging)
-    parser.add_argument("--inference_vis", type=bool, default=False)
-
-    # load trained model
-    parser.add_argument("--load_model", type=bool, default=True)
-
-    # Flags for which branches are clamped
-    clamp_parent = True
-    clamp_child1 = False
-    clamp_child2 = False
-
-    # Number of branches for the BDLO (1 parent branch + 2 children branches)
-    n_branch = 3
-
-    # For simplicity, everything is done on CPU in this version
-    device = "cpu"
-
-    args = parser.parse_args()
-
-    # Call the training function with the user-specified arguments
-    train(
-        train_batch=args.train_batch,
-        BDLO_type=args.BDLO_type,
-        total_time=args.total_time,
-        train_time_horizon=args.train_time_horizon,
-        undeform_vis=args.undeform_vis,
-        inference_vis=args.inference_vis,
-        inference_1_batch=args.inference_1_batch,
-        residual_learning=args.residual_learning,
-        clamp_type=args.clamp_type,
-        load_model=args.load_model
-    )
diff --git a/README.md b/README.md
index 27a0933..86867f1 100644
--- a/README.md
+++ b/README.md
@@ -32,11 +32,61 @@ A gradient is used for these predictions to depict the evolution of time, starti
 Note that the ground truth is only provided at t=0s and prediction is constructed until t=8s.
 The prediction is performed recursively, without requiring additional ground-truth data or perception inputs throughout the entire process.
 
-## Dependency 
-Run `pip install -r requirements.txt` to collect all python dependencies.
+## Dependencies
+The main dependencies are listed in `requirements.txt`. Install them using:
+```bash
+pip install -r requirements.txt
+```
+
+Key dependencies include:
+- PyTorch (2.5.1+)
+- NumPy
+- Numba
+- PyTorch3D
+- Theseus-AI
+- Matplotlib
+- Pandas
+
+## Installation
+
+### From Source
+```bash
+git clone https://github.com/roahmlab/DEFT.git
+cd DEFT
+pip install -e .
+```
+
+### Using Conda Environment
+```bash
+conda create -n DEFT python=3.11
+conda activate DEFT
+pip install -r requirements.txt
+pip install -e .
+```
+
+## Project Structure
+```
+DEFT/
+ deft/                    # Main package
+    core/               # Core simulation modules
+    models/             # Neural network models
+    solvers/            # Constraint and theta solvers
+    utils/              # Utility functions
+ scripts/                # Training and analysis scripts
+ examples/               # Example usage and demos
+ tests/                  # Unit tests
+ docs/                   # Documentation
+ assets/                 # Images and media
+ dataset/                # Training and evaluation data
+ save_model/             # Saved model checkpoints
+ training_record/        # Training logs and records
+```
 
 ## Train DEFT Models
-Example: To train a DEFT model using the BDLO1 dataset with end-effectors that grasp the BDLO's ends, run the following command: python DEFT_train.py --BDLO_type="1" --clamp_type="ends"
+Example: To train a DEFT model using the BDLO1 dataset with end-effectors that grasp the BDLO's ends, run the following command:
+```bash
+python scripts/DEFT_train.py --BDLO_type="1" --clamp_type="ends"
+```
 
 ## Dataset
 - For each BDLO, dynamic trajectory data is captured in real-world settings using a motion capture system operating at 100 Hz when robots grasp the BDLOs ends. For details on dataset usage, please refer to DEFT_train.py.
diff --git a/constraints_enforcement_numba.py b/constraints_enforcement_numba.py
deleted file mode 100644
index 3641091..0000000
--- a/constraints_enforcement_numba.py
+++ /dev/null
@@ -1,899 +0,0 @@
-import torch.nn as nn
-import numpy as np
-from numba import njit
-
-@njit
-def _numba_inextensibility_constraint_enforcement(
-    current_vertices,   # (B, N, 3)
-    nominal_length,     # (B, N-1)
-    scale,              # (2B, N-1)
-    mass_scale,         # (2B, N-1, 3,3)
-    zero_mask_num,      # (B, N-1)
-    tolerance
-):
-    B = current_vertices.shape[0]
-    N = current_vertices.shape[1]
-
-    # Precompute
-    nominal_length_sq = nominal_length * nominal_length
-
-    # Main loop over edges i = 0..(N-2)
-    for i in range(N-1):
-        # updated_edges shape = (B,3)
-        updated_edges = np.zeros((B,3), dtype=np.float64)
-        for b in range(B):
-            mask_val = zero_mask_num[b, i]
-            for k in range(3):
-                updated_edges[b,k] = (current_vertices[b, i+1, k]
-                                      - current_vertices[b, i, k]) * mask_val
-
-        # denominator = nominal_length_sq[:, i] + sum_of_squares
-        denominator = np.zeros(B, dtype=np.float64)
-        for b in range(B):
-            e_sum = 0.0
-            for k in range(3):
-                e_sum += updated_edges[b,k]*updated_edges[b,k]
-            denominator[b] = nominal_length_sq[b,i] + e_sum
-
-        # l-values, shape (B,)
-        l_vals = np.zeros(B, dtype=np.float64)
-        for b in range(B):
-            if zero_mask_num[b,i] != 0.0:
-                # 1 - 2*(L0^2)/denominator
-                l_vals[b] = 1.0 - 2.0*(nominal_length_sq[b,i]/denominator[b])
-
-        # If ALL abs(l) < tolerance => skip entire iteration
-        # (mimics: are_all_close_to_zero = torch.all(torch.abs(l)<tolerance))
-        all_small = True
-        for b in range(B):
-            if abs(l_vals[b]) >= tolerance:
-                all_small = False
-                break
-        if all_small:
-            continue
-
-        # Expand l into shape (2B,)
-        l_cat = np.zeros(2*B, dtype=np.float64)
-        for b in range(B):
-            val = l_vals[b]
-            l_cat[2*b]   = val
-            l_cat[2*b+1] = val
-
-        # Divide by scale[:, i] => also shape (2B,)
-        for s_idx in range(2*B):
-            l_cat[s_idx] /= scale[s_idx, i]
-
-        # Multiply each by mass_scale[:, i] => shape(2B, 3,3)
-        l_scale = np.zeros((2*B,3,3), dtype=np.float64)
-        for s_idx in range(2*B):
-            for r in range(3):
-                for c in range(3):
-                    l_scale[s_idx, r, c] = mass_scale[s_idx, i, r, c]*l_cat[s_idx]
-
-        # We must replicate updated_edges(b, :) -> 2 copies => big_edges(2B,3)
-        big_edges = np.zeros((2*B,3), dtype=np.float64)
-        for b in range(B):
-            for k in range(3):
-                val = updated_edges[b,k]
-                big_edges[2*b,   k] = val
-                big_edges[2*b+1, k] = val
-
-        # Matrix multiply l_scale[s_idx] (3x3) with big_edges[s_idx] (3,)
-        # => out (3,). Then store in result[s_idx, :]
-        result = np.zeros((2*B, 3), dtype=np.float64)
-        for s_idx in range(2*B):
-            for r in range(3):
-                accum = 0.0
-                for c in range(3):
-                    accum += l_scale[s_idx, r, c]*big_edges[s_idx, c]
-                result[s_idx, r] = accum
-
-        # Reshape (2B,3)->(B,2,3) so we can add into current_vertices
-        # exactly the same as your .view(-1,2,3) logic
-        for b in range(B):
-            # result row 2*b => parents i
-            # result row 2*b+1 => parents i+1
-            for k in range(3):
-                current_vertices[b, i,   k] += result[2*b,   k]
-                current_vertices[b, i+1, k] += result[2*b+1, k]
-
-    return current_vertices
-
-@njit
-def _numba_coupling_core(
-    p_vertices,        # shape (1, 13, 3) in your example
-    c_vertices,        # shape (2, 13, 3)
-    c_index,           # shape (2,) e.g. [4,8]
-    c_mass_scale       # shape (2,2,3,3)
-):
-    """
-    Replicates the arithmetic updates:
-      updated_edges = child_vertices[:, 0] - parent_vertices[:, coupling_index].view(-1, 3)
-      parent_vertices[:, coupling_index] += ...
-      child_vertices[:, 0] += ...
-    We do this in a Numba-friendly way.
-    """
-
-    # 1) Compute updated_edges = c_vertices[:,0] - p_vertices[:,c_index].view(-1,3)
-    #    c_vertices[:,0] is (2,3)
-    #    p_vertices[:,c_index] is (1,2,3), which we flatten -> shape(2,3).
-    # Numba cannot do "advanced indexing" the same way as PyTorch, so we do it manually.
-
-    # Let's gather p_vertices[:, c_index] => shape(1, len(c_index), 3).
-    # In your example, p_vertices.shape=(1,13,3), c_index=[4,8] => that's shape(1,2,3).
-    # We'll flatten that to (2,3).
-    k = c_index.shape[0]  # e.g. 2
-    # flatten parent slice
-    parent_slice = np.zeros((k, 3), dtype=np.float64)
-    for j in range(k):
-        idx = c_index[j]
-        # p_vertices[0, idx, :] => shape (3,) in your example
-        parent_slice[j,0] = p_vertices[0, idx, 0]
-        parent_slice[j,1] = p_vertices[0, idx, 1]
-        parent_slice[j,2] = p_vertices[0, idx, 2]
-
-    # child_vertices[:,0] => shape(2,3)
-    updated_edges = np.zeros((c_vertices.shape[0], 3), dtype=np.float64)
-    for row in range(c_vertices.shape[0]):
-        for col in range(3):
-            updated_edges[row,col] = c_vertices[row,0,col] - parent_slice[row,col]
-
-    # 2) l1 = c_mass_scale[:,0], l2 = c_mass_scale[:,1]
-    #    => shape(2,3,3) each
-    # We'll do matmul with updated_edges => shape(2,3,1)
-    # Then reshape => parent => (1,2,3), child => (2,3)
-    # We'll do it explicitly:
-
-    # parent update: l1 -> shape(2,3,3)
-    # multiply l1[row,:,:] with updated_edges[row,:] => shape(3,)
-    # result => shape(3,) => store in a small array => later we'll reshape to (1,2,3)
-
-    l1_out = np.zeros((c_vertices.shape[0],3), dtype=np.float64)
-    l2_out = np.zeros((c_vertices.shape[0],3), dtype=np.float64)
-    for row in range(c_vertices.shape[0]):
-        # matmul l1[row](3x3) * updated_edges[row](3,)
-        for r in range(3):
-            acc = 0.0
-            for c in range(3):
-                acc += c_mass_scale[row, 0, r, c]*updated_edges[row,c]
-            l1_out[row,r] = acc
-
-        # same for l2
-        for r in range(3):
-            acc = 0.0
-            for c in range(3):
-                acc += c_mass_scale[row, 1, r, c]*updated_edges[row,c]
-            l2_out[row,r] = acc
-
-    # l1_out => shape(2,3). In PyTorch we do .view(-1, len(coupling_index), 3) => (1,2,3)
-    # so we fold dimension 0=2 -> dimension [1,2], i.e. we want final shape(1,2,3).
-    # We'll do the same reorder: that means the first dimension becomes 1,
-    # and second dimension = k=2, third dimension=3.
-    # We'll just manually add to p_vertices[0, c_index[j], :] for j in [0..k-1].
-
-    # add to parent
-    for j in range(k):
-        p_vertices[0, c_index[j], 0] += l1_out[j,0]
-        p_vertices[0, c_index[j], 1] += l1_out[j,1]
-        p_vertices[0, c_index[j], 2] += l1_out[j,2]
-
-    # child update: l2_out => shape(2,3) => we add that to child_vertices[:,0]
-    for row in range(c_vertices.shape[0]):
-        for col in range(3):
-            c_vertices[row,0,col] += l2_out[row,col]
-
-    # done
-    return p_vertices, c_vertices
-
-"""rotation"""
-@njit
-def _quaternion_invert(q):
-    """
-    Inverse of a normalized quaternion q = (w, x, y, z).
-    """
-    return np.array([ q[0], -q[1], -q[2], -q[3]], dtype=np.float64)
-
-@njit
-def _quaternion_multiply(q1, q2):
-    """
-    Hamilton product of two quaternions q1 * q2.
-    q1,q2: shape(4,) => [w, x, y, z].
-    """
-    w1, x1, y1, z1 = q1
-    w2, x2, y2, z2 = q2
-    return np.array([
-        w1*w2 - x1*x2 - y1*y2 - z1*z2,
-        w1*x2 + x1*w2 + y1*z2 - z1*y2,
-        w1*y2 - x1*z2 + y1*w2 + z1*x2,
-        w1*z2 + x1*y2 - y1*x2 + z1*w2
-    ], dtype=np.float64)
-
-@njit
-def _quaternion_norm(q):
-    return np.sqrt(q[0]*q[0] + q[1]*q[1] + q[2]*q[2] + q[3]*q[3])
-
-@njit
-def _quaternion_apply(q, v):
-    """
-    Rotate 3D vector v by quaternion q (assumed normalized).
-    Returns the rotated vector.
-    Formula: v' = v + 2 * cross(q.xyz, cross(q.xyz, v) + q.w*v)
-    """
-    w, x, y, z = q
-    cx = y*v[2] - z*v[1]
-    cy = z*v[0] - x*v[2]
-    cz = x*v[1] - y*v[0]
-
-    rx = cx + w*v[0]
-    ry = cy + w*v[1]
-    rz = cz + w*v[2]
-
-    c2x = y*rz - z*ry
-    c2y = z*rx - x*rz
-    c2z = x*ry - y*rx
-
-    return np.array([v[0] + 2*c2x,
-                     v[1] + 2*c2y,
-                     v[2] + 2*c2z], dtype=np.float64)
-
-
-@njit
-def _axis_angle_to_quaternion(axis_angle):
-    """
-    Convert a 3D axis-angle vector (axis * angle) of shape (3,)
-    back to a quaternion [w, x, y, z].
-
-    The length of axis_angle is the rotation angle,
-    and its direction is the rotation axis.
-    """
-    eps = 1e-30
-    rx, ry, rz = axis_angle
-    theta = np.sqrt(rx * rx + ry * ry + rz * rz)
-    if theta < eps:
-        # angle ~ 0 => return identity quaternion
-        return np.array([1.0, 0.0, 0.0, 0.0], dtype=np.float64)
-
-    half = 0.5 * theta
-    sin_ = np.sin(half)
-    cos_ = np.cos(half)
-
-    # normalized axis
-    ux = rx / theta
-    uy = ry / theta
-    uz = rz / theta
-
-    # quaternion = [cos(half), sin(half)*axis]
-    return np.array([cos_, ux * sin_, uy * sin_, uz * sin_], dtype=np.float64)
-
-
-@njit
-def _quaternion_to_axis_angle(q):
-    """
-    Convert quaternion `q` => a 3D axis-angle vector of shape (3,).
-    The magnitude of the returned vector = angle in radians,
-    and the direction is the rotation axis.
-
-    If angle is near zero, returns [0,0,0].
-    """
-    # Normalize q just in case
-    eps = 1e-30
-    norm_q = np.sqrt(q[0] * q[0] + q[1] * q[1] + q[2] * q[2] + q[3] * q[3])
-    if norm_q < eps:
-        # Degenerate quaternion => no rotation
-        return np.zeros(3, dtype=np.float64)
-
-    w = q[0] / norm_q
-    x = q[1] / norm_q
-    y = q[2] / norm_q
-    z = q[3] / norm_q
-
-    angle = 2.0 * np.arccos(w)
-    s = np.sqrt(1.0 - w * w)
-
-    if s < eps:
-        # angle ~ 0 => axis can be anything, so we choose (0,0,0) as "no rotation"
-        return np.zeros(3, dtype=np.float64)
-
-    # unit axis
-    ux = x / s
-    uy = y / s
-    uz = z / s
-    # return the axis * angle
-    return np.array([angle * ux, angle * uy, angle * uz], dtype=np.float64)
-
-@njit
-def _rotation_matrix_from_vectors(v1, v2):
-    """
-    Rotate v1 -> v2.
-    Return a 3x3 rotation matrix using a standard cross/dot-based formula.
-    If v1 or v2 is near 0-length or they are antiparallel, handle it with fallback.
-    """
-    eps = 1e-30
-    norm1 = np.sqrt(np.sum(v1*v1))
-    norm2 = np.sqrt(np.sum(v2*v2))
-    if norm1<eps or norm2<eps:
-        # no rotation
-        return np.eye(3, dtype=np.float64)
-    a = v1 / norm1
-    b = v2 / norm2
-    cross_ = np.array([a[1]*b[2] - a[2]*b[1],
-                       a[2]*b[0] - a[0]*b[2],
-                       a[0]*b[1] - a[1]*b[0]], dtype=np.float64)
-    dot_ = a[0]*b[0] + a[1]*b[1] + a[2]*b[2]
-    s = np.sqrt(np.sum(cross_*cross_))
-
-    eye = np.eye(3, dtype=np.float64)
-    if s<1e-30:
-        # parallel or antiparallel
-        if dot_>0:
-            # parallel => identity
-            return eye
-        else:
-            # 180 deg => find axis
-            # pick any perpendicular
-            axis = np.array([1.0,0.0,0.0], dtype=np.float64)
-            if np.abs(a[0])>0.9:
-                axis = np.array([0.0,1.0,0.0], dtype=np.float64)
-            perp = np.array([a[1]*axis[2] - a[2]*axis[1],
-                             a[2]*axis[0] - a[0]*axis[2],
-                             a[0]*axis[1] - a[1]*axis[0]], dtype=np.float64)
-            normp = np.sqrt(np.sum(perp*perp))
-            if normp<1e-30:
-                return eye
-            perp/=normp
-            # R = I + 2*K^2
-            K = np.zeros((3,3), dtype=np.float64)
-            K[0,1] = -perp[2]
-            K[0,2] =  perp[1]
-            K[1,0] =  perp[2]
-            K[1,2] = -perp[0]
-            K[2,0] = -perp[1]
-            K[2,1] =  perp[0]
-            return eye + 2.0*(K @ K)
-    # general Rodrigues
-    K = np.zeros((3,3), dtype=np.float64)
-    K[0,1] = -cross_[2]
-    K[0,2] =  cross_[1]
-    K[1,0] =  cross_[2]
-    K[1,2] = -cross_[0]
-    K[2,0] = -cross_[1]
-    K[2,1] =  cross_[0]
-
-    return eye + K + (K @ K)*((1.0 - dot_)/(s*s))
-
-@njit
-def _matrix_to_quaternion(mat):
-    """
-    Convert 3x3 rotation matrix to quaternion (w, x, y, z).
-    """
-    tr = mat[0,0] + mat[1,1] + mat[2,2]
-    if tr > 0.0:
-        S = np.sqrt(tr + 1.0)*2
-        qw = 0.25*S
-        qx = (mat[2,1] - mat[1,2])/S
-        qy = (mat[0,2] - mat[2,0])/S
-        qz = (mat[1,0] - mat[0,1])/S
-    else:
-        if (mat[0,0] > mat[1,1]) and (mat[0,0] > mat[2,2]):
-            S = np.sqrt(1.0 + mat[0,0] - mat[1,1] - mat[2,2])*2
-            qw = (mat[2,1] - mat[1,2])/S
-            qx = 0.25*S
-            qy = (mat[0,1] + mat[1,0])/S
-            qz = (mat[0,2] + mat[2,0])/S
-        elif mat[1,1] > mat[2,2]:
-            S = np.sqrt(1.0 + mat[1,1] - mat[0,0] - mat[2,2])*2
-            qw = (mat[0,2] - mat[2,0])/S
-            qx = (mat[0,1] + mat[1,0])/S
-            qy = 0.25*S
-            qz = (mat[1,2] + mat[2,1])/S
-        else:
-            S = np.sqrt(1.0 + mat[2,2] - mat[0,0] - mat[1,1])*2
-            qw = (mat[1,0] - mat[0,1])/S
-            qx = (mat[0,2] + mat[2,0])/S
-            qy = (mat[1,2] + mat[2,1])/S
-            qz = 0.25*S
-    return np.array([qw, qx, qy, qz], dtype=np.float64)
-
-###############################################################################
-# 2) Subfunction: _numba_apply_rotation_moi(...)
-###############################################################################
-
-@njit
-def _numba_apply_rotation_moi(
-    parent_rod_vertices,   # shape (B, 2*n_children, 3)
-    child_rod_vertices,    # shape (B, 2*n_children, 3)
-    q1_array,              # shape (B*n_children, 4) or similar
-    q2_array,              # shape (B*n_children, 4) or similar
-    big_mscale,            # shape (B*n_children, 3, 3) -> momentum_scale
-    B,
-    total_rc
-):
-    """
-    Numba-accelerated version of the PyTorch apply_rotation_test.
-    Returns:
-       out_r   -> for example, updated rod vertices (could combine parent+child)
-       out_q1  -> updated orientation of parent
-       out_q2  -> updated orientation of child
-    """
-
-    # Number of "pairs" we are dealing with
-    N = B * total_rc # e.g. the flatten dimension for q1_array, q2_array, etc.
-    # 1) Compute updated quaternion = q1 * invert(q2)
-    # We'll store them in updated_q
-    updated_q = np.zeros((N, 4), dtype=q1_array.dtype)
-    for i in range(N):
-        inv_q2 = _quaternion_invert(q2_array[i])
-        updated_q[i] = _quaternion_multiply(q1_array[i], inv_q2)
-
-    # 2) Convert updated_q to axis_angle
-    delta_angular = np.zeros((N, 3), dtype=q1_array.dtype)
-    for i in range(N):
-        delta_angular[i] = _quaternion_to_axis_angle(updated_q[i])
-
-    # 3) Multiply delta_angular by big_mscale ( = momentum_scale ).
-    #    i.e. for each i, do big_mscale[i,:,:] dot delta_angular[i].
-    delta_angular_rod = np.zeros((N*2, 3), dtype=q1_array.dtype)
-    for i in range(N*2):
-        # shape is (3,) = (3x3) dot (3,)
-        mm = big_mscale[i]
-        da = delta_angular[i//N]
-        delta_angular_rod[i,0] = mm[0,0]*da[0] + mm[0,1]*da[1] + mm[0,2]*da[2]
-        delta_angular_rod[i,1] = mm[1,0]*da[0] + mm[1,1]*da[1] + mm[1,2]*da[2]
-        delta_angular_rod[i,2] = mm[2,0]*da[0] + mm[2,1]*da[1] + mm[2,2]*da[2]
-    # 4) axis_angle -> quaternion
-    #    Then we'll interpret that as 2 rods (?), so shape (N, 2, 4) in the torch code
-    #    but here we just keep it as something we can multiply with q1/q2
-    #    We'll mimic the same shape logic.
-    angular_change_q_rod = np.zeros((N, 2, 4), dtype=q1_array.dtype)
-    index = 0
-    for i in range(N):
-        # We assume we have 2 rods per "slot", or parent/child rods
-        # Typically in the original code it was "view(-1, 2, 4)"
-        # We'll do the same, so each i -> [0,4], [1,4].
-        # In the original code its a direct reshape, but let's fill them:
-        # Usually the same delta_angular_rod is used for both rods, so we
-        # produce the same quaternion for "slot=0" and "slot=1"
-        for j in range(2):
-            dq = _axis_angle_to_quaternion(delta_angular_rod[index])
-            angular_change_q_rod[i,j] = dq
-            index += 1
-    # 5) Multiply angular_change_q_rod * (concatenated q1,q2).
-    #    In the original code: orientation = quaternion_multiply(...).view(N, 2, 4)
-    #    Then orientation[:,0], orientation[:,1] => rod_orientation1, rod_orientation2
-    out_q1 = np.zeros((N, 4), dtype=q1_array.dtype)
-    out_q2 = np.zeros((N, 4), dtype=q1_array.dtype)
-    for i in range(N):
-        # "edge_q" was cat(q1, q2). We'll just do them separately:
-        # rod_orientation1 = angular_change_q_rod[i,0] * q1_array[i]
-        # rod_orientation2 = angular_change_q_rod[i,1] * q2_array[i]
-        # or you can do the original approach if needed.
-        # The original code did:
-        #   orientation = quaternion_multiply( angular_change_q_rod, edge_q )
-        #   => but for clarity we handle parent vs child separately:
-        out_q1[i] = _quaternion_multiply(angular_change_q_rod[i,0], q1_array[i])
-        out_q2[i] = _quaternion_multiply(angular_change_q_rod[i,1], q2_array[i])
-    # 6) Now do the rod vertices transformations.
-    #    Original code: rods_vertices1/2 -> shape (B, n_children, 2, 3)
-    #    We have shape (B, 2*n_children, 3). We'll reshape to (B, n_children, 2, 3).
-    #    Then stack parent/child, subtract origin, rotate, add origin back, etc.
-
-    # Reshape to (B, total_rc, 2, 3)
-    # total_rc = n_children, so 2*n_children = parent_rod_vertices.shape[1]
-    parent_rod_vertices_4d = parent_rod_vertices.reshape(B, total_rc, 2, 3)
-    child_rod_vertices_4d  = child_rod_vertices.reshape(B, total_rc, 2, 3)
-
-    # For demonstration, let's combine them [ parent, child ] along a new "rod index" dimension
-    # shape => (B, total_rc, 2 rods, 2 vertices, 3)
-    # (like torch.stack([rods_vertices1, rods_vertices2], dim=2))
-    combined_rod_verts = np.zeros((B, total_rc, 2, 2, 3), dtype=parent_rod_vertices.dtype)
-    for b in range(B):
-        for rc in range(total_rc):
-            # rod0 = parent, rod1 = child
-            for v in range(2):  # vertex index
-                combined_rod_verts[b, rc, 0, v] = parent_rod_vertices_4d[b, rc, v]
-                combined_rod_verts[b, rc, 1, v] = child_rod_vertices_4d[b, rc, v]
-
-    # rod_vertices_origin => the "first vertex" as an origin
-    # shape (B, total_rc, 2, 1, 3)
-    # We can just do it in a loop
-    rods_vertices_out = np.zeros_like(combined_rod_verts)
-    for b in range(B):
-        for rc in range(total_rc):
-            for rod_idx in range(2):
-                origin = combined_rod_verts[b, rc, rod_idx, 0].copy()  # shape (3,)
-                # subtract origin from both vertices
-                shifted = np.zeros((2,3), dtype=origin.dtype)
-                for v in range(2):
-                    shifted[v] = combined_rod_verts[b, rc, rod_idx, v] - origin
-                # get the quaternion that rotates this rod:
-                # we need the angular_change_q_rod that corresponds to this (b, rc)
-                # index in the flattened sense is i = b*total_rc + rc
-                i = b*total_rc + rc
-                q_rot = angular_change_q_rod[i, rod_idx]  # shape (4,)
-
-                # rotate each vertex about origin
-                rotated = np.zeros((2,3), dtype=origin.dtype)
-                for v in range(2):
-                    rotated[v] = _quaternion_apply(q_rot, shifted[v])
-                # add origin back
-                for v in range(2):
-                    rods_vertices_out[b, rc, rod_idx, v] = rotated[v] + origin
-
-    # Now rods_vertices_out has shape (B, total_rc, 2 rods, 2 vertices, 3).
-    # If you want it in the shape (B, 2*total_rc, 3) per rod, you can separate them:
-    updated_parent = np.zeros((B, 2*total_rc, 3), dtype=parent_rod_vertices.dtype)
-    updated_child  = np.zeros((B, 2*total_rc, 3), dtype=parent_rod_vertices.dtype)
-    for b in range(B):
-        for rc in range(total_rc):
-            # rod0 => parent, rod1 => child
-            # each rod has 2 vertices
-            updated_parent[b, rc*2+0] = rods_vertices_out[b, rc, 0, 0]
-            updated_parent[b, rc*2+1] = rods_vertices_out[b, rc, 0, 1]
-            updated_child[b, rc*2+0]  = rods_vertices_out[b, rc, 1, 0]
-            updated_child[b, rc*2+1]  = rods_vertices_out[b, rc, 1, 1]
-
-    # Decide how you want to combine them for the final out_r, or keep them separate.
-    # For example, let's just return the updated_parent for "out_r".
-    # Adjust to your needs:
-    return updated_parent, updated_child, out_q1, out_q2
-
-###############################################################################
-# 3) Main function:
-#    _numba_rotation_constraints_enforcement_parent_children(...)
-###############################################################################
-
-@njit
-def _numba_rotation_constraints_enforcement_parent_children(
-    parent_vertices,       # shape (1, 13, 3)
-    parent_orientations,   # shape (1, 12, 4)
-    prev_parent_vertices,  # shape (1, 13, 3)
-    children_vertices,     # shape (1, 2, 13, 3)
-    children_orientations, # shape (1, 2, 4)
-    prev_children_vertices,# shape (1, 2, 13, 3)
-    parent_MOIs,           # shape (4,3,3)
-    children_MOIs,         # shape (2,3,3)
-    index_selection,       # shape(2,) e.g. [3,7]
-    parent_MOI_index,      # shape(2,) e.g. [0,2]
-    momentum_scale,        # shape(4,3,3) or bigger
-    tolerance=5e-3,
-    big_scale=10.0
-):
-    B = parent_vertices.shape[0]  # should be 1
-    C = children_vertices.shape[1]  # 2 child rods
-    k = index_selection.shape[0]    # 2 rods in parent
-
-    # 1) Build [previous_edges + current_edges] => shape( (k+C)*B, 3 )
-    # We'll do single-batch loops.
-    total_rows = B*k + B*C  # e.g. 1*(2) + 1*(2) = 4
-    previous_edges = np.zeros((total_rows, 3), dtype=np.float64)
-    current_edges  = np.zeros((total_rows, 3), dtype=np.float64)
-
-    row_count = 0
-    # fill from parent's rods
-    for b in range(B):
-        for i in range(k):
-            idx = index_selection[i]
-            for r in range(3):
-                previous_edges[row_count,r] = (prev_parent_vertices[b, idx+1, r]
-                                               - prev_parent_vertices[b, idx, r])
-                current_edges[row_count,r]  = (parent_vertices[b, idx+1, r]
-                                               - parent_vertices[b, idx, r])
-            row_count += 1
-    # fill from children rods
-    for b in range(B):
-        for c_i in range(C):
-            for r in range(3):
-                previous_edges[row_count,r] = (prev_children_vertices[b, c_i, 1, r]
-                                               - prev_children_vertices[b, c_i, 0, r])
-                current_edges[row_count,r]  = (children_vertices[b, c_i, 1, r]
-                                               - children_vertices[b, c_i, 0, r])
-            row_count += 1
-
-    # 2) gather old orientations => shape( (k+C)*B, 4 )
-    all_orient = np.zeros((total_rows, 4), dtype=np.float64)
-    row_count = 0
-    for b in range(B):
-        # parent's rods
-        for i in range(k):
-            idx = index_selection[i]
-            for r in range(4):
-                all_orient[row_count, r] = parent_orientations[b, idx, r]
-            row_count += 1
-        # children's rods
-        for c_i in range(C):
-            for r in range(4):
-                all_orient[row_count, r] = children_orientations[b, c_i, r]
-            row_count += 1
-
-    # 3) compute quaternions from previous->current
-    quaternions = np.zeros((total_rows, 4), dtype=np.float64)
-    for i in range(total_rows):
-        p_ed = previous_edges[i]
-        c_ed = current_edges[i]
-        # norm_p = np.sqrt(np.sum(p_ed*p_ed))
-        # norm_c = np.sqrt(np.sum(c_ed*c_ed))
-        # if norm_p<1e-12 or norm_c<1e-12:
-        #     quaternions[i,0] = 1.0
-        #     continue
-        rot_mat = _rotation_matrix_from_vectors(p_ed, c_ed)
-        q_ = _matrix_to_quaternion(rot_mat)
-        quaternions[i] = q_
-
-
-    # 5) multiply onto old orientation => new_orient
-    new_orient = np.zeros_like(all_orient)
-    for i in range(total_rows):
-        new_orient[i] = _quaternion_multiply(quaternions[i], all_orient[i])
-
-    # write back
-    row_count = 0
-    for b in range(B):
-        for i in range(k):
-            idx = index_selection[i]
-            for r in range(4):
-                parent_orientations[b, idx, r] = new_orient[row_count,r]
-            row_count += 1
-        for c_i in range(C):
-            for r in range(4):
-                children_orientations[b, c_i, r] = new_orient[row_count,r]
-            row_count += 1
-
-    # 6) gather rods for "apply_rotation(...)"
-    #    -> In your code:
-    #       parent_desired_order = [i, i+1 for i in index_selection]
-    #       parent_rod_vertices = parent_vertices[:, parent_desired_order]
-    # We'll replicate that logic for the parent. For the child, we do 0..1.
-
-    parent_desired_order = []
-    for i in range(k):     # e.g. 2 rods
-        idx = index_selection[i]
-        parent_desired_order.append(idx)
-        parent_desired_order.append(idx+1)
-    parent_desired_order = np.array(parent_desired_order, dtype=np.int64)  # shape(2*k,)
-
-    # shape(1, 2*k, 3)
-    parent_rod_vertices = np.zeros((B, 2*k, 3), dtype=np.float64)
-    for b in range(B):
-        for jj in range(2*k):
-            vidx = parent_desired_order[jj]
-            for r in range(3):
-                parent_rod_vertices[b,jj,r] = parent_vertices[b,vidx,r]
-
-    # child_rod_vertices => shape(1, 2*C, 3) if we flatten rods
-    child_rod_vertices = np.zeros((B, 2*C, 3), dtype=np.float64)
-    for b in range(B):
-        for c_i in range(C):
-            for v_idx in range(2):
-                for r in range(3):
-                    child_rod_vertices[b, c_i*2+v_idx, r] = children_vertices[b, c_i, v_idx, r]
-
-    # Next, gather parent's orientation for these rods => shape(1, k,4)
-    # children_orient => shape(1, C,4).
-    parent_sel_orient = np.zeros((B,k,4), dtype=np.float64)
-    for b in range(B):
-        for i in range(k):
-            idx = index_selection[i]
-            for r in range(4):
-                parent_sel_orient[b,i,r] = parent_orientations[b, idx, r]
-    # child_orient is just children_orientations[b,c_i], shape(1,2,4).
-
-    # We'll flatten them so we can pass them to _numba_apply_rotation_moi in one pass.
-    total_rc = k  # e.g. 2 + 2 = 4 rods total
-    q1_array = np.zeros((B*total_rc, 4), dtype=np.float64)
-    row_count = 0
-    for b in range(B):
-        for i in range(k):
-            for r in range(4):
-                q1_array[row_count,r] = parent_sel_orient[b,i,r]
-            row_count += 1
-    # We'll let q2_array be identity
-    q2_array = np.zeros((B*total_rc, 4), dtype=np.float64)
-    row_count = 0
-    for b in range(B):
-        for c_i in range(C):
-            for r in range(4):
-                q2_array[row_count, r] = children_orientations[b, c_i, r]
-            row_count += 1
-
-
-    # rods_vertices => shape(1, (k+C), 2, 3).
-    # We have parent_rod_vertices => shape(1, 2*k,3) => that is k rods of 2 vertices each
-    # child_rod_vertices => shape(1, 2*C,3) => that is C rods
-
-
-    # Build is_parent_mask => shape (k+C,)
-    # first k rods => True, next C rods => False
-    is_parent_mask = np.zeros(k+C, dtype=np.bool_)
-    for i in range(k):
-        is_parent_mask[i] = True
-    # moi_idx_array => e.g. for parent rods, we use parent_MOI_index[i]; for child rods, we use c_i
-    moi_idx_array = np.zeros(k, dtype=np.int64)
-    for i in range(k):
-        moi_idx_array[i] = parent_MOI_index[i]
-
-    # momentum_scale => shape(4,3,3) => broadcast to (B*total_rc,3,3)
-    ms_shape_0 = momentum_scale.shape[0]  # e.g. 4
-    big_mscale = np.zeros((B*total_rc*2,3,3), dtype=np.float64)
-    for i in range(B*total_rc*2):
-        big_mscale[i] = momentum_scale[i % ms_shape_0]
-
-    # 7) call the subfunction
-    # print("parent_rod_vertices ", parent_rod_vertices)
-    # print("child_rod_vertices ", child_rod_vertices)
-    # print("q1_array ", q1_array)
-    # print("q2_array", q2_array)
-    # print("big_mscale ", big_mscale)
-    out_p, out_c, out_q1, out_q2 = _numba_apply_rotation_moi(
-        parent_rod_vertices,
-        child_rod_vertices,
-        q1_array,
-        q2_array,
-        big_mscale,
-        B,
-        total_rc
-    )
-    # print("out_p")
-    # print(out_p)
-    # print(out_c)
-    # print(out_q1.shape)
-    # print(out_q2.shape)
-    # print(parent_vertices.shape)
-    # print(children_vertices.shape)
-    # raise Exception('Stop here')
-
-    # 8) write back rods => parent_vertices, children_vertices
-    # parent rods => out_r[b, i], i in [0..k-1]
-    # print("out_q1.shape", out_q1.shape)
-    for b in range(B):
-        for i in range(k):
-            idx = index_selection[i]
-            parent_vertices[b, idx]   = out_p[b, i*k]
-            parent_vertices[b, idx+1] = out_p[b, i*k+1]
-            parent_orientations[b, idx]   = out_q1[i]
-
-        for c_i in range(C):
-            children_vertices[b, c_i, 0] = out_c[b, c_i*C]
-            children_vertices[b, c_i, 1] = out_c[b, c_i*C+1]
-    # print("parent_orientations ", parent_orientations)
-    # If you also want to store out_q1 => parent_orientations or children_orientations,
-    # parse them out similarly.
-    # We skip for brevity.
-
-    return (parent_vertices, parent_orientations,
-            children_vertices, out_q2)
-
-
-class constraints_enforcement_numba(nn.Module):
-    def __init__(self):
-        super().__init__()
-        self.tolerance = 5e-3
-        self.scale = 10.0
-
-
-    def Inextensibility_Constraint_Enforcement(
-            self, batch, current_vertices, nominal_length,
-             scale, mass_scale, zero_mask_num
-    ):
-        """
-        Drop-in for your PyTorch method.
-        We'll do the bridging in/out + call the Numba function.
-        """
-
-        cv_np = current_vertices
-        nl_np = nominal_length
-        sc_np = scale
-        ms_np = mass_scale
-        zm_np = zero_mask_num.detach().cpu().numpy()
-        out_np = _numba_inextensibility_constraint_enforcement(
-            cv_np, nl_np, sc_np, ms_np, zm_np,
-            self.tolerance
-        )
-        # out_torch = torch.from_numpy(out_np).to(device)
-        return out_np
-
-    def Inextensibility_Constraint_Enforcement_Coupling(
-            self,
-            parent_vertices,  # shape (1,13,3)
-            child_vertices,  # shape (2,13,3)
-            coupling_index,  # e.g. [4,8]
-            coupling_mass_scale,  # shape (2,2,3,3)
-            selected_parent_index,  # e.g. [0]
-            selected_children_index  # e.g. [1,2]
-    ):
-
-
-        # Convert to CPU numpy
-        p_np = parent_vertices
-        c_np = child_vertices
-
-        # coupling_index might be Python list => make int64 array
-        if isinstance(coupling_index, (list, tuple)):
-            ci_np = np.array(coupling_index, dtype=np.int64)
-        else:
-            ci_np = coupling_index
-
-        cms_np = coupling_mass_scale
-
-        # 1) Call the Numba core
-        p_upd, c_upd = _numba_coupling_core(p_np, c_np, ci_np, cms_np)
-
-        # 2) Rebuild b_DLOs_vertices as in your PyTorch code:
-        #    shape = (len(selected_parent_index)+ len(selected_children_index),
-        #             parent_vertices.size(1), 3)
-        out_size = len(selected_parent_index) + len(selected_children_index)
-        n_verts = p_upd.shape[1]  # = 13
-        out_np = np.empty((out_size, n_verts, 3), dtype=np.float64)
-
-        # For convenience, assume selected_parent_index is e.g. [0] => we copy the
-        # updated parent rods to out_np[0].
-        for i, idx in enumerate(selected_parent_index):
-            out_np[idx] = p_upd[i]  # i=0 => p_upd[0], shape(13,3)
-
-        # Similarly for child rods
-        for i, idx in enumerate(selected_children_index):
-            out_np[idx] = c_upd[i]  # c_upd[i], shape(13,3)
-
-        # Convert back to torch
-        # b_DLOs_vertices = torch.from_numpy(out_np).to(device=device, dtype=dtype)
-        return out_np
-
-    def Rotation_Constraints_Enforcement_Parent_Children(
-            self,
-            parent_vertices,
-            parent_rod_orientation,
-            previous_parent_vertices,
-            children_vertices,
-            children_rod_orientation,
-            previous_children_vertices,
-            parent_MOI_matrix,
-            children_MOI_matrix,
-            rigid_body_coupling_index,
-            parent_MOI_index,
-            momentum_scale
-    ):
-
-
-        # 1) convert to NumPy
-        pv_np = parent_vertices
-        pro_np = parent_rod_orientation
-        ppv_np = previous_parent_vertices
-        cv_np = children_vertices
-        cro_np = children_rod_orientation
-        pcv_np = previous_children_vertices
-        pMOI_np = parent_MOI_matrix
-        cMOI_np = children_MOI_matrix
-        if isinstance(rigid_body_coupling_index, (list, tuple)):
-            rci_np = np.array(rigid_body_coupling_index, dtype=np.int64)
-        else:
-            rci_np = rigid_body_coupling_index
-
-        if isinstance(parent_MOI_index, (list, tuple)):
-            pmi_np = np.array(parent_MOI_index, dtype=np.int64)
-        else:
-            pmi_np = parent_MOI_index
-
-        ms_np = momentum_scale
-
-        # 2) call the numba core
-        # print("pv_np", pv_np)
-        # print(pro_np)
-        # print("ppv_np", ppv_np)
-        # print(pv_np)
-        # print(rci_np)
-        # print(pmi_np)
-        out_pv, out_pro, out_cv, out_cro = _numba_rotation_constraints_enforcement_parent_children(
-            pv_np, pro_np, ppv_np,
-            cv_np, cro_np, pcv_np,
-            pMOI_np, cMOI_np,
-            rci_np, pmi_np, ms_np,
-            tolerance=self.tolerance,
-            big_scale=self.scale
-        )
-
-        # 3) convert back
-        # out_pv = torch.from_numpy(out_pv)
-        # out_pro_torch = torch.from_numpy(out_pro).to(device=device, dtype=dtype)
-        # out_cv = torch.from_numpy(out_cv)
-        # out_cro_torch = torch.from_numpy(out_cro).to(device=device, dtype=dtype)
-
-        return out_pv, out_pro, out_cv, np.expand_dims(out_cro, axis=0)
diff --git a/constraints_solver.py b/constraints_solver.py
deleted file mode 100644
index 2d76702..0000000
--- a/constraints_solver.py
+++ /dev/null
@@ -1,516 +0,0 @@
-import time
-from itertools import repeat, permutations
-
-import torch
-import pytorch3d
-import pytorch3d.transforms.rotation_conversions
-from click.core import batch
-from numpy.core.defchararray import lower
-
-torch.set_default_dtype(torch.float64)
-import torch.nn as nn
-
-torch.set_default_dtype(torch.float64)
-
-
-class constraints_enforcement(nn.Module):
-    """
-    A class that enforces various geometric constraints (inextensibility, rotation, coupling)
-    on discrete linkage objects (DLOs) or 'rods'. Inherits from PyTorch's nn.Module
-    to integrate with common PyTorch workflows.
-
-    Args:
-        n_branch (int): Number of 'branches' or rods in the system (if relevant).
-    """
-
-    def __init__(self, n_branch):
-        super().__init__()
-        self.tolerance = 5e-3  # Tolerance threshold for checking small angles or lengths
-        self.scale = 10.  # A scaling factor used in some constraints
-
-    def rotation_matrix_from_vectors(self, vec1, vec2):
-        """
-        Computes the rotation matrix that rotates vec1 into vec2 for each batch/branch in the input.
-
-        Args:
-            vec1 (torch.Tensor): Tensor of shape (batch, n_branch, 3) - initial vectors.
-            vec2 (torch.Tensor): Tensor of shape (batch, n_branch, 3) - target vectors.
-
-        Returns:
-            rotation_matrix (torch.Tensor): Shape (batch, n_branch, 3, 3),
-                                            the rotation matrices for each pair (vec1, vec2).
-        """
-        # 1) Normalize vec1 and vec2
-        a = vec1 / torch.norm(vec1, dim=-1, keepdim=True)
-        b = vec2 / torch.norm(vec2, dim=-1, keepdim=True)
-
-        # 2) Cross product (axis of rotation) and dot product (cosine of angle)
-        v = torch.cross(a, b, dim=-1)
-        c = torch.sum(a * b, dim=-1, keepdim=True)
-        s = torch.norm(v, dim=-1, keepdim=True)  # Sine of angle is magnitude of cross product
-
-        # 3) Build skew-symmetric cross-product matrix 'kmat' for each element
-        kmat = torch.zeros((vec1.shape[0], vec1.shape[1], 3, 3), dtype=torch.float64)
-        kmat[:, :, 0, 1] = -v[:, :, 2]
-        kmat[:, :, 0, 2] = v[:, :, 1]
-        kmat[:, :, 1, 0] = v[:, :, 2]
-        kmat[:, :, 1, 2] = -v[:, :, 0]
-        kmat[:, :, 2, 0] = -v[:, :, 1]
-        kmat[:, :, 2, 1] = v[:, :, 0]
-
-        # 4) Create identity matrix
-        eye = torch.eye(3, dtype=torch.float64).unsqueeze(0).unsqueeze(0).repeat(vec1.shape[0], vec1.shape[1], 1, 1)
-
-        # 5) Rodrigues' rotation formula: R = I + [k] + [k]^2 * ((1 - c) / s^2)
-        rotation_matrix = eye + kmat + torch.matmul(kmat, kmat) * ((1 - c) / (s ** 2)).unsqueeze(-1)
-
-        # 6) Handle near-zero 's' (parallel or anti-parallel vectors)
-        s_zero = (s < 1e-30).squeeze(-1)  # bool mask for s ~ 0
-        c_positive = (c > 0).squeeze(-1)  # parallel
-        c_negative = (c < 0).squeeze(-1)  # anti-parallel
-
-        # Expand for broadcasting
-        s_zero_expanded = s_zero.unsqueeze(-1).unsqueeze(-1).expand_as(eye)
-        c_positive_expanded = c_positive.unsqueeze(-1).unsqueeze(-1).expand_as(eye)
-
-        # 7) If vectors are parallel (s=0, c>0), use Identity
-        rotation_matrix = torch.where(s_zero_expanded & c_positive_expanded, eye, rotation_matrix)
-
-        # 8) Anti-parallel vectors (s=0, c<0): rotate 180 degrees around any perpendicular axis
-        for batch in range(vec1.shape[0]):
-            for branch in range(vec1.shape[1]):
-                if s_zero[batch, branch] and c_negative[batch, branch]:
-                    # Choose a fallback axis for cross product
-                    axis = torch.tensor([1.0, 0.0, 0.0], dtype=torch.float64)
-                    if torch.allclose(a[batch, branch], axis):
-                        axis = torch.tensor([0.0, 1.0, 0.0], dtype=torch.float64)
-                    # Perpendicular axis to 'a'
-                    perp_axis = torch.cross(a[batch, branch], axis)
-                    perp_axis = perp_axis / torch.norm(perp_axis)
-
-                    # Construct 180-degree rotation matrix around 'perp_axis'
-                    kmat_180 = torch.zeros(3, 3, dtype=torch.float64)
-                    kmat_180[0, 1] = -perp_axis[2]
-                    kmat_180[0, 2] = perp_axis[1]
-                    kmat_180[1, 0] = perp_axis[2]
-                    kmat_180[1, 2] = -perp_axis[0]
-                    kmat_180[2, 0] = -perp_axis[1]
-                    kmat_180[2, 1] = perp_axis[0]
-                    # R = I + 2 * kmat_180^2
-                    rotation_matrix[batch, branch] = eye[batch, branch] + 2 * torch.matmul(kmat_180, kmat_180)
-
-        return rotation_matrix
-
-    def rotation_matrix_from_vectors_lowerdim(self, vec1, vec2):
-        """
-        Similar to rotation_matrix_from_vectors, but designed for fewer dimensions
-        (batch dimension only, no 'branch' dimension).
-        Used for a simpler scenario: shape (batch, 3) for vec1/vec2.
-
-        Args:
-            vec1 (torch.Tensor): Shape (batch, 3)
-            vec2 (torch.Tensor): Shape (batch, 3)
-
-        Returns:
-            rotation_matrix (torch.Tensor): Shape (batch, 3, 3)
-        """
-        # 1) Normalize inputs
-        a = vec1 / torch.norm(vec1, dim=-1, keepdim=True)
-        b = vec2 / torch.norm(vec2, dim=-1, keepdim=True)
-
-        # 2) Cross product & dot product
-        v = torch.cross(a, b, dim=-1)
-        c = torch.sum(a * b, dim=-1, keepdim=True)
-        s = torch.norm(v, dim=-1, keepdim=True)
-
-        # 3) Skew-symmetric cross matrix
-        kmat = torch.zeros((vec1.shape[0], 3, 3), dtype=torch.float64)
-        kmat[:, 0, 1] = -v[:, 2]
-        kmat[:, 0, 2] = v[:, 1]
-        kmat[:, 1, 0] = v[:, 2]
-        kmat[:, 1, 2] = -v[:, 0]
-        kmat[:, 2, 0] = -v[:, 1]
-        kmat[:, 2, 1] = v[:, 0]
-
-        # 4) Identity matrix
-        eye = torch.eye(3, dtype=torch.float64).unsqueeze(0).repeat(vec1.shape[0], 1, 1)
-
-        # 5) Rodrigues' formula with safe check for s^2 == 0
-        s_squared = s ** 2
-        s_squared_safe = s_squared.clone()
-        s_squared_safe[s_squared_safe == 0] = 1  # avoid division by zero
-        rotation_matrix = eye + kmat + torch.matmul(kmat, kmat) * ((1 - c) / s_squared_safe).unsqueeze(-1)
-
-        # 6) Handle parallel and anti-parallel vectors
-        s_zero = (s.squeeze(-1) < 1e-30)
-        c_positive = (c.squeeze(-1) > 0)
-        c_negative = (c.squeeze(-1) < 0)
-
-        # Vectors are parallel: identity matrix
-        rotation_matrix[s_zero & c_positive] = eye[s_zero & c_positive]
-
-        # Vectors are anti-parallel: 180-degree rotation about some perpendicular axis
-        for batch in range(vec1.shape[0]):
-            if s_zero[batch] and c_negative[batch]:
-                # fallback axis
-                not_parallel = torch.tensor([1.0, 0.0, 0.0], dtype=torch.float64)
-                if torch.allclose(a[batch], not_parallel):
-                    not_parallel = torch.tensor([0.0, 1.0, 0.0], dtype=torch.float64)
-                perp_axis = torch.cross(a[batch], not_parallel)
-                perp_axis = perp_axis / torch.norm(perp_axis)
-
-                kmat_180 = torch.zeros(3, 3, dtype=torch.float64)
-                kmat_180[0, 1] = -perp_axis[2]
-                kmat_180[0, 2] = perp_axis[1]
-                kmat_180[1, 0] = perp_axis[2]
-                kmat_180[1, 2] = -perp_axis[0]
-                kmat_180[2, 0] = -perp_axis[1]
-                kmat_180[2, 1] = perp_axis[0]
-                rotation_matrix[batch] = eye[batch] + 2 * torch.matmul(kmat_180, kmat_180)
-
-        return rotation_matrix
-
-    def rotation_matrix_from_vectors_lower(self, vec1, vec2):
-        """
-        Another variant of rotation_matrix_from_vectors supporting a single batch dimension
-        without an extra "branch" dimension. Very similar to rotation_matrix_from_vectors_lowerdim,
-        but uses a slightly different code structure.
-
-        Args:
-            vec1 (torch.Tensor): Shape (batch, 3)
-            vec2 (torch.Tensor): Shape (batch, 3)
-
-        Returns:
-            rotation_matrix (torch.Tensor): Shape (batch, 3, 3)
-        """
-        # Same steps as above: (1) Normalize, (2) Cross/dot, (3) Skew mat, (4) Identity
-        a = vec1 / torch.norm(vec1, dim=-1, keepdim=True)
-        b = vec2 / torch.norm(vec2, dim=-1, keepdim=True)
-        v = torch.cross(a, b, dim=-1)
-        c = torch.sum(a * b, dim=-1, keepdim=True)
-        s = torch.norm(v, dim=-1, keepdim=True)
-
-        kmat = torch.zeros((vec1.shape[0], 3, 3), dtype=torch.float64)
-        kmat[:, 0, 1] = -v[:, 2]
-        kmat[:, 0, 2] = v[:, 1]
-        kmat[:, 1, 0] = v[:, 2]
-        kmat[:, 1, 2] = -v[:, 0]
-        kmat[:, 2, 0] = -v[:, 1]
-        kmat[:, 2, 1] = v[:, 0]
-
-        eye = torch.eye(3, dtype=torch.float64).unsqueeze(0).repeat(vec1.shape[0], 1, 1)
-
-        rotation_matrix = eye + kmat + torch.matmul(kmat, kmat) * ((1 - c) / (s ** 2)).unsqueeze(-1)
-
-        s_zero = (s < 1e-30).squeeze(-1)
-        c_positive = (c > 0).squeeze(-1)
-        c_negative = (c < 0).squeeze(-1)
-
-        s_zero_expanded = s_zero.unsqueeze(-1).unsqueeze(-1).expand_as(eye)
-        c_positive_expanded = c_positive.unsqueeze(-1).unsqueeze(-1).expand_as(eye)
-
-        # Parallel => identity
-        rotation_matrix = torch.where(s_zero_expanded & c_positive_expanded, eye, rotation_matrix)
-
-        # Anti-parallel => rotate 180 degrees around perpendicular
-        for batch in range(vec1.shape[0]):
-            if s_zero[batch] and c_negative[batch]:
-                axis = torch.tensor([1.0, 0.0, 0.0], dtype=torch.float64)
-                if torch.allclose(a[batch], axis):
-                    axis = torch.tensor([0.0, 1.0, 0.0], dtype=torch.float64)
-                perp_axis = torch.cross(a[batch], axis)
-                perp_axis = perp_axis / torch.norm(perp_axis)
-
-                kmat_180 = torch.zeros(3, 3, dtype=torch.float64)
-                kmat_180[0, 1] = -perp_axis[2]
-                kmat_180[0, 2] = perp_axis[1]
-                kmat_180[1, 0] = perp_axis[2]
-                kmat_180[1, 2] = -perp_axis[0]
-                kmat_180[2, 0] = -perp_axis[1]
-                kmat_180[2, 1] = perp_axis[0]
-
-                rotation_matrix[batch] = eye[batch] + 2 * torch.matmul(kmat_180, kmat_180)
-
-        return rotation_matrix
-
-    def Inextensibility_Constraint_Enforcement(self, batch, current_vertices, nominal_length, DLO_mass, clamped_index,
-                                               scale, mass_scale, zero_mask_num):
-        """
-        Enforces inextensibility constraints for a single DLO by adjusting vertex positions
-        so that the edge lengths stay near their nominal values.
-
-        Args:
-            batch (int): Batch size (number of rods or scenes).
-            current_vertices (torch.Tensor): Shape (batch, n_vertices, 3).
-            nominal_length (torch.Tensor): Shape (batch, n_edges). The nominal distances between adjacent vertices.
-            DLO_mass (torch.Tensor): (Not used directly here, but can store mass information)
-            clamped_index (torch.Tensor): Indices in the rods to clamp or fix (not used here).
-            scale (torch.Tensor): Scale factors for each edge, shape (batch, n_edges).
-            mass_scale (torch.Tensor): Another scaling for masses, shape (batch, n_edges).
-            zero_mask_num (torch.Tensor): 0/1 or boolean mask indicating which edges are active.
-
-        Returns:
-            current_vertices (torch.Tensor): Updated vertex positions enforcing length constraints.
-        """
-        # Square of the nominal length for each edge
-        nominal_length_square = nominal_length * nominal_length
-
-        # Loop over each edge
-        for i in range(current_vertices.size()[1] - 1):
-            # Extract the 'edge' vector, masked by zero_mask_num
-            updated_edges = (current_vertices[:, i + 1] - current_vertices[:, i]) * zero_mask_num[:, i].unsqueeze(-1)
-
-            # denominator = L^2 + updated_edges^2
-            denominator = nominal_length_square[:, i] + (updated_edges * updated_edges).sum(dim=1)
-            # l ~ measure of inextensibility mismatch
-            l = torch.zeros_like(nominal_length_square[:, i])
-            mask = zero_mask_num[:, i].bool()
-
-            # l = 1 - 2L^2 / (L^2 + |edge|^2)
-            l[mask] = 1 - 2 * nominal_length_square[mask, i] / denominator[mask]
-
-            # If all edges are within tolerance, skip
-            are_all_close_to_zero = torch.all(torch.abs(l) < self.tolerance)
-            if are_all_close_to_zero:
-                continue
-
-            # l_cat used for scaling -> shape (batch,) -> repeated
-            l_cat = (l.unsqueeze(-1).repeat(1, 2).view(-1) / scale[:, i])
-            # l_scale -> (batch,) -> expanded for each dimension
-            l_scale = l_cat.unsqueeze(-1).unsqueeze(-1) * mass_scale[:, i]
-
-            # Update vertices in pair: i, i+1
-            #   new_position = old_position + l_scale * 'edge_vector'
-            #   repeated for each vertex in the pair
-            current_vertices[:, (i, i + 1)] = current_vertices[:, (i, i + 1)] + (
-                    l_scale @ updated_edges.unsqueeze(dim=1)
-                    .repeat(1, 2, 1)
-                    .view(-1, 3, 1)
-            ).view(-1, 2, 3)
-
-        return current_vertices
-
-    def Inextensibility_Constraint_Enforcement_Coupling(self, parent_vertices, child_vertices, coupling_index,
-                                                        coupling_mass_scale, selected_parent_index,
-                                                        selected_children_index):
-        """
-        Enforces inextensibility or position constraints between a 'parent' rod and a 'child' rod
-        at a specific coupling index.
-
-        Args:
-            parent_vertices (torch.Tensor): Shape (batch, n_parent_vertices, 3).
-            child_vertices (torch.Tensor): Shape (batch, n_child_vertices, 3).
-            coupling_index (torch.Tensor): Indices on the parent rod to couple with children.
-            coupling_mass_scale (torch.Tensor): Matrix scale for how parent/child share corrections.
-            selected_parent_index (list): Which rods in a bigger scene are 'parents'.
-            selected_children_index (list): Which rods in the bigger scene are 'children'.
-
-        Returns:
-            b_DLOs_vertices (torch.Tensor): Combined or updated vertices for the rods
-                                            after enforcing coupling constraints.
-        """
-        # Vector from parent to child's first vertex
-        updated_edges = child_vertices[:, 0] - parent_vertices[:, coupling_index].view(-1, 3)
-
-        # coupling_mass_scale => (l1, l2)
-        l1 = coupling_mass_scale[:, 0]
-        l2 = coupling_mass_scale[:, 1]
-
-        # Update parent's coupling_index
-        parent_vertices[:, coupling_index] = parent_vertices[:, coupling_index] + (
-                l1 @ updated_edges.unsqueeze(dim=-1)
-        ).view(-1, len(coupling_index), 3)
-
-        # Update child's first vertex
-        child_vertices[:, 0] = child_vertices[:, 0] + (
-                l2 @ updated_edges.unsqueeze(dim=-1)
-        ).reshape(-1, 3)
-
-        # Combine back into b_DLOs_vertices for a final representation
-        b_DLOs_vertices = torch.empty(len(selected_parent_index) + len(selected_children_index),
-                                      parent_vertices.size()[1], 3)
-        b_DLOs_vertices[selected_parent_index] = parent_vertices
-        b_DLOs_vertices[selected_children_index] = child_vertices
-
-        return b_DLOs_vertices
-
-    def quaternion_magnitude(self, quaternion):
-        """
-        Calculate the magnitude (norm) of a quaternion.
-
-        Args:
-            quaternion (torch.Tensor): Shape (..., 4), last dim is (w, x, y, z).
-
-        Returns:
-            torch.Tensor: Magnitude of the quaternion(s).
-        """
-        assert quaternion.shape[-1] == 4, "Quaternion should have 4 components (w, x, y, z)"
-        magnitude = torch.sqrt(torch.sum(quaternion ** 2, dim=-1))
-        return magnitude
-
-    def Rotation_Constraints_Enforcement_Parent_Children(
-            self,
-            parent_vertices, parent_orientations, previous_parent_vertices,
-            children_vertices, children_orientations, previous_children_vertices,
-            parent_MOIs, children_MOIs, index_selection, parent_MOI_index, momentum_scale_previous
-    ):
-        """
-        Enforces rotational constraints (continuity) between parent and child rods
-        based on how edges have changed from a 'previous' iteration/state to the current one.
-
-        Args:
-            parent_vertices (torch.Tensor): Current parent rod vertices.
-            parent_orientations (torch.Tensor): Current parent rod orientations (quaternions).
-            previous_parent_vertices (torch.Tensor): Previous parent rod vertices.
-            children_vertices (torch.Tensor): Current child rod vertices.
-            children_orientations (torch.Tensor): Current child rod orientations.
-            previous_children_vertices (torch.Tensor): Previous child rod vertices.
-            parent_MOIs (torch.Tensor): Parent moments of inertia (not fully used here).
-            children_MOIs (torch.Tensor): Child moments of inertia.
-            index_selection (torch.Tensor): Indices of the parent rods to apply constraints to.
-            parent_MOI_index (torch.Tensor): Indices for selecting from parent_MOIs.
-            momentum_scale_previous (torch.Tensor): Scale factors for rotational momentum-based correction.
-
-        Returns:
-            Tuple of updated parent_vertices, parent_orientations, children_vertices, children_orientations.
-        """
-        batch = parent_vertices.size()[0]
-        n_children = len(index_selection)
-
-        # 1) Collect 'previous' edges and 'current' edges from both parent and children rods
-        previous_edges = torch.cat(
-            (
-                previous_parent_vertices[:, index_selection + 1] - previous_parent_vertices[:, index_selection],
-                previous_children_vertices[:, :, 1] - previous_children_vertices[:, :, 0]
-            ),
-            dim=0
-        ).view(-1, 3)
-
-        current_edges = torch.cat(
-            (
-                parent_vertices[:, index_selection + 1] - parent_vertices[:, index_selection],
-                children_vertices[:, :, 1] - children_vertices[:, :, 0]
-            ),
-            dim=0
-        ).view(-1, 3)
-
-        # 2) Collect current orientations, then compute quaternion that rotates 'previous_edges' to 'current_edges'
-        orientations = torch.cat((parent_orientations[:, index_selection], children_orientations), dim=0).view(-1, 4)
-        quaternion = pytorch3d.transforms.matrix_to_quaternion(
-            self.rotation_matrix_from_vectors_lowerdim(previous_edges, current_edges)
-        )
-
-        # 3) Combine new rotation quaternion with existing orientation
-        quaternion_magnitude = self.quaternion_magnitude(quaternion)
-        # (Optional early exit if all are within tolerance, commented out here)
-        orientations = pytorch3d.transforms.quaternion_multiply(quaternion, orientations)
-
-        # 4) Split updated orientations back into parent/child
-        parent_orientations[:, index_selection] = orientations.view(2 * batch, -1, 4)[:batch]
-        children_orientations = orientations.view(2 * batch, -1, 4)[batch:]
-
-        # 5) Re-order parent vertices for rotation application
-        parent_desired_order = torch.cat((index_selection.unsqueeze(0), index_selection.unsqueeze(0) + 1),
-                                         dim=0).T.flatten()
-        parent_rod_vertices = parent_vertices[:, parent_desired_order]
-        children_rod_vertices = children_vertices[:, :, 0:2].reshape(-1, children_vertices.size()[1] * 2, 3)
-
-        # 6) Apply further rotation updates based on momentum scale
-        parent_rod_vertices, parent_rod_quaternion, children_rod_vertices, children_orientations = self.apply_rotation(
-            batch, n_children,
-            parent_orientations[:, index_selection],  # sub-set of parent orientations
-            children_orientations,
-            parent_MOIs[parent_MOI_index], children_MOIs,
-            parent_rod_vertices, children_rod_vertices,
-            momentum_scale_previous
-        )
-
-        # 7) Put updated vertices and orientations back in place
-        parent_vertices[:, parent_desired_order] = parent_rod_vertices
-        parent_orientations[:, index_selection] = parent_rod_quaternion.view(batch, n_children, 4)
-        children_vertices[:, :, 0:2] = children_rod_vertices.reshape(-1, children_vertices.size()[1], 2, 3)
-
-        return parent_vertices, parent_orientations, children_vertices, children_orientations.view(batch, n_children, 4)
-
-    def apply_rotation(
-            self, batch, n_children, edge_q1, edge_q2, rod_MOI1, rod_MOI2,
-            rods_vertices1, rods_vertices2, momentum_scale
-    ):
-        """
-        Applies a rotation update to rods based on quaternion differences between
-        parent edge orientation (edge_q1) and child edge orientation (edge_q2).
-
-        Args:
-            batch (int): Number of samples.
-            n_children (int): Number of rods or child edges to process.
-            edge_q1 (torch.Tensor): Parent's edge quaternions, shape (batch*n_children, 4).
-            edge_q2 (torch.Tensor): Child's edge quaternions, same shape.
-            rod_MOI1 (torch.Tensor): Parent's moment of inertia (not fully used here).
-            rod_MOI2 (torch.Tensor): Child's moment of inertia.
-            rods_vertices1 (torch.Tensor): Parent rod vertex coordinates.
-            rods_vertices2 (torch.Tensor): Child rod vertex coordinates.
-            momentum_scale (torch.Tensor): A matrix for adjusting how rotation is applied
-                                           based on some momentum factor.
-
-        Returns:
-            rods_vertices1, rod_orientation1, rods_vertices2, rod_orientation2: Updated rods and their new orientations.
-        """
-        # 1) Flatten or combine edge quaternions
-        edge_q1 = edge_q1.view(-1, 4)
-        edge_q2 = edge_q2.view(-1, 4)
-        edge_q = torch.cat((edge_q1, edge_q2), 1).view(-1, 4)
-
-        # 2) Compute delta quaternion (difference)
-        updated_quaternion = pytorch3d.transforms.quaternion_multiply(
-            edge_q1.clone(),
-            pytorch3d.transforms.quaternion_invert(edge_q2)
-        )
-        # Convert delta quaternion to axis-angle, then scale by momentum_scale
-        delta_angular = pytorch3d.transforms.rotation_conversions.quaternion_to_axis_angle(updated_quaternion).view(-1,
-                                                                                                                    1,
-                                                                                                                    3)
-        delta_angular = delta_angular.repeat(1, 2, 1).view(-1, 3)
-        delta_angular_rod = (momentum_scale @ delta_angular.unsqueeze(dim=-1)).view(-1, 3)
-
-        # 3) Convert that scaled axis-angle back to a quaternion, separate parent & child
-        angular_change_quaternion_rod = pytorch3d.transforms.rotation_conversions.axis_angle_to_quaternion(
-            delta_angular_rod
-        ).view(-1, 2, 4)
-
-        # 4) Multiply new rotation quaternions with existing edge quaternions
-        orientation = pytorch3d.transforms.quaternion_multiply(
-            angular_change_quaternion_rod.clone().view(-1, 4), edge_q.clone()
-        ).view(n_children * batch, 2, 4)
-        rod_orientation1, rod_orientation2 = orientation[:, 0], orientation[:, 1]
-
-        # 5) Reshape rods
-        angular_change_quaternion_rod = angular_change_quaternion_rod.view(batch, n_children, 2, 4)
-        rods_vertices1 = rods_vertices1.view(batch, n_children, 2, 3)
-        rods_vertices2 = rods_vertices2.view(batch, n_children, 2, 3)
-
-        # 6) Combine rods for consistent rotation application
-        rods_vertices = torch.stack([rods_vertices1, rods_vertices2], dim=2)
-        # => shape: [batch, n_children, 2(rods), 2(vertices), 3]
-
-        # 7) Compute each rod's origin so we can rotate around the rod's base
-        rod_vertices_origin = rods_vertices[:, :, :, 0:1, :]  # shape: [batch, n_children, 2, 1, 3]
-        rod_vertices_originated = rods_vertices - rod_vertices_origin
-
-        angular_change_quaternion_rod_expanded = angular_change_quaternion_rod.unsqueeze(dim=3).expand(-1, -1, -1, 2,
-                                                                                                       -1)
-        # => shape: [batch, n_children, 2, 2(vertices), 4]
-
-        # 8) Apply rotation to each vertex
-        rod_vertices_rotated = pytorch3d.transforms.quaternion_apply(
-            angular_change_quaternion_rod_expanded.reshape(-1, 4),
-            rod_vertices_originated.reshape(-1, 3)
-        ).view(batch, n_children, 2, 2, 3)
-
-        # 9) Add back origin
-        rods_vertices_updated = rod_vertices_rotated + rod_vertices_origin
-
-        # 10) Separate the updated rods
-        rods_vertices1 = rods_vertices_updated[:, :, 0, :, :].reshape(batch, n_children * 2, 3)
-        rods_vertices2 = rods_vertices_updated[:, :, 1, :, :].reshape(batch, n_children * 2, 3)
-
-        return rods_vertices1, rod_orientation1, rods_vertices2, rod_orientation2
diff --git a/demo_image.png b/demo_image.png
deleted file mode 100644
index 1a9ca37..0000000
Binary files a/demo_image.png and /dev/null differ
diff --git a/modeling_demo.png b/modeling_demo.png
deleted file mode 100644
index b51ced5..0000000
Binary files a/modeling_demo.png and /dev/null differ
diff --git a/modeling_demo2.png b/modeling_demo2.png
deleted file mode 100644
index 6f2dfb0..0000000
Binary files a/modeling_demo2.png and /dev/null differ
diff --git a/read_results.py b/read_results.py
deleted file mode 100644
index f323e63..0000000
--- a/read_results.py
+++ /dev/null
@@ -1,36 +0,0 @@
-import pandas as pd
-import matplotlib.pyplot as plt
-import numpy as np
-
-"""example of reading pkl files"""
-
-clamp_type = "ends"
-training_case = 1
-BDLO_type = 1
-eval_loss_1 = np.array(pd.read_pickle(r"training_record/eval_%s_loss_DEFT_%s_%s.pkl" % (clamp_type, training_case, BDLO_type)))
-eval_step_1 = np.array(pd.read_pickle(r"training_record/eval_%s_epoches_DEFT_%s_%s.pkl" % (clamp_type, training_case, BDLO_type)))
-
-fig, (ax1, ax2) = plt.subplots(1, 2)
-fig.set_figheight(10)
-fig.set_figwidth(20)
-
-
-line1 = ax2.plot(eval_step_1, np.sqrt(eval_loss_1), label='%s'%BDLO_type)
-
-# # # #
-ax1.set_title('BDLO1: Training')
-ax1.set_xlabel('Training Iterations')
-ax1.set_ylabel('MSE')
-
-ax2.set_title('BDLO1: Eval')
-ax2.set_xlabel('Training Iterations')
-ax1.set_ylabel('MSE')
-
-ax1.grid(which = "minor")
-ax1.minorticks_on()
-ax2.grid(which = "minor")
-ax2.minorticks_on()
-plt.legend()
-plt.show()
-
-
diff --git a/requirements.txt b/requirements.txt
deleted file mode 100644
index c20b034..0000000
--- a/requirements.txt
+++ /dev/null
@@ -1,11 +0,0 @@
-click==8.1.7
-fonttools==4.39.4
-matplotlib==3.7.1
-numba==0.61.0
-numpy==1.24.0
-pandas==2.2.3
-pytorch3d==0.7.7
-sympy==1.13.1
-theseus_ai==0.2.2
-torch==2.5.1
-tqdm==4.67.0
diff --git a/residual_learning_nn/GNN_tree.py b/residual_learning_nn/GNN_tree.py
deleted file mode 100644
index fe0cba2..0000000
--- a/residual_learning_nn/GNN_tree.py
+++ /dev/null
@@ -1,251 +0,0 @@
-import time
-
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-from click.core import batch
-import numpy as np
-from fontTools.misc.psOperators import PSOperators
-from sympy.codegen import Print
-
-from util import visualize_tensors_3d_in_same_plot_no_zeros
-np.set_printoptions(threshold=np.inf)
-
-# 2. Define the model (same as before)
-class BatchedGCNLayer(nn.Module):
-    def __init__(self, in_features, out_features):
-        super(BatchedGCNLayer, self).__init__()
-        self.linear = nn.Linear(in_features, out_features)
-
-    def forward(self, x, adjacency):
-        degrees = adjacency.sum(dim=-1)
-        degree_matrix_inv_sqrt = degrees.pow(-0.5).unsqueeze(-1)
-        degree_matrix_inv_sqrt[degrees == 0] = 0
-        adjacency_normalized = adjacency * degree_matrix_inv_sqrt * degree_matrix_inv_sqrt.transpose(1, 2)
-        x = self.linear(x)
-        x = torch.bmm(adjacency_normalized, x)
-        return x
-
-class BatchedGNNModel(nn.Module):
-    def __init__(self, batch, in_features, hidden_features, out_features, n_vert, cs_n_vert, rigid_body_coupling_index,
-                 clamp_parent, clamp_child1, clamp_child2, parent_clamped_selection, child1_clamped_selection, child2_clamped_selection,
-                 selected_child1_index, selected_child2_index, selected_parent_index, selected_children_index):
-        super(BatchedGNNModel, self).__init__()
-        num_nodes = n_vert * 3
-        adjacency = torch.zeros(num_nodes, num_nodes)
-        self.rigid_body_coupling_index = rigid_body_coupling_index
-        self.n_vert = n_vert
-        hop = 1
-        for i in range(n_vert - hop):
-            adjacency[i, i + 1] = 1
-            adjacency[i + 1, i] = 1
-
-        for i in range(n_vert, n_vert + cs_n_vert[0] - hop):  # Nodes 13 to 16
-            adjacency[i, i + 1] = 1
-            adjacency[i + 1, i] = 1
-
-        for i in range(n_vert + n_vert, n_vert + n_vert + cs_n_vert[1] - hop):  # Nodes 18 to 20
-            adjacency[i, i + 1] = 1
-            adjacency[i + 1, i] = 1
-
-        self.zero_mask = torch.all(adjacency == 0, dim=-1).int()
-        adjacency = (adjacency + torch.eye(num_nodes)) * (1 - self.zero_mask)
-        self.selected_child1_index = selected_child1_index
-        self.selected_child2_index = selected_child2_index
-        self.selected_parent_index = selected_parent_index
-        self.selected_children_index = selected_children_index
-        # print("before:", adjacency.numpy())
-        for i in range(len(rigid_body_coupling_index)):
-            if i == 0:
-                adjacency[n_vert, rigid_body_coupling_index[i] - 1] = 1
-                adjacency[n_vert, rigid_body_coupling_index[i]] = 1
-                adjacency[n_vert, rigid_body_coupling_index[i] + 1] = 1
-                adjacency[rigid_body_coupling_index[i], n_vert] = 1
-                adjacency[rigid_body_coupling_index[i], n_vert + 1] = 1
-            else:
-                adjacency[n_vert * (i + 1), rigid_body_coupling_index[i] - 1] = 1
-                adjacency[n_vert * (i + 1), rigid_body_coupling_index[i]] = 1
-                adjacency[n_vert * (i + 1), rigid_body_coupling_index[i] + 1] = 1
-                adjacency[rigid_body_coupling_index[i], n_vert + cs_n_vert[i - 1]] = 1
-                adjacency[rigid_body_coupling_index[i], n_vert + cs_n_vert[i - 1] + 1] = 1
-
-        # Include self-loops in the adjacency matrix
-
-        # Batch of adjacency matrices: Shape (batch_size, num_nodes, num_nodes)
-        self.adjacency_batch = adjacency.unsqueeze(0).repeat(batch, 1, 1)
-        self.batch = batch
-        # self.gcn1 = BatchedGCNLayer(in_features-3, hidden_features)
-        # self.gcn1 = BatchedGCNLayer(in_features, hidden_features)
-        # self.gcn2 = BatchedGCNLayer(hidden_features, hidden_features)
-        # self.gcn3 = BatchedGCNLayer(hidden_features, hidden_features)
-        # self.gcn4 = BatchedGCNLayer(hidden_features, out_features)
-
-        self.gcn1 = BatchedGCNLayer(in_features, hidden_features * 2)
-        self.gcn2 = BatchedGCNLayer(hidden_features * 2, hidden_features)
-        self.gcn3 = BatchedGCNLayer(hidden_features, hidden_features)
-        self.gcn4 = BatchedGCNLayer(hidden_features, out_features)
-
-        # self.gcn4 = BatchedGCNLayer(3, hidden_features)
-        # self.gcn5 = BatchedGCNLayer(hidden_features, out_features)
-
-        self.clamp_parent = clamp_parent
-        self.clamp_child1 = clamp_child1
-        self.clamp_child2 = clamp_child2
-        self.parent_clamped_selection = parent_clamped_selection
-        self.child1_clamped_selection = child1_clamped_selection
-        self.child2_clamped_selection = child2_clamped_selection
-
-    def inference(self, x, inputs):
-        in_feature = x.size()[-1]
-        x = x.view(self.batch, -1, self.n_vert, x.size()[-1])
-        inputs = inputs.view(self.batch, -1, self.n_vert, 3)
-        if self.clamp_parent:
-            x[:, 0, self.parent_clamped_selection, 0:3] = inputs[:, 0, self.parent_clamped_selection]
-
-        if self.clamp_child1:
-            x[:, 1, self.child1_clamped_selection, 0:3] = inputs[:, 1, self.child1_clamped_selection]
-
-        if self.clamp_child2:
-            x[:, 2, self.child2_clamped_selection, 0:3] = inputs[:, 2, self.child2_clamped_selection]
-
-        x = x.view(self.batch, -1, in_feature)
-        inputs = inputs.view(self.batch, -1, 3)
-
-        x1 = self.gcn1(x, self.adjacency_batch)
-        x1 = F.relu(x1)
-        x1 = self.gcn2(x1, self.adjacency_batch)
-        x1 = F.relu(x1)
-        x1 = self.gcn3(x1, self.adjacency_batch)
-        x = self.gcn4(x1, self.adjacency_batch)
-
-        x = x.view(self.batch, -1, self.n_vert, 3)
-        inputs = inputs.view(self.batch, -1, self.n_vert, 3)
-        if self.clamp_parent:
-            x[:, 0, self.parent_clamped_selection] = inputs[:, 0, self.parent_clamped_selection]
-
-        if self.clamp_child1:
-            x[:, 1, self.child1_clamped_selection] = inputs[:, 1, self.child1_clamped_selection]
-
-        if self.clamp_child2:
-            x[:, 2, self.child2_clamped_selection] = inputs[:, 2, self.child2_clamped_selection]
-
-        x = x.view(self.batch, -1, 3)
-        return x
-
-    def iterative_sim(self, time_horizon, b_DLOs_vertices_traj, previous_b_DLOs_vertices_traj, target_b_DLOs_vertices_traj, loss_func, vis=False):
-        inputs = torch.zeros_like(target_b_DLOs_vertices_traj)
-        if self.clamp_parent:
-            parent_fix_point = target_b_DLOs_vertices_traj[:, :, 0, self.parent_clamped_selection]
-            inputs[:, :, 0, self.parent_clamped_selection] = parent_fix_point
-
-        if self.clamp_child1:
-            child1_fix_point = target_b_DLOs_vertices_traj[:, :, 1, self.child1_clamped_selection]
-            inputs[:, :, 1, self.child1_clamped_selection] = child1_fix_point
-
-        if self.clamp_child2:
-            child2_fix_point = target_b_DLOs_vertices_traj[:, :, 2, self.child2_clamped_selection]
-            inputs[:, :, 2, self.child2_clamped_selection] = child2_fix_point
-
-        traj_loss_eval = 0
-        for ith in range(time_horizon):
-            if ith == 0:
-                b_DLOs_vertices = b_DLOs_vertices_traj[:, ith].reshape(self.batch, -1, 3)
-                previous_b_DLOs_vertices = previous_b_DLOs_vertices_traj[:, ith].reshape(self.batch, -1, 3)
-                input = inputs[:, ith].reshape(self.batch, -1, 3)
-                pred_b_DLOs_vertices = self.inference(torch.cat((b_DLOs_vertices, previous_b_DLOs_vertices), dim=-1), input)
-                traj_loss_eval += loss_func(
-                    target_b_DLOs_vertices_traj[:, ith].reshape(self.batch, -1, 3),
-                    pred_b_DLOs_vertices)
-
-                if self.clamp_parent:
-                    parent_fix_point_flat = parent_fix_point[:, ith].reshape(-1, 3)
-
-
-                if self.clamp_child1:
-                    child1_fix_point_flat = child1_fix_point[:, ith].reshape(-1, 3)
-
-                else:
-                    child1_fix_point_flat = None
-
-                if self.clamp_child2:
-                    child2_fix_point_flat = child2_fix_point[:, ith].reshape(-1, 3)
-
-                else:
-                    child2_fix_point_flat = None
-                if vis:
-                    test_batch = 24
-                    for i_eval_batch in range(test_batch):
-                        parent_vertices_traj_vis = target_b_DLOs_vertices_traj[i_eval_batch][:, 0]
-                        child1_vertices_traj_vis = target_b_DLOs_vertices_traj[i_eval_batch][:, 1]
-                        child2_vertices_traj_vis = target_b_DLOs_vertices_traj[i_eval_batch][:, 2]
-                        child1_vertices_vis = torch.cat((parent_vertices_traj_vis[ith, self.rigid_body_coupling_index[0]].unsqueeze(
-                            dim=0), child1_vertices_traj_vis[ith]), dim=0)
-                        child2_vertices_vis = torch.cat((parent_vertices_traj_vis[ith, self.rigid_body_coupling_index[1]].unsqueeze(
-                            dim=0), child2_vertices_traj_vis[ith]), dim=0)
-                        parent_vertices_pred = pred_b_DLOs_vertices.reshape(self.batch * 3, -1, 3)[self.selected_parent_index]
-                        children_vertices_pred = pred_b_DLOs_vertices.reshape(self.batch * 3, -1, 3)[self.selected_children_index].view(self.batch, -1, 3)
-                        visualize_tensors_3d_in_same_plot_no_zeros(self.parent_clamped_selection, parent_vertices_pred[i_eval_batch],
-                                                                   children_vertices_pred[i_eval_batch], ith, 0, self.clamp_parent,
-                                                                   self.clamp_child1, self.clamp_child2, parent_fix_point_flat,
-                                                                   child1_fix_point_flat, child2_fix_point_flat,
-                                                                   parent_vertices_traj_vis[ith], child1_vertices_vis,
-                                                                   child2_vertices_vis, i_eval_batch)
-
-
-            if ith == 1:
-                input = inputs[:, ith].reshape(self.batch, -1, 3)
-                b_DLOs_vert = pred_b_DLOs_vertices.clone()
-                pred_b_DLOs_vertices = self.inference(torch.cat((pred_b_DLOs_vertices, b_DLOs_vertices), dim=-1), input)
-                traj_loss_eval += loss_func(
-                    target_b_DLOs_vertices_traj[:, ith].reshape(self.batch, -1, 3),
-                    pred_b_DLOs_vertices)
-                if vis:
-                    test_batch = 24
-                    for i_eval_batch in range(test_batch):
-                        parent_vertices_traj_vis = target_b_DLOs_vertices_traj[i_eval_batch][:, 0]
-                        child1_vertices_traj_vis = target_b_DLOs_vertices_traj[i_eval_batch][:, 1]
-                        child2_vertices_traj_vis = target_b_DLOs_vertices_traj[i_eval_batch][:, 2]
-                        child1_vertices_vis = torch.cat((parent_vertices_traj_vis[ith, self.rigid_body_coupling_index[0]].unsqueeze(
-                            dim=0), child1_vertices_traj_vis[ith]), dim=0)
-                        child2_vertices_vis = torch.cat((parent_vertices_traj_vis[ith, self.rigid_body_coupling_index[1]].unsqueeze(
-                            dim=0), child2_vertices_traj_vis[ith]), dim=0)
-                        parent_vertices_pred = pred_b_DLOs_vertices.reshape(self.batch * 3, -1, 3)[self.selected_parent_index]
-                        children_vertices_pred = pred_b_DLOs_vertices.reshape(self.batch * 3, -1, 3)[self.selected_children_index].view(self.batch, -1, 3)
-                        visualize_tensors_3d_in_same_plot_no_zeros(self.parent_clamped_selection, parent_vertices_pred[i_eval_batch],
-                                                                   children_vertices_pred[i_eval_batch], ith, 0, self.clamp_parent,
-                                                                   self.clamp_child1, self.clamp_child2, parent_fix_point_flat,
-                                                                   child1_fix_point_flat, child2_fix_point_flat,
-                                                                   parent_vertices_traj_vis[ith], child1_vertices_vis,
-                                                                   child2_vertices_vis, i_eval_batch)
-
-            if ith >= 2:
-                # start_time = time.time()
-                input = inputs[:, ith].reshape(self.batch, -1, 3)
-                previous_b_DLOs_vertices = b_DLOs_vert.clone()
-                b_DLOs_vert = pred_b_DLOs_vertices.clone()
-                pred_b_DLOs_vertices = self.inference(torch.cat((b_DLOs_vert, previous_b_DLOs_vertices), dim=-1), input)
-                # print(time.time() - start_time)
-                traj_loss_eval += loss_func(
-                    target_b_DLOs_vertices_traj[:, ith].reshape(self.batch, -1, 3),
-                    pred_b_DLOs_vertices)
-
-                if vis:
-                    test_batch = 24
-                    for i_eval_batch in range(test_batch):
-                        parent_vertices_traj_vis = target_b_DLOs_vertices_traj[i_eval_batch][:, 0]
-                        child1_vertices_traj_vis = target_b_DLOs_vertices_traj[i_eval_batch][:, 1]
-                        child2_vertices_traj_vis = target_b_DLOs_vertices_traj[i_eval_batch][:, 2]
-                        child1_vertices_vis = torch.cat((parent_vertices_traj_vis[ith, self.rigid_body_coupling_index[0]].unsqueeze(
-                            dim=0), child1_vertices_traj_vis[ith]), dim=0)
-                        child2_vertices_vis = torch.cat((parent_vertices_traj_vis[ith, self.rigid_body_coupling_index[1]].unsqueeze(
-                            dim=0), child2_vertices_traj_vis[ith]), dim=0)
-                        parent_vertices_pred = pred_b_DLOs_vertices.reshape(self.batch * 3, -1, 3)[self.selected_parent_index]
-                        children_vertices_pred = pred_b_DLOs_vertices.reshape(self.batch * 3, -1, 3)[self.selected_children_index].view(self.batch, -1, 3)
-                        visualize_tensors_3d_in_same_plot_no_zeros(self.parent_clamped_selection, parent_vertices_pred[i_eval_batch],
-                                                                   children_vertices_pred[i_eval_batch], ith, 0, self.clamp_parent,
-                                                                   self.clamp_child1, self.clamp_child2, parent_fix_point_flat,
-                                                                   child1_fix_point_flat, child2_fix_point_flat,
-                                                                   parent_vertices_traj_vis[ith], child1_vertices_vis,
-                                                                   child2_vertices_vis, i_eval_batch)
-        return traj_loss_eval
-
diff --git a/sanity_check/image_store b/sanity_check/image_store
deleted file mode 100644
index 8b13789..0000000
--- a/sanity_check/image_store
+++ /dev/null
@@ -1 +0,0 @@
-
diff --git a/save_model/DEFT_ends_1_0_1.pth b/save_model/DEFT_ends_1_0_1.pth
index ac4f8ec..ebdf060 100644
Binary files a/save_model/DEFT_ends_1_0_1.pth and b/save_model/DEFT_ends_1_0_1.pth differ
diff --git a/theta_solver.py b/theta_solver.py
deleted file mode 100644
index 3b0ffb6..0000000
--- a/theta_solver.py
+++ /dev/null
@@ -1,531 +0,0 @@
-import torch
-import theseus as th
-from typing import List, Optional, Tuple
-import time
-import numpy as np
-from matplotlib.colors import to_rgb
-from numpy.f2py.crackfortran import verbose
-
-# Set seeds for reproducibility
-torch.manual_seed(0)
-np.random.seed(0)
-
-
-# If needed, uncomment these lines to enforce deterministic behaviors (may affect performance).
-# torch.backends.cudnn.deterministic = True
-# torch.backends.cudnn.benchmark = False
-
-# If needed, uncomment these lines to limit threading (can help ensure reproducibility and control CPU usage).
-# import os
-# os.environ["OMP_NUM_THREADS"] = "1"
-# os.environ["MKL_NUM_THREADS"] = "1"
-# torch.set_num_threads(1)
-# torch.set_num_interop_threads(1)
-
-
-# ----------------------------------------------
-#  Custom CostFunction: VectorDifference
-# ----------------------------------------------
-class VectorDifference(th.CostFunction):
-    """
-    This class defines a custom cost function for Theseus-based optimization. The cost function
-    encapsulates both the bending and twisting energies of a discrete rod-like structure using
-    concepts from the Discrete Elastic Rods (DER) formulation.
-
-    Attributes:
-        n_branch (int): Number of 'branches' or rod segments treated together in a batch.
-        cost_weight (th.CostWeight): Cost weighting used by Theseus in the objective.
-        energy_target (th.Variable): (Currently unused) An auxiliary variable intended for
-                                     target energy or reference data.
-        kb (th.Variable): Discrete curvature binormal (batch_size, n_edge, 3).
-        b_u (th.Variable): Bishop frame component 'u' (batch_size, n_edge, 3).
-        b_v (th.Variable): Bishop frame component 'v' (batch_size, n_edge, 3).
-        m_restW1 (th.Variable): Rest curvature in the material frame component #1 (batch_size, n_edge, 2).
-        m_restW2 (th.Variable): Rest curvature in the material frame component #2 (batch_size, n_edge, 2).
-        restRegionL (th.Variable): Rest lengths for each segment (batch_size, n_edge).
-        inner_theta_variable (th.Vector): The twist angles (theta) to be optimized (batch_size, n_edge).
-        end_theta (th.Variable): (Currently unused) Possibly the endpoint twist angle or boundary condition.
-        stiff_threshold (th.Variable): Minimum threshold for stiffness values to prevent degeneracies.
-        bend_stiffness_last_unsq (th.Variable): Bending stiffness for the "previous" portion of each edge.
-        bend_stiffness_next_unsq (th.Variable): Bending stiffness for the "next" portion of each edge.
-        bend_stiffness (th.Variable): Bending stiffness (legacy parameter, not directly used if we have last/next).
-        twist_stiffness (th.Variable): Twisting stiffness for each edge (batch_size, n_edge).
-        optimization_mask (torch.Tensor or tuple): Mask to selectively zero out gradient entries.
-        name (Optional[str]): Name to be used for cost function in Theseus.
-
-    Notes:
-        - The cost function calculates the sum of bending and twisting energies for
-          each segment and accumulates them to get the total rod energy.
-        - Bending energy is derived from the difference between the current material
-          curvature and the rest curvature.
-        - Twisting energy is derived from the difference in angles between consecutive segments.
-    """
-
-    def __init__(
-            self,
-            n_branch,
-            cost_weight: th.CostWeight,
-            energy_target: th.Variable,
-            kb: th.Variable,
-            b_u: th.Variable,
-            b_v: th.Variable,
-            m_restW1: th.Variable,
-            m_restW2: th.Variable,
-            restRegionL: th.Variable,
-            inner_theta_variable: th.Vector,
-            end_theta: th.Variable,
-            stiff_threshold: th.Variable,
-            bend_stiffness_last_unsq: th.Variable,
-            bend_stiffness_next_unsq: th.Variable,
-            bend_stiffness: th.Variable,
-            twist_stiffness: th.Variable,
-            optimization_mask,
-            name: Optional[str] = None,
-    ):
-        # Call the parent constructor (CostFunction)
-        super().__init__(cost_weight, name=name)
-
-        # A small epsilon value to avoid division by zero.
-        self.epsilon = 1e-40
-
-        # Save references to the input variables
-        self.cost_weight = cost_weight
-        self.energy_target = energy_target
-        self.kb = kb
-        self.b_u = b_u
-        self.b_v = b_v
-        self.m_restW1 = m_restW1
-        self.m_restW2 = m_restW2
-        self.restRegionL = restRegionL
-        self.inner_theta_variable = inner_theta_variable
-        self.end_theta = end_theta
-        self.n_branch = n_branch
-        self.stiff_threshold = stiff_threshold
-        self.bend_stiffness_last_unsq = bend_stiffness_last_unsq
-        self.bend_stiffness_next_unsq = bend_stiffness_next_unsq
-        self.bend_stiffness = bend_stiffness
-        self.twist_stiffness = twist_stiffness
-
-        # Register the optimization variable with Theseus (the variable to be optimized).
-        self.register_optim_vars(["inner_theta_variable"])
-
-        # Register auxiliary variables that are not optimized but will be read by the cost function.
-        self.register_aux_vars(["energy_target"])
-        self.register_aux_vars(["b_u"])
-        self.register_aux_vars(["b_v"])
-        self.register_aux_vars(["m_restW1"])
-        self.register_aux_vars(["m_restW2"])
-        self.register_aux_vars(["restRegionL"])
-        self.register_aux_vars(["end_theta"])
-        self.register_aux_vars(["bend_stiffness"])
-        self.register_aux_vars(["twist_stiffness"])
-
-        # Keep track of the mask for partial gradient updates
-        self.optimization_mask = optimization_mask,
-
-        # Basic set-up for indexing edges
-        n_edge = b_u.tensor.size()[1]
-        self.idx = torch.arange(1, n_edge)
-        self.idx_prev = torch.arange(0, n_edge - 1)
-
-        # Clamp the bending stiffness to avoid values below the threshold
-        bend_stiffness_clamped = torch.clamp(
-            self.bend_stiffness.tensor, min=self.stiff_threshold.tensor
-        ).view(1, -1, 1, 1)
-
-        # Build a rotation matrix that rotates by 90 degrees for all edges
-        J = self.rotation_matrix(torch.pi / 2. * torch.ones(kb.tensor.size()[1]))
-
-        # Expand rotation matrices J across the batch dimension and edges
-        # n_branch: how many rods in parallel we are optimizing
-        J_expanded = (
-            J.unsqueeze(0)
-            .repeat(n_branch, 1, 1, 1)
-            .unsqueeze(0)
-            .view(1, -1, 2, 2)
-        )
-
-        # Multiply rotation matrix J by the clamped bending stiffness
-        self.JB = J_expanded * bend_stiffness_clamped
-
-        # Identify where restRegionL is zero; used to zero-out certain computations
-        # for edges that effectively do not exist or have zero length.
-        restRegionL_unsq = self.restRegionL[:, 1:].unsqueeze(dim=-1)
-        self.zero_mask = restRegionL_unsq == 0
-        self.zero_mask_twist = self.restRegionL[:, 1:] == 0
-
-        # Batch size is total batch divided by the number of rods (n_branch),
-        # e.g., if you have multiple rods each with the same number of edges combined in one batch.
-        self.batch = self.kb.tensor.size()[0] // n_branch
-        n_edge = self.kb.tensor.size()[1]
-
-        # Repeat the twist stiffness to match the entire batch dimension
-        self.twist_stiffness_unsq = self.twist_stiffness.tensor.repeat(self.batch, 1, 1).view(-1, n_edge)
-
-    def computeMaterialFrame(self, m_theta, b_u, b_v):
-        """
-        Computes the material frame (m1, m2) given the Bishop frame (b_u, b_v) and
-        a twist angle m_theta. The material frame is rotated by m_theta about the rod's tangent.
-
-        Parameters:
-            m_theta (torch.Tensor): Twist angles (batch_size, n_edge).
-            b_u (torch.Tensor): Bishop frame 'u' (batch_size, n_edge, 3).
-            b_v (torch.Tensor): Bishop frame 'v' (batch_size, n_edge, 3).
-
-        Returns:
-            (m1, m2): The two perpendicular axes of the material frame.
-        """
-        # Compute cosines and sines of the angles, shape: (batch_size, n_edge, 1)
-        cosQ = torch.cos(m_theta.clone()).unsqueeze(dim=2)
-        sinQ = torch.sin(m_theta.clone()).unsqueeze(dim=2)
-
-        # m1, m2 are formed by rotating (b_u, b_v) around the rod's tangent
-        m1 = cosQ * b_u + sinQ * b_v
-        m2 = -sinQ * b_u + cosQ * b_v
-        return m1, m2
-
-    def computeW(self, kb, m1, m2):
-        """
-        Projects the discrete curvature binormal kb onto the local material frame (m1, m2).
-        This is used to extract the 2D curvature components in the local cross-section.
-
-        Parameters:
-            kb (torch.Tensor): Curvature binormal, shape (batch_size, n_edge, 3).
-            m1, m2 (torch.Tensor): The material frame vectors, each (batch_size, n_edge, 3).
-
-        Returns:
-            o_wij (torch.Tensor): 2D curvature components in the material frame,
-                                  shape (batch_size, n_edge, 2).
-        """
-        # Dot product of kb with m2 and m1 (with sign changes) to get the local 2D curvature.
-        # We create a 2D vector of shape (batch_size, n_edge, 2).
-        o_wij = torch.cat((
-            (kb * m2).sum(dim=2).unsqueeze(dim=2),
-            -(kb * m1).sum(dim=2).unsqueeze(dim=2)
-        ), dim=2)
-        return o_wij
-
-    def computeMaterialCurvature(self, kb, m1, m2):
-        """
-        Computes the material curvature at edges 1..n_edge-1 using the derivative
-        of twist angles between consecutive edges.
-
-        According to the DER paper, eq. (2), the material curvature is the difference
-        between consecutive frames in the bishop or material representation.
-
-        Parameters:
-            kb (torch.Tensor): Curvature binormal, shape (batch_size, n_edge, 3).
-            m1, m2 (torch.Tensor): Material frames (batch_size, n_edge, 3).
-
-        Returns:
-            m_W1, m_W2 (torch.Tensor): The 2D curvature in the material frame
-                                       for each edge in [1..n_edge-1].
-        """
-        # Curvature for the "previous" portion (between indices j-1 and j).
-        m_W1 = self.computeW(kb[:, 1:], m1[:, :-1], m2[:, :-1])
-        # Curvature for the "next" portion (between indices j and j+1).
-        m_W2 = self.computeW(kb[:, 1:], m1[:, 1:], m2[:, 1:])
-        return m_W1, m_W2
-
-    def error(self) -> torch.Tensor:
-        """
-        Computes the total energy (bending + twisting) for all edges, which is the
-        quantity that gets minimized in the optimization.
-
-        Returns:
-            O_E (torch.Tensor): A tensor of shape (batch_size, 1) representing
-                                the energy for each batch element.
-        """
-        # Retrieve the twist angles
-        theta_full = self.inner_theta_variable.tensor
-
-        # Compute the material frame from the Bishop frame
-        m1, m2 = self.computeMaterialFrame(theta_full, self.b_u.tensor, self.b_v.tensor)
-
-        # For convenience, get the rest lengths for edges 1..n_edge-1 and expand dimension
-        restRegionL_unsq = self.restRegionL[:, 1:].unsqueeze(dim=-1)
-
-        # Project discrete curvature binormal onto material frame
-        o_W1, o_W2 = self.computeMaterialCurvature(self.kb.tensor, m1, m2)
-
-        # Compute difference between current curvature and rest curvature
-        diff_prev = o_W1 - self.m_restW1.tensor[:, 1:]
-        diff_next = o_W2 - self.m_restW2.tensor[:, 1:]
-
-        # Bending energy: sum of squared differences scaled by stiffness / restRegion length
-        O_E = torch.where(
-            self.zero_mask,
-            0.,  # Zero out if restRegion is zero
-            (
-                    0.5 * (
-                    torch.clamp(self.bend_stiffness_last_unsq.tensor, self.stiff_threshold.tensor)
-                    * diff_prev * diff_prev
-                    + torch.clamp(self.bend_stiffness_next_unsq.tensor, self.stiff_threshold.tensor)
-                    * diff_next * diff_next
-            ) / (restRegionL_unsq + self.epsilon)
-            )
-        ).sum(dim=(1, 2))
-
-        # Twisting energy: depends on the difference between consecutive theta values
-        m = theta_full[:, 1:] - theta_full[:, :-1]
-
-        # Add the twisting part of the energy
-        O_E += torch.where(
-            self.zero_mask_twist,
-            0.,
-            0.5 * (
-                    torch.clamp(self.twist_stiffness_unsq[:, 1:], self.stiff_threshold.tensor)
-                    * m * m
-                    / (self.restRegionL[:, 1:] + self.epsilon)
-            )
-        ).sum(dim=1)
-
-        # Return as (batch_size, 1) for Theseus
-        return O_E.view(-1, 1)
-
-    def rotation_matrix(self, theta):
-        """
-        Constructs a 2D rotation matrix (for each batch element) that rotates by the input angle theta.
-
-        Parameters:
-            theta (torch.Tensor): Shape (batch_size,). The angle of rotation for each batch element.
-
-        Returns:
-            transform_basis (torch.Tensor): Shape (batch_size, 2, 2). A 2D rotation matrix for each batch.
-        """
-        batch = theta.size()[0]
-        rot_sin = torch.sin(theta)
-        rot_cos = torch.cos(theta)
-
-        # Initialize a zero tensor for the rotation matrix
-        transform_basis = torch.zeros(batch, 2, 2)
-
-        # Fill in the rotation matrix entries
-        transform_basis[:, 0, 0] = rot_cos
-        transform_basis[:, 0, 1] = -rot_sin
-        transform_basis[:, 1, 0] = rot_sin
-        transform_basis[:, 1, 1] = rot_cos
-        return transform_basis
-
-    def jacobians(self) -> Tuple[List[torch.Tensor], torch.Tensor]:
-        """
-        Computes the gradient of the energy function with respect to the twist angles theta.
-
-        Returns:
-            A tuple (jacobian_list, error_tensor):
-                - jacobian_list: A list of length 1 containing the Jacobian tensor
-                                 with shape [batch_size, 1, n_edge].
-                - error_tensor: The same as self.error() for direct usage in Theseus.
-        """
-        # Get the current twist angles
-        theta = self.inner_theta_variable.tensor
-
-        # Compute the material frame
-        m1, m2 = self.computeMaterialFrame(theta, self.b_u.tensor, self.b_v.tensor)
-
-        # Prepare a gradient buffer
-        batch_size, n_edge, _ = m1.size()
-        dEdtheta = torch.zeros((batch_size, n_edge))  # [batch_size, n_edge]
-
-        # Only proceed if n_edge > 1 because we need consecutive edges
-        if n_edge > 1:
-            # Compute material curvature for consecutive edges
-            o_W1, o_W2 = self.computeMaterialCurvature(self.kb.tensor, m1, m2)
-
-            # 1) Bending energy gradient components
-            # Difference from rest
-            temp = (o_W1 - self.m_restW1.tensor[:, 1:]).unsqueeze(-1)  # shape: [batch_size, n_edge-1, 2, 1]
-
-            # JB_j for "previous" edges (skip the last one)
-            JB_j = self.JB.view(self.n_branch, -1, 2, 2)[:, :-1].repeat(self.batch, 1, 1, 1)
-            JB_wij = torch.matmul(JB_j, temp).squeeze(-1)  # shape: [batch_size, n_edge-1, 2]
-
-            # dot product with o_W1
-            term1 = (o_W1 * JB_wij).sum(dim=-1)  # [batch_size, n_edge-1]
-
-            # Similarly for "next" edges
-            temp = (o_W2 - self.m_restW2.tensor[:, 1:]).unsqueeze(-1)
-            JB_j = self.JB.view(self.n_branch, -1, 2, 2)[:, 1:].repeat(self.batch, 1, 1, 1)
-            JB_wij = torch.matmul(JB_j, temp).squeeze(-1)
-            term2 = (o_W2 * JB_wij).sum(dim=-1)
-
-            # 2) Twisting energy gradient components
-            # Clamped twist stiffness
-            twist_stiffness_clamped = torch.clamp(
-                self.twist_stiffness_unsq[:, 1:], min=self.stiff_threshold.tensor
-            )
-
-            # The difference in theta values
-            # gradient wrt theta_j for the difference (theta_j - theta_{j-1})
-            term1 -= twist_stiffness_clamped * (theta[:, 1:] - theta[:, :-1])
-            term1 = torch.where(
-                self.zero_mask_twist,
-                0.,
-                term1 / (self.restRegionL[:, 1:] + self.epsilon)
-            )
-
-            # gradient wrt theta_{j-1} for the difference (theta_j - theta_{j-1})
-            term2 += twist_stiffness_clamped * (theta[:, 1:] - theta[:, :-1])
-            term2 = torch.where(
-                self.zero_mask_twist,
-                0.,
-                term2 / (self.restRegionL[:, 1:] + self.epsilon)
-            )
-
-            # Accumulate these values appropriately in the gradient
-            dEdtheta[:, :-1] += term1
-            dEdtheta[:, 1:] += term2
-
-        # Expand the gradient to match the shape expected by Theseus: [batch_size, 1, n_edge]
-        jacobian_tensor = dEdtheta.unsqueeze(1)
-
-        # Apply any given optimization mask (if certain DOFs need to be disabled)
-        jacobian_tensor = jacobian_tensor * self.optimization_mask[0]
-
-        # Return the gradient and the error
-        return [jacobian_tensor], self.error()
-
-    def dim(self) -> int:
-        """
-        This cost function returns a single scalar energy value per batch element,
-        so the dimension is 1.
-        """
-        return 1
-
-    def _copy_impl(self, new_name: Optional[str] = None) -> "VectorDifference":
-        """
-        Creates a copy of this cost function. Required method for Theseus
-        to replicate the cost function with a new name if needed.
-        """
-        return VectorDifference(  # type: ignore
-            self.n_branch,
-            self.cost_weight.copy(),
-            self.energy_target.copy(),
-            self.kb.copy(),
-            self.b_u.copy(),
-            self.b_v.copy(),
-            self.m_restW1.copy(),
-            self.m_restW2.copy(),
-            self.restRegionL.copy(),
-            self.inner_theta_variable.copy(),
-            self.end_theta.copy(),
-            self.stiff_threshold.copy(),
-            self.bend_stiffness_last_unsq.copy(),
-            self.bend_stiffness_next_unsq.copy(),
-            self.bend_stiffness.copy(),
-            self.twist_stiffness.copy(),
-            name=new_name,
-        )
-
-
-# ------------------------------------------------------
-#  Optimization Routine for theta (the twist angles)
-# ------------------------------------------------------
-def theta_optimize(
-        n_branch,
-        cost_weight,
-        target_energy,
-        kb,
-        b_u,
-        b_v,
-        m_restW1,
-        m_restW2,
-        restRegionL,
-        inner_theta_opt,
-        inner_theta_tensor,
-        end_theta,
-        stiff_threshold,
-        bend_stiffness_last_unsq,
-        bend_stiffness_next_unsq,
-        bend_stiffness,
-        twist_stiffness,
-        optimization_mask
-):
-    """
-    Sets up a Theseus optimization problem with the VectorDifference cost function.
-
-    Args:
-        n_branch (int): Number of parallel rod segments in the batch.
-        cost_weight (th.CostWeight): Theseus cost weight parameter.
-        target_energy (th.Variable): (Currently unused) Possibly a reference energy target.
-        kb (th.Variable): Curvature binormal variable (batch_size, n_edge, 3).
-        b_u (th.Variable): Bishop frame u (batch_size, n_edge, 3).
-        b_v (th.Variable): Bishop frame v (batch_size, n_edge, 3).
-        m_restW1 (th.Variable): Rest curvature (component #1).
-        m_restW2 (th.Variable): Rest curvature (component #2).
-        restRegionL (th.Variable): Rest lengths for edges.
-        inner_theta_opt (th.Vector): The Theseus variable that will be optimized.
-        inner_theta_tensor (torch.Tensor): Initial guess for the twist angles.
-        end_theta (th.Variable): (Currently unused) Possibly boundary condition for the last edge.
-        stiff_threshold (th.Variable): Minimum stiffness threshold.
-        bend_stiffness_last_unsq (th.Variable): Bending stiffness for the previous portion of edges.
-        bend_stiffness_next_unsq (th.Variable): Bending stiffness for the next portion of edges.
-        bend_stiffness (th.Variable): Bending stiffness (legacy).
-        twist_stiffness (th.Variable): Twisting stiffness.
-        optimization_mask (torch.Tensor): Mask to disable certain optimization DOFs if needed.
-
-    Returns:
-        a_i_value (torch.Tensor): The optimized twist angles (batch_size, n_edge).
-    """
-    # Create a Theseus Objective
-    objective = th.Objective()
-
-    # Instantiate our custom cost function
-    cost_fn = VectorDifference(
-        n_branch,
-        cost_weight,
-        target_energy,
-        kb,
-        b_u,
-        b_v,
-        m_restW1,
-        m_restW2,
-        restRegionL,
-        inner_theta_opt,
-        end_theta,
-        stiff_threshold,
-        bend_stiffness_last_unsq,
-        bend_stiffness_next_unsq,
-        bend_stiffness,
-        twist_stiffness,
-        optimization_mask
-    )
-    # Add the cost function to the objective
-    objective.add(cost_fn)
-
-    # Prepare the initial values (dict) for the optimization variables
-    theseus_inputs = {}
-    theseus_inputs.update({f"inner_theta_variable": inner_theta_tensor})
-
-    # Update the objective with the data
-    objective.update(theseus_inputs)
-
-    # (Optional) We could check initial error:
-    # error_sq = objective.error_metric()
-    # print(f"Initial error: {error_sq.item()}")
-
-    # Set up the Levenberg-Marquardt optimizer
-    optimizer = th.LevenbergMarquardt(
-        objective,
-        linear_solver_cls=th.LUDenseSolver,  # Use LU solver for dense systems
-        linearization_cls=th.DenseLinearization,
-        linear_solver_kwargs={'check_singular': False},
-        max_iterations=10,
-        step_size=0.5,
-        abs_err_tolerance=1e-10,
-        rel_err_tolerance=1e-5,
-        adaptive_damping=True,
-    )
-
-    # Solve the optimization problem
-    info = optimizer.optimize(inputs=theseus_inputs)
-
-    # (Optional) Check error after optimization:
-    # error_sq = objective.error_metric()
-    # print(f"Final error: {error_sq.item()}")
-
-    # Retrieve the optimized angles
-    a_i_value = objective.get_optim_var("inner_theta_variable").tensor
-
-    # Return the final optimized twist angles
-    return a_i_value
diff --git a/theta_solver_numpy.py b/theta_solver_numpy.py
deleted file mode 100644
index 9726307..0000000
--- a/theta_solver_numpy.py
+++ /dev/null
@@ -1,465 +0,0 @@
-import torch
-import theseus as th
-from typing import List, Optional, Tuple
-import time
-import numpy as np
-
-# For deterministic runs:
-torch.manual_seed(0)
-np.random.seed(0)
-
-from numba import njit, prange
-import numpy as np
-
-
-@njit
-def compute_error_and_grad_np(
-    theta_np,                     # (batch, n_edge), float64
-    kb_np, b_u_np, b_v_np,        # (batch, n_edge, 3), float64
-    m_restW1_np, m_restW2_np,     # (batch, n_edge, 2), float64
-    restRegionL_np,               # (batch, n_edge), float64
-    stiff_threshold,              # scalar float64
-    bend_stiffness_last_unsq_np,  # (batch, n_edge-1, 1), float64
-    bend_stiffness_next_unsq_np,  # (batch, n_edge-1, 1), float64
-    twist_stiffness_unsq_np,      # (batch, n_edge), float64
-    zero_mask_np,                 # (batch, n_edge-1) bool
-    zero_mask_twist_np,           # (batch, n_edge-1) bool
-    epsilon,                      # scalar float64
-    compute_gradient              # bool
-):
-    """
-    A single-pass Numba-jitted function that computes both energy (O_E_np)
-    and gradient (dEdtheta_np) for bending and twisting. Operates on NumPy arrays
-    for speed, particularly for large batch sizes.
-    """
-    batch, n_edge = theta_np.shape
-
-    # Allocate storage for outputs:
-    # - O_E_np: total energy per batch
-    # - dEdtheta_np: gradient of the total energy w.r.t. theta
-    O_E_np = np.zeros(batch, dtype=theta_np.dtype)
-    dEdtheta_np = np.zeros((batch, n_edge), dtype=theta_np.dtype)
-
-    # Loop in parallel over batch
-    for b in prange(batch):
-        # Local accumulator for this batch element's energy
-        O_E_local = 0.0
-
-        # Loop over edges from 0 to n_edge - 1
-        # (since i+1 is used, we stop at n_edge-1)
-        for i in range(n_edge - 1):
-            #----------------------------------
-            #  1) Compute local cos/sin for i, i+1
-            #----------------------------------
-            t_i   = theta_np[b, i]
-            t_ip1 = theta_np[b, i+1]
-
-            c_i   = np.cos(t_i)
-            s_i   = np.sin(t_i)
-            c_ip1 = np.cos(t_ip1)
-            s_ip1 = np.sin(t_ip1)
-
-            #----------------------------------
-            #  2) Build local m1_i, m2_i  (index i)
-            #----------------------------------
-            # b_u and b_v are "basis" vectors;
-            # we rotate them by theta to get m1 and m2
-            bux_i, buy_i, buz_i = b_u_np[b, i, 0], b_u_np[b, i, 1], b_u_np[b, i, 2]
-            bvx_i, bvy_i, bvz_i = b_v_np[b, i, 0], b_v_np[b, i, 1], b_v_np[b, i, 2]
-
-            m1x_i = c_i*bux_i + s_i*bvx_i
-            m1y_i = c_i*buy_i + s_i*bvy_i
-            m1z_i = c_i*buz_i + s_i*bvz_i
-
-            m2x_i = -s_i*bux_i + c_i*bvx_i
-            m2y_i = -s_i*buy_i + c_i*bvy_i
-            m2z_i = -s_i*buz_i + c_i*bvz_i
-
-            #----------------------------------
-            #  3) Build local m1_(i+1), m2_(i+1)
-            #----------------------------------
-            bux_ip1, buy_ip1, buz_ip1 = b_u_np[b, i+1, 0], b_u_np[b, i+1, 1], b_u_np[b, i+1, 2]
-            bvx_ip1, bvy_ip1, bvz_ip1 = b_v_np[b, i+1, 0], b_v_np[b, i+1, 1], b_v_np[b, i+1, 2]
-
-            m1x_ip1 = c_ip1*bux_ip1 + s_ip1*bvx_ip1
-            m1y_ip1 = c_ip1*buy_ip1 + s_ip1*bvy_ip1
-            m1z_ip1 = c_ip1*buz_ip1 + s_ip1*bvz_ip1
-
-            m2x_ip1 = -s_ip1*bux_ip1 + c_ip1*bvx_ip1
-            m2y_ip1 = -s_ip1*buy_ip1 + c_ip1*bvy_ip1
-            m2z_ip1 = -s_ip1*buz_ip1 + c_ip1*bvz_ip1
-
-            #----------------------------------
-            #  4) Compute local o_W1, o_W2
-            #     (depend on the cross-binormal kb and the newly built m1, m2).
-            #----------------------------------
-            kbx, kby, kbz = kb_np[b, i+1, 0], kb_np[b, i+1, 1], kb_np[b, i+1, 2]
-
-            # Dot products for building o_W1 / o_W2:
-            dot_kb_m2_i = kbx*m2x_i + kby*m2y_i + kbz*m2z_i
-            dot_kb_m1_i = kbx*m1x_i + kby*m1y_i + kbz*m1z_i
-            oW1x = dot_kb_m2_i
-            oW1y = -dot_kb_m1_i
-
-            dot_kb_m2_ip1 = kbx*m2x_ip1 + kby*m2y_ip1 + kbz*m2z_ip1
-            dot_kb_m1_ip1 = kbx*m1x_ip1 + kby*m1y_ip1 + kbz*m1z_ip1
-            oW2x = dot_kb_m2_ip1
-            oW2y = -dot_kb_m1_ip1
-
-            #----------------------------------
-            #  5) Bending portion
-            #----------------------------------
-            # denom ~ restRegionL plus epsilon
-            # If zero_mask_np[b, i] is False, we proceed with bending energy.
-            denom = restRegionL_np[b, i+1] + epsilon
-            if not zero_mask_np[b, i]:
-                diff_prev_x = oW1x - m_restW1_np[b, i+1, 0]
-                diff_prev_y = oW1y - m_restW1_np[b, i+1, 1]
-                diff_next_x = oW2x - m_restW2_np[b, i+1, 0]
-                diff_next_y = oW2y - m_restW2_np[b, i+1, 1]
-
-                # Retrieve and clamp bending stiffness values by stiff_threshold
-                ks_l = bend_stiffness_last_unsq_np[b, i, 0]
-                if ks_l < stiff_threshold:
-                    ks_l = stiff_threshold
-                ks_n = bend_stiffness_next_unsq_np[b, i, 0]
-                if ks_n < stiff_threshold:
-                    ks_n = stiff_threshold
-
-                # Bending energy = 0.5 * ks * squared difference
-                bend_e = 0.5 * (
-                    ks_l * (diff_prev_x**2 + diff_prev_y**2)
-                  + ks_n * (diff_next_x**2 + diff_next_y**2)
-                )
-                # Accumulate normalized by denom
-                O_E_local += bend_e / denom
-
-                # If gradient needed, compute partial derivatives w.r.t. theta
-                if compute_gradient:
-                    # Partial derivatives for theta[b, i]
-                    dm1x_i = -s_i*bux_i + c_i*bvx_i
-                    dm1y_i = -s_i*buy_i + c_i*bvy_i
-                    dm1z_i = -s_i*buz_i + c_i*bvz_i
-
-                    dm2x_i = -c_i*bux_i - s_i*bvx_i
-                    dm2y_i = -c_i*buy_i - s_i*bvy_i
-                    dm2z_i = -c_i*buz_i - s_i*bvz_i
-
-                    dW1_dx_i = (kbx*dm2x_i + kby*dm2y_i + kbz*dm2z_i)
-                    dW1_dy_i = -(kbx*dm1x_i + kby*dm1y_i + kbz*dm1z_i)
-
-                    bend_grad_prev = ks_l * (diff_prev_x * dW1_dx_i + diff_prev_y * dW1_dy_i)
-                    dEdtheta_np[b, i] += bend_grad_prev / denom
-
-                    # Partial derivatives for theta[b, i+1]
-                    dm1x_ip1 = -s_ip1*bux_ip1 + c_ip1*bvx_ip1
-                    dm1y_ip1 = -s_ip1*buy_ip1 + c_ip1*bvy_ip1
-                    dm1z_ip1 = -s_ip1*buz_ip1 + c_ip1*bvz_ip1
-
-                    dm2x_ip1 = -c_ip1*bux_ip1 - s_ip1*bvx_ip1
-                    dm2y_ip1 = -c_ip1*buy_ip1 - s_ip1*bvy_ip1
-                    dm2z_ip1 = -c_ip1*buz_ip1 - s_ip1*bvz_ip1
-
-                    dW2_dx_ip1 = (kbx*dm2x_ip1 + kby*dm2y_ip1 + kbz*dm2z_ip1)
-                    dW2_dy_ip1 = -(kbx*dm1x_ip1 + kby*dm1y_ip1 + kbz*dm1z_ip1)
-
-                    bend_grad_next = ks_n * (diff_next_x*dW2_dx_ip1 + diff_next_y*dW2_dy_ip1)
-                    dEdtheta_np[b, i+1] += bend_grad_next / denom
-
-            #----------------------------------
-            #  6) Twisting portion
-            #----------------------------------
-            # If not zero_mask_twist_np[b, i], compute twist energy
-            # based on difference in angles dt = theta[i+1] - theta[i].
-            if not zero_mask_twist_np[b, i]:
-                dt = t_ip1 - t_i
-                ks_t = twist_stiffness_unsq_np[b, i+1]
-                if ks_t < stiff_threshold:
-                    ks_t = stiff_threshold
-                # 0.5 * ks_t * dt^2 / denom
-                twist_e = 0.5 * ks_t * (dt*dt) / denom
-                O_E_local += twist_e
-
-                if compute_gradient:
-                    # The twist partial derivative is (ks_t * dt)/denom for
-                    # + w.r.t. theta[i+1], and - w.r.t. theta[i]
-                    dEdtheta_np[b, i+1] += (ks_t * dt) / denom
-                    dEdtheta_np[b, i]   -= (ks_t * dt) / denom
-
-        # Store the accumulated energy for this batch
-        O_E_np[b] = O_E_local
-
-    return O_E_np, dEdtheta_np
-
-
-
-class VectorDifference(th.CostFunction):
-    """
-    A custom Theseus CostFunction that wraps the compute_error_and_grad_np
-    function for rod-like bending and twisting optimization.
-    """
-    def __init__(
-        self,
-        n_branch,
-        cost_weight: th.CostWeight,
-        energy_target: th.Variable,
-        kb: th.Variable,
-        b_u: th.Variable,
-        b_v: th.Variable,
-        m_restW1: th.Variable,
-        m_restW2: th.Variable,
-        restRegionL: th.Variable,
-        inner_theta_variable: th.Vector,
-        end_theta: th.Variable,
-        stiff_threshold: th.Variable,
-        bend_stiffness_last_unsq: th.Variable,
-        bend_stiffness_next_unsq: th.Variable,
-        bend_stiffness: th.Variable,
-        twist_stiffness: th.Variable,
-        optimization_mask,
-        name: Optional[str] = None,
-    ):
-        # Initialize the parent CostFunction
-        super().__init__(cost_weight, name=name)
-        self.epsilon = 1e-40
-        self.cost_weight = cost_weight
-        self.energy_target = energy_target
-        self.kb = kb
-        self.b_u = b_u
-        self.b_v = b_v
-        self.m_restW1 = m_restW1
-        self.m_restW2 = m_restW2
-        self.restRegionL = restRegionL
-        self.inner_theta_variable = inner_theta_variable
-        self.end_theta = end_theta
-        self.n_branch = n_branch
-        self.stiff_threshold = stiff_threshold
-        self.bend_stiffness_last_unsq = bend_stiffness_last_unsq
-        self.bend_stiffness_next_unsq = bend_stiffness_next_unsq
-        self.bend_stiffness = bend_stiffness
-        self.twist_stiffness = twist_stiffness
-        # Note that optimization_mask is a tuple with one element: (mask,)
-        self.optimization_mask = optimization_mask,
-
-        # Register optimization and auxiliary variables in Theseus
-        self.register_optim_vars(["inner_theta_variable"])
-        self.register_aux_vars(["energy_target"])
-        self.register_aux_vars(["b_u"])
-        self.register_aux_vars(["b_v"])
-        self.register_aux_vars(["m_restW1"])
-        self.register_aux_vars(["m_restW2"])
-        self.register_aux_vars(["restRegionL"])
-        self.register_aux_vars(["end_theta"])
-        self.register_aux_vars(["bend_stiffness"])
-        self.register_aux_vars(["twist_stiffness"])
-
-        # Build boolean masks to detect zero restRegionL (where we skip bending/twisting)
-        restRegionL_unsq = self.restRegionL.tensor[:, 1:].unsqueeze(dim=-1)
-        self.zero_mask = (restRegionL_unsq == 0)
-        self.zero_mask_twist = (self.restRegionL.tensor[:, 1:] == 0)
-
-        # For repeated usage in jacobians, store batch size and n_edge
-        self.batch = self.kb.tensor.size()[0] // n_branch
-        n_edge = self.kb.tensor.size()[1]
-
-        # Repeat or reshape twist stiffness if needed so it matches (batch, n_edge)
-        self.twist_stiffness_unsq = self.twist_stiffness.tensor.repeat(self.batch, 1, 1).view(-1, n_edge)
-
-    def error(self) -> torch.Tensor:
-        """
-        Computes the total energy (batch,1) by calling the Numba-accelerated
-        compute_error_and_grad_np function without gradient computation.
-        """
-        device = self.kb.tensor.device
-
-        # 1) Move data to CPU NumPy arrays
-        theta_np = self.inner_theta_variable.tensor.detach().cpu().numpy()
-        kb_np    = self.kb.tensor.detach().cpu().numpy()
-        b_u_np   = self.b_u.tensor.detach().cpu().numpy()
-        b_v_np   = self.b_v.tensor.detach().cpu().numpy()
-        m_restW1_np = self.m_restW1.tensor.detach().cpu().numpy()
-        m_restW2_np = self.m_restW2.tensor.detach().cpu().numpy()
-        restRegionL_np = self.restRegionL.tensor.detach().cpu().numpy()
-        zero_mask_np = self.zero_mask.detach().cpu().numpy()
-        zero_mask_twist_np = self.zero_mask_twist.detach().cpu().numpy()
-        bend_stiff_last_np = self.bend_stiffness_last_unsq.tensor.detach().cpu().numpy()
-        bend_stiff_next_np = self.bend_stiffness_next_unsq.tensor.detach().cpu().numpy()
-        twist_stiff_np     = self.twist_stiffness_unsq.detach().cpu().numpy()
-        stiff_threshold = float(self.stiff_threshold.tensor.item())
-
-        # 2) Call Numba function (compute gradient=False)
-        O_E_np, _ = compute_error_and_grad_np(
-            theta_np,
-            kb_np, b_u_np, b_v_np,
-            m_restW1_np, m_restW2_np,
-            restRegionL_np,
-            stiff_threshold,
-            bend_stiff_last_np,
-            bend_stiff_next_np,
-            twist_stiff_np,
-            zero_mask_np,
-            zero_mask_twist_np,
-            self.epsilon,
-            compute_gradient=False
-        )
-
-        # 3) Convert result to torch => shape (batch,1)
-        O_E = torch.from_numpy(O_E_np).float().view(-1, 1).to(device)
-        return O_E
-
-    def jacobians(self) -> Tuple[List[torch.Tensor], torch.Tensor]:
-        """
-        Returns:
-          - list of 1 Jacobian Tensor => shape (batch, 1, n_edge)
-          - the same error => shape (batch,1)
-        """
-        device = self.kb.tensor.device
-
-        # 1) Same data extraction as in error()
-        theta_np = self.inner_theta_variable.tensor.detach().cpu().numpy()
-        kb_np    = self.kb.tensor.detach().cpu().numpy()
-        b_u_np   = self.b_u.tensor.detach().cpu().numpy()
-        b_v_np   = self.b_v.tensor.detach().cpu().numpy()
-        m_restW1_np = self.m_restW1.tensor.detach().cpu().numpy()
-        m_restW2_np = self.m_restW2.tensor.detach().cpu().numpy()
-        restRegionL_np = self.restRegionL.tensor.detach().cpu().numpy()
-        zero_mask_np = self.zero_mask.detach().cpu().numpy()
-        zero_mask_twist_np = self.zero_mask_twist.detach().cpu().numpy()
-        bend_stiff_last_np = self.bend_stiffness_last_unsq.tensor.detach().cpu().numpy()
-        bend_stiff_next_np = self.bend_stiffness_next_unsq.tensor.detach().cpu().numpy()
-        twist_stiff_np = self.twist_stiffness_unsq.detach().cpu().numpy()
-        stiff_threshold = float(self.stiff_threshold.tensor.item())
-
-        # 2) Call Numba again, now with compute_gradient=True
-        O_E_np, dEdtheta_np = compute_error_and_grad_np(
-            theta_np,
-            kb_np, b_u_np, b_v_np,
-            m_restW1_np, m_restW2_np,
-            restRegionL_np,
-            stiff_threshold,
-            bend_stiff_last_np,
-            bend_stiff_next_np,
-            twist_stiff_np,
-            zero_mask_np,
-            zero_mask_twist_np,
-            self.epsilon,
-            compute_gradient=True
-        )
-
-        # 3) Convert to PyTorch
-        O_E = torch.from_numpy(O_E_np).float().view(-1, 1).to(device)
-        jac_cpu = dEdtheta_np  # shape => (batch, n_edge)
-        jac_torch = torch.from_numpy(jac_cpu).float().unsqueeze(1).to(device)  # => (batch, 1, n_edge)
-
-        # Apply the optimization_mask if needed (sometimes partial edges are optimized)
-        jac_torch = jac_torch * self.optimization_mask[0]
-
-        return [jac_torch], O_E
-
-    def dim(self) -> int:
-        """
-        Returns the dimension of this cost function (scalar -> dim=1).
-        """
-        return 1
-
-    def _copy_impl(self, new_name: Optional[str] = None) -> "VectorDifference":
-        """
-        Provide a copy constructor for Theseus.
-        """
-        return VectorDifference(  # type: ignore
-            self.n_branch,
-            self.cost_weight.copy(),
-            self.energy_target.copy(),
-            self.kb.copy(),
-            self.b_u.copy(),
-            self.b_v.copy(),
-            self.m_restW1.copy(),
-            self.m_restW2.copy(),
-            self.restRegionL.copy(),
-            self.inner_theta_variable.copy(),
-            self.end_theta.copy(),
-            self.stiff_threshold.copy(),
-            self.bend_stiffness_last_unsq.copy(),
-            self.bend_stiffness_next_unsq.copy(),
-            self.bend_stiffness.copy(),
-            self.twist_stiffness.copy(),
-            self.optimization_mask,
-            name=new_name,
-        )
-
-
-def theta_optimize_numpy(
-    n_branch,
-    cost_weight,
-    target_energy,
-    kb,
-    b_u,
-    b_v,
-    m_restW1,
-    m_restW2,
-    restRegionL,
-    inner_theta_opt,
-    inner_theta_tensor,
-    end_theta,
-    stiff_threshold,
-    bend_stiffness_last_unsq,
-    bend_stiffness_next_unsq,
-    bend_stiffness,
-    twist_stiffness,
-    optimization_mask
-):
-    """
-    Sets up and solves a non-linear least squares objective using Theseus's
-    LevenbergMarquardt optimizer. The main cost is given by VectorDifference,
-    which wraps the Numba code to compute bending/twisting energy and gradients.
-    """
-    # Create an empty objective container
-    objective = th.Objective()
-
-    # Add our custom cost function to the objective
-    cost_fn = VectorDifference(
-        n_branch,
-        cost_weight,
-        target_energy,
-        kb,
-        b_u,
-        b_v,
-        m_restW1,
-        m_restW2,
-        restRegionL,
-        inner_theta_opt,
-        end_theta,
-        stiff_threshold,
-        bend_stiffness_last_unsq,
-        bend_stiffness_next_unsq,
-        bend_stiffness,
-        twist_stiffness,
-        optimization_mask
-    )
-    objective.add(cost_fn)
-
-    # Initialize the Theseus input dictionary
-    theseus_inputs = {"inner_theta_variable": inner_theta_tensor}
-    objective.update(theseus_inputs)
-
-    # Create a Levenberg-Marquardt optimizer
-    optimizer = th.LevenbergMarquardt(
-        objective,
-        linear_solver_cls=th.LUDenseSolver,
-        linearization_cls=th.DenseLinearization,
-        linear_solver_kwargs={'check_singular': False},
-        max_iterations=10,
-        step_size=0.5,
-        abs_err_tolerance=1e-10,
-        rel_err_tolerance=1e-5,
-        adaptive_damping=True,
-    )
-
-    # Solve the problem
-    info = optimizer.optimize(inputs=theseus_inputs)
-
-    # Retrieve optimized values for 'inner_theta_variable'
-    a_i_value = objective.get_optim_var("inner_theta_variable").tensor
-    return a_i_value
-
-
diff --git a/training_record/eval_ends_epoches_DEFT_1_3.pkl b/training_record/eval_ends_epoches_DEFT_1_3.pkl
deleted file mode 100644
index c969aa9..0000000
Binary files a/training_record/eval_ends_epoches_DEFT_1_3.pkl and /dev/null differ
diff --git a/training_record/eval_ends_loss_DEFT_1_1.pkl b/training_record/eval_ends_loss_DEFT_1_1.pkl
index f654f51..85fd79e 100644
Binary files a/training_record/eval_ends_loss_DEFT_1_1.pkl and b/training_record/eval_ends_loss_DEFT_1_1.pkl differ
diff --git a/training_record/eval_ends_loss_DEFT_1_3.pkl b/training_record/eval_ends_loss_DEFT_1_3.pkl
deleted file mode 100644
index a044e44..0000000
Binary files a/training_record/eval_ends_loss_DEFT_1_3.pkl and /dev/null differ
diff --git a/training_record/train_ends_loss_DEFT_1_1.pkl b/training_record/train_ends_loss_DEFT_1_1.pkl
index 24348cc..bc466c0 100644
Binary files a/training_record/train_ends_loss_DEFT_1_1.pkl and b/training_record/train_ends_loss_DEFT_1_1.pkl differ
diff --git a/training_record/train_ends_loss_DEFT_1_3.pkl b/training_record/train_ends_loss_DEFT_1_3.pkl
deleted file mode 100644
index 32eedb8..0000000
Binary files a/training_record/train_ends_loss_DEFT_1_3.pkl and /dev/null differ
diff --git a/training_record/train_ends_step_DEFT_1_1.pkl b/training_record/train_ends_step_DEFT_1_1.pkl
index 2e79d92..1c6c4cc 100644
Binary files a/training_record/train_ends_step_DEFT_1_1.pkl and b/training_record/train_ends_step_DEFT_1_1.pkl differ
diff --git a/training_record/train_ends_step_DEFT_1_3.pkl b/training_record/train_ends_step_DEFT_1_3.pkl
deleted file mode 100644
index 1c6c4cc..0000000
Binary files a/training_record/train_ends_step_DEFT_1_3.pkl and /dev/null differ
diff --git a/util.py b/util.py
deleted file mode 100644
index 71a34ac..0000000
--- a/util.py
+++ /dev/null
@@ -1,1114 +0,0 @@
-import torch
-import torch.nn.functional as F
-import glob
-import os
-import pytorch3d
-from pathlib import Path
-import pickle
-import pytorch3d.transforms.rotation_conversions
-from sympy import pprint
-from tqdm import tqdm
-from torch.utils.data import Dataset, DataLoader
-import random
-import matplotlib.pyplot as plt
-import numpy as np
-import pandas as pd
-
-# Set random seed for reproducibility.
-random.seed(0)
-torch.manual_seed(0)
-
-
-def computeEdges(vertices, zero_mask):
-    """
-    Computes edge vectors (v_{i+1} - v_i) for each pair of consecutive vertices.
-    If zero_mask is True at position i, the corresponding edge is set to zero.
-
-    Args:
-        vertices (torch.Tensor): Shape [batch, n_vert, 3]. The 3D coordinates of each vertex.
-        zero_mask (torch.Tensor): Shape [batch, n_vert-1]. Boolean mask indicating which edges should be zeroed.
-
-    Returns:
-        edges (torch.Tensor): Shape [batch, n_vert-1, 3]. The computed edges, possibly zeroed at certain indices.
-    """
-    # Subtract consecutive vertices to get edges,
-    # then zero them out where zero_mask is True.
-    edges = torch.where(zero_mask.unsqueeze(dim=-1), 0., vertices[:, 1:] - vertices[:, :-1])
-    return edges
-
-
-def computeLengths(edges):
-    """
-    Computes:
-      1. The length of each edge (EdgeL).
-      2. The sum of lengths of two adjacent edges (RegionL). Often used in energy or curvature calculations.
-
-    Args:
-        edges (torch.Tensor): Shape [batch, n_edge, 3]. The edge vectors.
-
-    Returns:
-        EdgeL (torch.Tensor): Shape [batch, n_edge]. Length of each edge.
-        RegionL (torch.Tensor): Shape [batch, n_edge]. Sum of lengths of two adjacent edges, with RegionL[:,0] initialized as 0 + first adjacent sum.
-    """
-    batch = edges.size()[0]
-    # Magnitude of each edge
-    EdgeL = torch.norm(edges, dim=2)
-    # Initialize RegionL with zeros for the first column
-    RegionL = torch.zeros(batch, 1, device=edges.device)
-    # RegionL for edges i is EdgeL[i] + EdgeL[i-1], concatenated for all i
-    RegionL = torch.cat((RegionL, (EdgeL[:, 1:] + EdgeL[:, :-1])), dim=1)
-    return EdgeL, RegionL
-
-
-def sqrt_safe(value):
-    """
-    Computes a 'safe' square root by clamping the input to prevent negative values.
-
-    Args:
-        value (torch.Tensor): The input tensor for which sqrt is to be taken.
-
-    Returns:
-        (torch.Tensor): The square root of the clamped input.
-    """
-    return torch.sqrt(torch.clamp(value, 1e-10))
-
-
-def extractSinandCos(magnitude):
-    """
-    Extracts the sine and cosine of an angle from a given 'magnitude' using a specific function:
-        sin(phi) = sqrt(magnitude / (4 + magnitude))
-        cos(phi) = sqrt(4 / (4 + magnitude))
-    This is typically used for rotation angles in discrete rod calculations.
-
-    Args:
-        magnitude (torch.Tensor): The input magnitude used to compute sinPhi and cosPhi.
-
-    Returns:
-        o_sinPhi (torch.Tensor): sin(phi).
-        o_cosPhi (torch.Tensor): cos(phi).
-    """
-    constant = 4.0
-    o_sinPhi = sqrt_safe(magnitude / (constant + magnitude))
-    o_cosPhi = sqrt_safe(constant / (constant + magnitude))
-    return o_sinPhi, o_cosPhi
-
-
-def computeKB(edges, m_restEdgeL):
-    """
-    Computes the discrete curvature binormal k_b for each edge using the cross product approach from DER (Discrete Elastic Rods).
-    See DER paper eq. 1 for reference.
-
-    Args:
-        edges (torch.Tensor): Shape [batch, n_edge, 3]. Edge vectors for consecutive vertices.
-        m_restEdgeL (torch.Tensor): Shape [batch, n_edge]. Rest lengths for each edge.
-
-    Returns:
-        o_kb (torch.Tensor): Shape [batch, n_edge, 3]. The computed discrete curvature binormal for each edge.
-    """
-    o_kb = torch.zeros_like(edges)
-    zero_mask = m_restEdgeL[:, 1:] == 0
-    epsilon = 1e-20
-    # Inverse length factor ensures no division by zero or near-zero.
-    inv_length = torch.where(
-        zero_mask,
-        0.,
-        1 / (m_restEdgeL[:, :-1] * m_restEdgeL[:, 1:] + (edges[:, :-1] * edges[:, 1:]).sum(dim=-1) + epsilon)
-    )
-    # Cross product of adjacent edges, scaled by the factor. Clamped to avoid large values.
-    o_kb[:, 1:] = torch.clamp(
-        2 * torch.linalg.cross(edges[:, :-1], edges[:, 1:]) * inv_length.unsqueeze(dim=-1),
-        min=-500, max=500
-    )
-    return o_kb
-
-
-def quaternion_q(theta, kb):
-    """
-    Forms a partial quaternion by concatenating twist angles theta and curvature binormal kb along dim=2.
-
-    Args:
-        theta (torch.Tensor): Shape [batch, n_edge, 1]. Twist angles.
-        kb (torch.Tensor): Shape [batch, n_edge, 3]. Curvature binormal.
-
-    Returns:
-        (torch.Tensor): Shape [batch, n_edge, 4]. The combined quaternion-like [theta, kb].
-    """
-    return torch.cat((theta.unsqueeze(dim=2), kb), dim=2)
-
-
-def quaternion_p(theta, kb):
-    """
-    Forms a partial quaternion by concatenating twist angles theta and curvature binormal kb along dim=1.
-    (Slightly different shape arrangement than quaternion_q.)
-
-    Args:
-        theta (torch.Tensor): Shape [batch, 1].
-        kb (torch.Tensor): Shape [batch, 3].
-
-    Returns:
-        (torch.Tensor): Shape [batch, 4]. [theta, kb].
-    """
-    return torch.cat((theta, kb), dim=1)
-
-
-def computeW(kb, m1, m2):
-    """
-    Computes the local 2D curvature components by projecting the discrete curvature binormal onto the material frame.
-
-    Args:
-        kb (torch.Tensor): [batch, n_edge, 3]. The curvature binormal.
-        m1, m2 (torch.Tensor): [batch, n_edge, 3]. The two perpendicular axes of the material frame.
-
-    Returns:
-        o_wij (torch.Tensor): [batch, n_edge, 2]. The curvature in local (m1, m2) coordinates.
-    """
-    o_wij = torch.cat((
-        (kb * m2).sum(dim=2).unsqueeze(dim=2),
-        -(kb * m1).sum(dim=2).unsqueeze(dim=2)
-    ), dim=2)
-    return o_wij
-
-
-def skew_symmetric(edges):
-    """
-    Creates a batch of skew-symmetric matrices for each 3D vector in edges.
-    If v = (x, y, z), the corresponding skew-symmetric matrix is:
-        [ 0   -z   y ]
-        [ z    0  -x ]
-        [-y    x   0 ]
-
-    Args:
-        edges (torch.Tensor): Shape [batch, n_edge, 3]. Each row is a vector.
-
-    Returns:
-        matrix (torch.Tensor): Shape [batch, n_edge, 3, 3]. The skew-symmetric matrices.
-    """
-    batch = edges.size()[0]
-    n_edges = edges.size()[1]
-    matrix = torch.zeros(batch, n_edges, 3, 3, dtype=edges.dtype, device=edges.device)
-    matrix[:, :, 0, 1] = -edges[:, :, 2]
-    matrix[:, :, 0, 2] = edges[:, :, 1]
-    matrix[:, :, 1, 0] = edges[:, :, 2]
-    matrix[:, :, 1, 2] = -edges[:, :, 0]
-    matrix[:, :, 2, 0] = -edges[:, :, 1]
-    matrix[:, :, 2, 1] = edges[:, :, 0]
-    return matrix
-
-
-def scalar_func(edges, restEdgeL):
-    """
-    Computes a scalar function often used in calculations of the discrete rod (like <e_{i}, e_{i+1}>).
-
-    Args:
-        edges (torch.Tensor): [batch, n_edge, 3].
-        restEdgeL (torch.Tensor): [batch, n_edge]. The rest lengths of edges.
-
-    Returns:
-        (torch.Tensor): Scalar result for each pair of adjacent edges in the batch.
-    """
-    return restEdgeL[:, :-1] * restEdgeL[:, 1:] + (edges[:, :-1] * edges[:, 1:]).sum(dim=2)
-
-
-def rotation_matrix(theta):
-    """
-    Constructs 2D rotation matrices for each element in theta.
-
-    Args:
-        theta (torch.Tensor): [batch]. Angles for each batch element.
-
-    Returns:
-        transform_basis (torch.Tensor): [batch, 2, 2]. The rotation matrices.
-    """
-    batch = theta.size()[0]
-    rot_sin = torch.sin(theta)
-    rot_cos = torch.cos(theta)
-    transform_basis = torch.zeros(batch, 2, 2)
-    transform_basis[:, 0, 0] = rot_cos
-    transform_basis[:, 0, 1] = -rot_sin
-    transform_basis[:, 1, 0] = rot_sin
-    transform_basis[:, 1, 1] = rot_cos
-    return transform_basis
-
-
-def quaternion_multiply(q1, q2):
-    """
-    Multiplies two quaternions q1 and q2. Each has shape (batch_size, 4) -> [w, x, y, z].
-
-    Args:
-        q1 (torch.Tensor): [batch, 4].
-        q2 (torch.Tensor): [batch, 4].
-
-    Returns:
-        (torch.Tensor): [batch, 4]. The product of the two quaternions.
-    """
-    w1 = q1[:, 0]
-    x1 = q1[:, 1]
-    y1 = q1[:, 2]
-    z1 = q1[:, 3]
-    w2 = q2[:, 0]
-    x2 = q2[:, 1]
-    y2 = q2[:, 2]
-    z2 = q2[:, 3]
-
-    w = w1 * w2 - x1 * x2 - y1 * y2 - z1 * z2
-    x = w1 * x2 + x1 * w2 + y1 * z2 - z1 * y2
-    y = w1 * y2 - x1 * z2 + y1 * w2 + z1 * x2
-    z = w1 * z2 + x1 * y2 - y1 * x2 + z1 * w2
-    return torch.stack((w, x, y, z), -1)
-
-
-def quaternion_conjugate(q):
-    """
-    Computes the conjugate of a quaternion q = [w, x, y, z].
-    The conjugate is q* = [w, -x, -y, -z].
-
-    Args:
-        q (torch.Tensor): (..., 4). A quaternion or batch of quaternions.
-
-    Returns:
-        q_conj (torch.Tensor): (..., 4). The conjugate of the input quaternion.
-    """
-    q_conj = q.clone()  # copy
-    q_conj[..., 1:] *= -1  # negate the vector part
-    return q_conj
-
-
-def quaternion_rotation(o_u, edges, q, i):
-    """
-    Applies quaternion-based rotation to update the frame vectors (u, v).
-
-    Args:
-        o_u (torch.Tensor): [batch, n_edge, 3]. The initial 'u' direction (Bishop frame).
-        edges (torch.Tensor): [batch, n_edge, 3]. The edge vectors.
-        q (torch.Tensor): [batch, n_edge, 4]. The quaternion for each edge.
-        i (int): The index of the current edge.
-
-    Returns:
-        (u, v) (torch.Tensor, torch.Tensor): The updated frame vectors (u, v) after rotation.
-    """
-    batch = o_u.size()[0]
-    # Build partial quaternion for p
-    p = quaternion_p(torch.zeros(batch, 1).to(o_u.device), o_u[:, i - 1])
-    # Rotate p by q[i]
-    quat_p = quaternion_multiply(quaternion_multiply(q[:, i], p), quaternion_conjugate(q[:, i]))
-    # Normalize to get updated u
-    u = F.normalize(quat_p[:, 1:4], dim=1)
-    # Compute v as cross of edges and u
-    v = F.normalize(torch.cross(edges[:, i], u, dim=-1), dim=1)
-    return u.unsqueeze(dim=1), v.unsqueeze(dim=1)
-
-
-def quaternion_rotation_parallel(cosPhi, sinPhi, axis, io_u):
-    """
-    Applies a rotation about 'axis' using angle components cosPhi, sinPhi in quaternion form to rotate io_u.
-
-    Args:
-        cosPhi (torch.Tensor): Shape [batch].
-        sinPhi (torch.Tensor): Shape [batch].
-        axis (torch.Tensor): Shape [batch, 3]. The rotation axis.
-        io_u (torch.Tensor): Shape [batch, 3]. The vector to rotate.
-
-    Returns:
-        io_u (torch.Tensor): Shape [batch, 3]. The rotated vector.
-    """
-    batch = cosPhi.size()[0]
-    # Form quaternion q
-    q = quaternion_p(
-        cosPhi.view(-1, 1),
-        sinPhi.view(-1, 1) * F.normalize(axis, dim=1)
-    )
-    # Build p
-    p = quaternion_p(torch.zeros(batch, 1).to(io_u.device), io_u)
-    # Apply quaternion rotation
-    quat_p = quaternion_multiply(quaternion_multiply(q, p), quaternion_conjugate(q))
-    io_u = F.normalize(quat_p[:, 1:4], dim=1)
-    return io_u
-
-
-def compute_u0(e0, init_direct):
-    """
-    Initializes the first Bishop frame vector u0 for the first edge.
-    Typically, N_0 = e0 x init_direct, then we define m_u0 = normalize(N_0 x e0).
-
-    Args:
-        e0 (torch.Tensor): [batch, 3]. The first edge vector.
-        init_direct (torch.Tensor): [1, 3]. A reference direction to help define the initial frame.
-
-    Returns:
-        m_u0 (torch.Tensor): [batch, 3]. The initialized first 'u' direction.
-    """
-    batch = e0.size()[0]
-    N_0 = torch.cross(e0, init_direct.view(batch, -1))
-    m_u0 = F.normalize(torch.cross(N_0, e0), dim=1)
-    return m_u0
-
-
-def parallelTransportFrame(e0, e1, io_u):
-    """
-    Parallel transports the frame vector io_u from edge e0 to edge e1, accounting for holonomy in discrete rods.
-    A quaternion-based rotation is applied if the rotation angle is not near zero.
-
-    Args:
-        e0, e1 (torch.Tensor): [batch, 3]. Consecutive edges.
-        io_u (torch.Tensor): [batch, 3]. The frame vector 'u' to be updated.
-
-    Returns:
-        io_u (torch.Tensor): The updated frame vector after parallel transport.
-    """
-    batch = e0.size()[0]
-    err = torch.tensor(1e-6).to(io_u.device)
-
-    # Define axis for rotation:
-    axis = 2 * torch.cross(e0, e1, dim=1) / (e0.norm(dim=1) * e1.norm(dim=1) + (e0 * e1).sum(dim=1)).unsqueeze(dim=1)
-    # Magnitude of the axis (squared)
-    magnitude = (axis * axis).sum(dim=1)
-    sinPhi, cosPhi = extractSinandCos(magnitude)
-
-    # If rotation is almost zero, we apply a simpler re-orthogonalization approach. Otherwise, use quaternion rotation.
-    io_u = torch.where(
-        torch.ones(batch, 1).to(io_u.device) - cosPhi.unsqueeze(dim=1) <= err * torch.ones(batch, 1).to(io_u.device),
-        F.normalize(torch.cross(torch.cross(e1, io_u, dim=1), e1), dim=1),
-        quaternion_rotation_parallel(cosPhi, sinPhi, axis, io_u)
-    )
-    return io_u
-
-
-def DEFT_initialization(parent_vertices, child1_vertices, child2_vertices, n_branch, p_n_vert, cs_n_vert,
-                        rigid_body_coupling_index, parent_mass_scale, parent_moment_scale, children_moment_scale,
-                        children_mass_scale, moment_ratio):
-    """
-    Initializes mass, moment of inertia (MOI), and orientation data for a branched discrete elastic rod system
-    with 1 parent rod and (n_branch-1) child rods.
-
-    Args:
-        parent_vertices (torch.Tensor): [1, p_n_vert, 3]. Coordinates of the parent rod's vertices.
-        child1_vertices, child2_vertices (torch.Tensor): [1, c_n_vert, 3]. Coordinates of child rods.
-        n_branch (int): Total number of rods (1 parent + children).
-        p_n_vert (int): Number of parent vertices.
-        cs_n_vert (List[int]): Number of child vertices for each branch.
-        rigid_body_coupling_index (List[int]): Indices in the parent rod where child rods attach.
-        parent_mass_scale, parent_moment_scale: Scaling factors for parent rod's mass and MOI.
-        children_moment_scale, children_mass_scale: Scaling factors for children rods' MOI and mass.
-        moment_ratio (float): Radius scale ratio relative to parent edge length for MOI calculations.
-
-    Returns:
-        Various tensors related to mass, MOI, orientations, and nominal length for the entire branched system.
-    """
-    # Compute nominal length and radius for parent rod
-    parent_nominal_length = torch.norm(parent_vertices[:, 1:] - parent_vertices[:, :-1], dim=-1)[0]
-    parent_nominal_radius = parent_nominal_length * moment_ratio
-
-    # Compute mass distribution for the parent rod
-    p_DLO_mass = torch.zeros(p_n_vert)
-    # Each edge length is half attributed to the two vertices it connects
-    p_DLO_mass[0:p_n_vert - 1] += parent_nominal_length / 2.
-    p_DLO_mass[1:p_n_vert] += parent_nominal_length / 2.
-    p_DLO_mass = p_DLO_mass * parent_mass_scale
-
-    # Prepare MOI placeholders for the parent (at each coupling index), and define rod orientation.
-    parent_MOI = torch.zeros(len(rigid_body_coupling_index) * 2, 3)
-    parent_rod_axis_angle = torch.zeros(1, 3)
-    parent_rod_orientation = pytorch3d.transforms.rotation_conversions.axis_angle_to_quaternion(parent_rod_axis_angle) \
-        .unsqueeze(dim=0).repeat(1, p_n_vert - 1, 1)
-
-    # Prepare placeholders for children
-    children_vertices = torch.zeros(1, len(cs_n_vert), max(cs_n_vert), 3)
-    children_mass = torch.zeros(len(cs_n_vert), max(cs_n_vert))
-    children_MOI = torch.zeros(len(rigid_body_coupling_index), 3)
-    children_nominal_length = torch.zeros(len(cs_n_vert), max(cs_n_vert) - 1)
-    children_nominal_radius = torch.zeros(len(cs_n_vert), max(cs_n_vert) - 1)
-    child_rod_axis_angle = torch.zeros(1, 3)
-    children_rod_orientation = pytorch3d.transforms.rotation_conversions.axis_angle_to_quaternion(child_rod_axis_angle) \
-        .unsqueeze(dim=0).repeat(1, len(rigid_body_coupling_index), 1)
-
-    # Loop through rigid body coupling points to compute MOI for parent rods at those couplings,
-    # and build child rods.
-    for i in range(len(rigid_body_coupling_index)):
-        # MOI for parent rod at rigid_body_coupling_index[i]-1
-        I_x_parent = 1 / 12 * parent_nominal_length[rigid_body_coupling_index[i] - 1] ** 2 \
-                     + 1 / 4 * parent_nominal_radius[rigid_body_coupling_index[i] - 1] ** 2
-        I_y_parent = I_x_parent
-        I_z_parent = 1 / 2 * parent_nominal_radius[rigid_body_coupling_index[i] - 1] ** 2
-        parent_MOI[2 * i, 0] = I_x_parent * parent_moment_scale
-        parent_MOI[2 * i, 1] = I_y_parent * parent_moment_scale
-        parent_MOI[2 * i, 2] = I_z_parent * parent_moment_scale
-
-        # Another MOI for the second index usage
-        I_x_parent = 1 / 12 * parent_nominal_length[rigid_body_coupling_index[0]] ** 2 \
-                     + 1 / 4 * parent_nominal_radius[rigid_body_coupling_index[0]] ** 2
-        I_y_parent = I_x_parent
-        I_z_parent = 1 / 2 * parent_nominal_radius[rigid_body_coupling_index[0]] ** 2
-        parent_MOI[2 * i + 1, 0] = I_x_parent * parent_moment_scale
-        parent_MOI[2 * i + 1, 1] = I_y_parent * parent_moment_scale
-        parent_MOI[2 * i + 1, 2] = I_z_parent * parent_moment_scale
-
-        c_n_vert = cs_n_vert[i]
-
-        # Merge child rod with the parent rod at the coupling index
-        if i == 0:
-            # Insert the parent's coupling point + child1 vertices
-            children_vertices[:, i, :c_n_vert] = torch.cat(
-                (parent_vertices[:, rigid_body_coupling_index[i]].unsqueeze(dim=1), child1_vertices), dim=1
-            )
-        if i == 1:
-            children_vertices[:, i, :c_n_vert] = torch.cat(
-                (parent_vertices[:, rigid_body_coupling_index[i]].unsqueeze(dim=1), child2_vertices), dim=1
-            )
-
-        # Compute length and radius for children
-        child_nominal_length = \
-        torch.norm(children_vertices[:, i, 1:c_n_vert] - children_vertices[:, i, :c_n_vert - 1], dim=-1)[0]
-        child_nominal_radius = child_nominal_length * moment_ratio
-        # Mass distribution for the child rod
-        child_mass = torch.zeros(c_n_vert)
-        child_mass[0:c_n_vert - 1] += child_nominal_length / 2.
-        child_mass[1:c_n_vert] += child_nominal_length / 2.
-        child_mass = child_mass * children_mass_scale[i]
-        children_mass[i, :c_n_vert] = child_mass
-
-        # Save child nominal lengths/radii
-        children_nominal_length[i, :c_n_vert - 1] = child_nominal_length
-        children_nominal_radius[i, :c_n_vert - 1] = child_nominal_radius
-        I_y_child = 1 / 12 * child_nominal_length[0] ** 2 + 1 / 4 * child_nominal_radius[0] ** 2
-        I_x_child = I_y_parent
-        I_z_child = 1 / 2 * child_nominal_radius[0] ** 2
-        children_MOI[i, 0] = I_x_child * children_moment_scale[i]
-        children_MOI[i, 1] = I_y_child * children_moment_scale[i]
-        children_MOI[i, 2] = I_z_child * children_moment_scale[i]
-
-    # Collect mass data for the branched rods (b_DLO refers to 'branched DLO').
-    b_DLO_mass = torch.zeros(n_branch, p_n_vert)
-    b_DLO_mass[0] = p_DLO_mass
-    b_DLO_mass[1:, :children_mass.size()[1]] = children_mass
-
-    # Collect nominal length data
-    b_nominal_length = torch.zeros(n_branch, p_n_vert - 1)
-    b_nominal_length[0] = parent_nominal_length
-    b_nominal_length[1:, :children_nominal_length.size()[1]] = children_nominal_length
-
-    return b_DLO_mass, parent_MOI, children_MOI, parent_rod_orientation, children_rod_orientation, b_nominal_length
-
-
-def construct_b_DLOs(batch, rigid_body_coupling_index, p_n_vert, cs_n_vert, n_branch,
-                     previous_parent_vertices, parent_vertices,
-                     previous_child1_vertices, child1_vertices,
-                     previous_child2_vertices, child2_vertices):
-    """
-    Constructs a batched representation of the full branched DLO's vertices:
-    [batch, n_branch, p_n_vert, 3].
-
-    We integrate the parent rod and the child rods by merging the child's start vertex with
-    the parent's coupling vertex.
-
-    Args:
-        batch (int): Batch size.
-        rigid_body_coupling_index (List[int]): The indices on the parent rod where each child rod connects.
-        p_n_vert (int): Number of parent rod vertices.
-        cs_n_vert (List[int]): Number of child vertices for each branch.
-        n_branch (int): Total branches (1 parent + others children).
-        previous_parent_vertices, parent_vertices, previous_child1_vertices, child1_vertices, ...
-            (torch.Tensor): The 3D coordinates for each rod's vertices, possibly from two timesteps (previous & current).
-
-    Returns:
-        b_DLOs_vertices, previous_b_DLOs_vertices (torch.Tensor):
-            Shape [batch, n_branch, p_n_vert, 3]. The constructed branched rods for current and previous timesteps.
-    """
-    b_DLOs_vertices = torch.zeros(batch, n_branch, p_n_vert, 3)
-    previous_b_DLOs_vertices = torch.zeros(batch, n_branch, p_n_vert, 3)
-
-    # The first branch is the parent itself
-    b_DLOs_vertices[:, 0] = parent_vertices
-    previous_b_DLOs_vertices[:, 0] = previous_parent_vertices
-
-    # Build the children rods
-    for i in range(n_branch - 1):
-        c_n_vert = cs_n_vert[i]
-        if i == 0:
-            b_DLOs_vertices[:, i + 1, :c_n_vert] = torch.cat(
-                (parent_vertices[:, rigid_body_coupling_index[i]].unsqueeze(dim=1), child1_vertices), dim=1
-            )
-            previous_b_DLOs_vertices[:, i + 1, :c_n_vert] = torch.cat(
-                (previous_parent_vertices[:, rigid_body_coupling_index[i]].unsqueeze(dim=1), previous_child1_vertices),
-                dim=1
-            )
-        if i == 1:
-            b_DLOs_vertices[:, i + 1, :c_n_vert] = torch.cat(
-                (parent_vertices[:, rigid_body_coupling_index[i]].unsqueeze(dim=1), child2_vertices), dim=1
-            )
-            previous_b_DLOs_vertices[:, i + 1, :c_n_vert] = torch.cat(
-                (previous_parent_vertices[:, rigid_body_coupling_index[i]].unsqueeze(dim=1), previous_child2_vertices),
-                dim=1
-            )
-    return b_DLOs_vertices, previous_b_DLOs_vertices
-
-
-def construct_BDLOs_data(total_length, rigid_body_coupling_index, p_n_vert, cs_n_vert, n_branch,
-                         parent_vertices, child1_vertices, child2_vertices):
-    """
-    Constructs a timeline of branched DLO vertices for a sequence of length total_length.
-
-    Args:
-        total_length (int): The total number of timesteps in the data.
-        rigid_body_coupling_index (List[int]): Indices on the parent rod for branching.
-        p_n_vert (int): Number of vertices in the parent rod.
-        cs_n_vert (List[int]): Number of vertices in each child rod.
-        n_branch (int): Total branches (1 parent + children).
-        parent_vertices, child1_vertices, child2_vertices (torch.Tensor): [total_length, n_*_vertices, 3].
-
-    Returns:
-        b_DLOs_vertices (torch.Tensor): [total_length, n_branch, p_n_vert, 3]. The merged rod system over time.
-    """
-    b_DLOs_vertices = torch.zeros(total_length, n_branch, p_n_vert, 3)
-    # First branch is the parent
-    b_DLOs_vertices[:, 0] = parent_vertices
-    # Build the child rods
-    for i in range(n_branch - 1):
-        c_n_vert = cs_n_vert[i]
-        if i == 0:
-            b_DLOs_vertices[:, i + 1, :c_n_vert] = torch.cat(
-                (parent_vertices[:, rigid_body_coupling_index[i]].unsqueeze(dim=1), child1_vertices), dim=1
-            )
-        if i == 1:
-            b_DLOs_vertices[:, i + 1, :c_n_vert] = torch.cat(
-                (parent_vertices[:, rigid_body_coupling_index[i]].unsqueeze(dim=1), child2_vertices), dim=1
-            )
-    return b_DLOs_vertices
-
-
-def label_tensor(tensor):
-    """
-    Interprets special clamp values within a tensor (0, 1), (-2, -1) as boundary conditions.
-    Also handles extremely large clamp marks (1e10).
-
-    Returns a list or tuple of 'labels' extracted. E.g., if (0,1) is present, add 0 to output.
-    If (-2,-1) is present, add -1 to output. Otherwise, includes the leftover elements.
-    """
-    clamp_mark = 1e10
-    tensor = tensor.float()
-
-    # If entire tensor is the clamp_mark, return empty
-    if torch.all(tensor == clamp_mark):
-        return ()
-
-    # If fewer than 2 elements, just return them
-    if tensor.numel() < 2:
-        other_numbers = tensor if tensor.numel() > 0 else torch.tensor([])
-        output = []
-        if other_numbers.numel() > 0:
-            output.extend(other_numbers.tolist())
-        return tuple(output)
-
-    # Create pairs
-    pairs = torch.stack((tensor[:-1], tensor[1:]), dim=1)
-
-    # Define patterns
-    pair_0_1 = torch.tensor([0, 1])
-    pair_neg2_neg1 = torch.tensor([-2, -1])
-
-    pair_mask = torch.zeros(tensor.size(0), dtype=torch.bool)
-
-    is_0_1 = torch.all(pairs == pair_0_1, dim=1)
-    indices_0_1 = torch.nonzero(is_0_1, as_tuple=False).flatten()
-
-    is_neg2_neg1 = torch.all(pairs == pair_neg2_neg1, dim=1)
-    indices_neg2_neg1 = torch.nonzero(is_neg2_neg1, as_tuple=False).flatten()
-
-    for idx in indices_0_1:
-        pair_mask[idx] = True
-        pair_mask[idx + 1] = True
-    for idx in indices_neg2_neg1:
-        pair_mask[idx] = True
-        pair_mask[idx + 1] = True
-
-    other_numbers = tensor[~pair_mask]
-    output = []
-
-    if indices_0_1.numel() > 0:
-        output.append(0)
-
-    if other_numbers.numel() > 0:
-        output.extend(other_numbers.tolist())
-
-    if indices_neg2_neg1.numel() > 0:
-        output.append(-1)
-
-    return output
-
-
-def clamp_init(batch, parent_clamped_selection, child1_clamped_selection, child2_clamped_selection,
-               n_branch, p_n_vert,
-               clamp_parent, clamp_child1, clamp_child2,
-               parent_vertices_traj, child1_vertices_traj, child2_vertices_traj):
-    """
-    Initializes clamp indices for the rods. A clamp means a vertex whose twist angle is fixed.
-
-    Args:
-        parent_clamped_selection, child1_clamped_selection, child2_clamped_selection:
-            The vertices chosen to clamp (can include special values like -1).
-        clamp_parent, clamp_child1, clamp_child2 (bool): Whether each rod is clamped.
-        parent_vertices_traj, child*_vertices_traj (torch.Tensor): Vertex trajectories for each rod.
-
-    Returns:
-        clamped_index (torch.Tensor): [n_branch, p_n_vert]. Mark =1 where clamp is applied.
-        parent_fix_point, child1_fix_point, child2_fix_point (torch.Tensor or None):
-            The positions of the clamped vertices repeated along batch dimension.
-        parent_theta_clamp, child1_theta_clamp, child2_theta_clamp (Union[torch.Tensor, None]):
-            The final clamp 'labels' derived from label_tensor or None if not clamped.
-    """
-    clamped_index = torch.zeros(n_branch, p_n_vert)
-
-    if clamp_parent:
-        clamped_index[0, parent_clamped_selection] = torch.tensor((1.))
-        # Repeat the fix point for the entire batch
-        parent_fix_point = parent_vertices_traj[:, parent_clamped_selection].unsqueeze(dim=0).repeat(batch, 1, 1, 1)
-        parent_theta_clamp = label_tensor(parent_clamped_selection)
-    else:
-        parent_fix_point = None
-        parent_theta_clamp = None
-
-    if clamp_child1:
-        clamped_index[1, child1_clamped_selection] = torch.tensor((1.))
-        child1_fix_point = child1_vertices_traj[:, child1_clamped_selection - 1].unsqueeze(dim=0).repeat(batch, 1, 1, 1)
-        if child1_clamped_selection == -1:
-            child1_theta_clamp = torch.tensor((-1))
-        else:
-            child1_theta_clamp = child1_clamped_selection
-    else:
-        child1_fix_point = None
-        child1_theta_clamp = None
-
-    if clamp_child2:
-        clamped_index[2, child2_clamped_selection] = torch.tensor((1.))
-        child2_fix_point = child2_vertices_traj[:, child2_clamped_selection - 1].unsqueeze(dim=0).repeat(batch, 1, 1, 1)
-        if child2_clamped_selection == -1:
-            child2_theta_clamp = torch.tensor((-1))
-        else:
-            child2_theta_clamp = child2_clamped_selection
-    else:
-        child2_fix_point = None
-        child2_theta_clamp = None
-
-    return (clamped_index, parent_fix_point, child1_fix_point, child2_fix_point,
-            parent_theta_clamp, child1_theta_clamp, child2_theta_clamp)
-
-
-def clamp_index(batch, parent_clamped_selection, child1_clamped_selection, child2_clamped_selection,
-                n_branch, p_n_vert, clamp_parent, clamp_child1, clamp_child2):
-    """
-    Similar to clamp_init but only returns the clamp indices and theta clamp values without fix points.
-
-    Args:
-        parent_clamped_selection, child1_clamped_selection, child2_clamped_selection: Indices to clamp.
-        n_branch, p_n_vert (int): Number of rods and parent vertices.
-        clamp_parent, clamp_child1, clamp_child2 (bool): Flags for each rod.
-
-    Returns:
-        clamped_index (torch.Tensor): [n_branch, p_n_vert]. Mark =1 where clamp is applied.
-        parent_theta_clamp, child1_theta_clamp, child2_theta_clamp (Union[torch.Tensor, None]):
-            The clamp selection or None for each rod.
-    """
-    clamped_index = torch.zeros(n_branch, p_n_vert)
-
-    if clamp_parent:
-        clamped_index[0, parent_clamped_selection] = torch.tensor((1.))
-        parent_theta_clamp = label_tensor(parent_clamped_selection)
-    else:
-        parent_theta_clamp = None
-
-    if clamp_child1:
-        clamped_index[1, child1_clamped_selection] = torch.tensor((1.))
-        if child1_clamped_selection == -1:
-            child1_theta_clamp = torch.tensor((-1))
-        else:
-            child1_theta_clamp = child1_clamped_selection
-    else:
-        child1_theta_clamp = None
-
-    if clamp_child2:
-        clamped_index[2, child2_clamped_selection] = torch.tensor((1.))
-        if child2_clamped_selection == -1:
-            child2_theta_clamp = torch.tensor((-1))
-        else:
-            child2_theta_clamp = child2_clamped_selection
-    else:
-        child2_theta_clamp = None
-
-    return clamped_index, parent_theta_clamp, child1_theta_clamp, child2_theta_clamp
-
-
-def index_init(rigid_body_coupling_index, n_branch):
-    """
-    Generates index arrays for MOI-based indexing in parent rods.
-
-    Args:
-        rigid_body_coupling_index (List[int]): Indices to be used for coupling or MOI references.
-        n_branch (int): Number of branches (parent + children).
-
-    Returns:
-        index_selection1, index_selection2, parent_MOI_index1, parent_MOI_index2 (torch.Tensor):
-            Various index selections computed from the coupling indices.
-    """
-    # Adjust the index for parent rod
-    index_selection1 = torch.tensor(rigid_body_coupling_index) - 1
-    start = 0
-    end = (n_branch - 1) * 2 - 2
-    num_points = len(rigid_body_coupling_index)
-    parent_MOI_index1 = torch.linspace(start, end, num_points).to(torch.int)
-
-    index_selection2 = torch.tensor(rigid_body_coupling_index)
-    start = 1
-    end = (n_branch - 1) * 2 - 1
-    parent_MOI_index2 = torch.linspace(start, end, num_points).to(torch.int)
-    return index_selection1, index_selection2, parent_MOI_index1, parent_MOI_index2
-
-
-def visualize_tensors_3d_in_same_plot_no_zeros(
-        parent_clamped_selection, tensor_1, tensor_2, ith, test_data_index,
-        clamp_parent, clamp_child1, clamp_child2,
-        parent_fix_point_flat2, child1_fix_point_flat, child2_fix_point_flat,
-        additional_tensor_1, additional_tensor_2, additional_tensor_3, i_eval_batch, vis_type
-):
-    """
-    Plots multiple 3D tensor datasets in a single figure with two 3D subplots (two different view angles).
-    Zeros are filtered out (ignored), and certain indices from parent_clamped_selection are highlighted.
-
-    Args:
-        parent_clamped_selection (torch.Tensor): Indices in tensor_1 (the main rod) that are clamped or special.
-        tensor_1 (torch.Tensor): A main set of 3D points (e.g., predicted rod).
-        tensor_2 (torch.Tensor): Possibly multiple sets of 3D points to overlay (e.g., other rods).
-        additional_tensor_1, additional_tensor_2, additional_tensor_3: Extra sets of points to overlay (e.g. ground truth).
-        clamp_parent, clamp_child1, clamp_child2 (bool): Flags that decide if fix points are plotted.
-        parent_fix_point_flat2, child1_fix_point_flat, child2_fix_point_flat (torch.Tensor or None):
-            The fix/clamp points to highlight if clamps are used.
-        i_eval_batch (int): ID for saving directory path.
-        vis_type (str): Directory subfolder for saving the results.
-
-    Returns:
-        None. Saves a .png file of the 3D plot.
-    """
-
-    def filter_non_zero_points(tensor):
-        # Filters out rows that are all zeros in the last dimension
-        non_zero_mask = torch.any(tensor != 0, dim=-1)
-        return tensor[non_zero_mask]
-
-    # Create 2 subplots (two views) in 3D
-    fig = plt.figure(figsize=(16, 8))
-    ax1 = fig.add_subplot(121, projection='3d')
-    ax1.set_title('View 1')
-    ax2 = fig.add_subplot(122, projection='3d')
-    ax2.set_title('View 2')
-
-    # Core plotting function
-    def plot_tensors(ax):
-        N = tensor_1.shape[0]
-
-        # Convert negative indices to positive with modulo, then remove duplicates
-        selected_indices = parent_clamped_selection % N
-        selected_indices = np.unique(selected_indices)
-        total_indices = np.arange(N)
-        non_selected_indices = np.setdiff1d(total_indices, selected_indices)
-
-        # Identify negative indices (originally <0)
-        negative_indices = parent_clamped_selection[parent_clamped_selection < 0] % N
-        negative_indices = np.unique(negative_indices)
-        # Positive indices
-        positive_indices = np.setdiff1d(selected_indices, negative_indices)
-
-        # Plot additional_tensor_1 (likely ground truth)
-        additional_tensor_1_filtered = filter_non_zero_points(additional_tensor_1)
-        if additional_tensor_1_filtered.size(0) > 0:
-            ax.scatter(
-                additional_tensor_1_filtered[:, 0].detach().cpu().numpy(),
-                additional_tensor_1_filtered[:, 1].detach().cpu().numpy(),
-                additional_tensor_1_filtered[:, 2].detach().cpu().numpy(),
-                c='black', marker='o', s=30, label='Ground Truth'
-            )
-        # Plot additional_tensor_2
-        additional_tensor_2_filtered = filter_non_zero_points(additional_tensor_2)
-        if additional_tensor_2_filtered.size(0) > 0:
-            ax.scatter(
-                additional_tensor_2_filtered[:, 0].detach().cpu().numpy(),
-                additional_tensor_2_filtered[:, 1].detach().cpu().numpy(),
-                additional_tensor_2_filtered[:, 2].detach().cpu().numpy(),
-                c='black', marker='o', alpha=1.0, s=30
-            )
-        # Plot additional_tensor_3
-        additional_tensor_3_filtered = filter_non_zero_points(additional_tensor_3)
-        if additional_tensor_3_filtered.size(0) > 0:
-            ax.scatter(
-                additional_tensor_3_filtered[:, 0].detach().cpu().numpy(),
-                additional_tensor_3_filtered[:, 1].detach().cpu().numpy(),
-                additional_tensor_3_filtered[:, 2].detach().cpu().numpy(),
-                c='black', marker='o', alpha=1.0, s=30
-            )
-
-        # Plot non-selected points from tensor_1
-        tensor_1_non_selected = tensor_1[non_selected_indices]
-        tensor_1_non_selected = filter_non_zero_points(tensor_1_non_selected)
-        if tensor_1_non_selected.size(0) > 0:
-            ax.scatter(
-                tensor_1_non_selected[:, 0].detach().cpu().numpy(),
-                tensor_1_non_selected[:, 1].detach().cpu().numpy(),
-                tensor_1_non_selected[:, 2].detach().cpu().numpy(),
-                c='blue', marker='o', alpha=1.0, s=30, label='Prediction'
-            )
-
-        # Plot selected points with positive indices
-        tensor_1_positive = tensor_1[positive_indices]
-        tensor_1_positive = filter_non_zero_points(tensor_1_positive)
-        if tensor_1_positive.size(0) > 0:
-            ax.scatter(
-                tensor_1_positive[:, 0].detach().cpu().numpy(),
-                tensor_1_positive[:, 1].detach().cpu().numpy(),
-                tensor_1_positive[:, 2].detach().cpu().numpy(),
-                c='red', marker='o', alpha=1.0, s=40, label='Clamped Points'
-            )
-
-        # Plot selected points with negative indices
-        tensor_1_negative = tensor_1[negative_indices]
-        tensor_1_negative = filter_non_zero_points(tensor_1_negative)
-        if tensor_1_negative.size(0) > 0:
-            ax.scatter(
-                tensor_1_negative[:, 0].detach().cpu().numpy(),
-                tensor_1_negative[:, 1].detach().cpu().numpy(),
-                tensor_1_negative[:, 2].detach().cpu().numpy(),
-                c='red', marker='o', alpha=1.0, s=40
-            )
-
-        # Plot each row in tensor_2
-        for i in range(tensor_2.shape[0]):
-            filtered_tensor_2 = filter_non_zero_points(tensor_2[i])
-            if filtered_tensor_2.size(0) > 0:
-                ax.scatter(
-                    filtered_tensor_2[:, 0].detach().cpu().numpy(),
-                    filtered_tensor_2[:, 1].detach().cpu().numpy(),
-                    filtered_tensor_2[:, 2].detach().cpu().numpy(),
-                    c='blue', alpha=1.0, s=30, marker='o'
-                )
-
-        # If child rods are clamped, plot the fix points
-        if clamp_child1 and child1_fix_point_flat is not None:
-            points = child1_fix_point_flat[0]
-            filtered_points = filter_non_zero_points(points)
-            if filtered_points.size(0) > 0:
-                ax.scatter(
-                    filtered_points[:, 0].detach().cpu().numpy(),
-                    filtered_points[:, 1].detach().cpu().numpy(),
-                    filtered_points[:, 2].detach().cpu().numpy(),
-                    c='red', s=40, marker='o', label='Child1 Fix Points'
-                )
-        if clamp_child2 and child2_fix_point_flat is not None:
-            points = child2_fix_point_flat[0]
-            filtered_points = filter_non_zero_points(points)
-            if filtered_points.size(0) > 0:
-                ax.scatter(
-                    filtered_points[:, 0].detach().cpu().numpy(),
-                    filtered_points[:, 1].detach().cpu().numpy(),
-                    filtered_points[:, 2].detach().cpu().numpy(),
-                    c='red', s=40, marker='o', label='Child2 Fix Points'
-                )
-
-        # Configure plot
-        ax.set_xlim(-0.5, 1.0)
-        ax.set_ylim(-0.5, 1.0)
-        ax.set_zlim(-0.25, 1.25)
-        ax.set_xlabel('X')
-        ax.set_ylabel('Y')
-        ax.set_zlabel('Z')
-        ax.legend()
-
-    # Plot on both subplots
-    plot_tensors(ax1)
-    plot_tensors(ax2)
-
-    # Adjust viewpoints
-    ax1.view_init(elev=0, azim=90)
-    ax2.view_init(elev=30, azim=-45)
-
-    # Save the figure
-    dir_path = Path(f"sanity_check/{vis_type}/{i_eval_batch}")
-    dir_path.mkdir(parents=True, exist_ok=True)
-
-    plt.savefig(f"sanity_check/{vis_type}/{i_eval_batch}/{ith}.png")
-    plt.close(fig)
-
-
-def save_pickle(data, myfile):
-    """
-    Saves data to a pickle file.
-
-    Args:
-        data: The Python object to save.
-        myfile (str): Path where the file will be stored.
-
-    Returns:
-        None.
-    """
-    with open(myfile, "wb") as f:
-        pickle.dump(data, f)
-
-
-class Train_DEFTData(Dataset):
-    """
-    A PyTorch Dataset for loading and transforming training data for DEFT-based rod simulation.
-    Each data item is a triple of (previous_vertices, current_vertices, target_vertices, mu_0).
-
-    This is typically used to train a model that predicts how the rod evolves from t to t+training_time_horizon.
-    """
-
-    def __init__(self, BDLO_type, n_parent_vertices, n_children_vertices, n_branch,
-                 rigid_body_coupling_index, train_set_number, total_time, training_time_horizon, device):
-        super(Train_DEFTData, self).__init__()
-        # Root directory containing data
-        self.root_dir = "dataset/BDLO%s/train/" % BDLO_type
-        file_list = glob.glob(self.root_dir + "*")
-        self.device = device
-
-        # Preallocate data holders
-        self.BDLOs_previous_vertices = []
-        self.BDLOs_vertices = []
-        self.BDLOs_target_vertices = []
-        n_child1_vertices, n_child2_vertices = n_children_vertices
-        self.mu_0 = []
-        self.parent_input = []
-        self.child1_input = []
-        self.child2_input = []
-
-        # Hard-coded points / midpoint (seem to be a user-specific coordinate transformation)
-        point1 = np.array([0.652495, 0.012239, -0.703962])
-        point2 = np.array([0.359612, 0.012701, -0.701503])
-        point3 = np.array([0.358077, 0.009511, -0.995053])
-        midpoint = np.array([
-            point2[0] + (point1[0] - point2[0]) / 2.,
-            (point1[1] + point2[1] + point3[1]) / 3,
-            point2[2] - (point2[2] - point3[2]) / 2.
-        ])
-        midpoint_mod = torch.tensor(np.array([-midpoint[2], -midpoint[0], midpoint[1]]))
-
-        bar = tqdm(file_list)
-        for rope_data in bar:
-            # Load data, shape: (3, total_time, n_parent_vertices + something?), then rearrange
-            verts = torch.tensor(pd.read_pickle(r'%s' % str(rope_data))) \
-                .view(3, total_time, -1).permute(1, 2, 0)
-
-            # Separate into parent, child1, child2
-            parent_vertices = verts[:, :n_parent_vertices]
-            child1_vertices = verts[:, n_parent_vertices: n_parent_vertices + n_child1_vertices - 1]
-            child2_vertices = verts[:, n_parent_vertices + n_child1_vertices - 1:]
-
-            # Construct the branched rod data structure for the entire time sequence
-            BDLO_vert_no_trans = construct_BDLOs_data(total_time, rigid_body_coupling_index,
-                                                      n_parent_vertices, n_children_vertices,
-                                                      n_branch, parent_vertices, child1_vertices, child2_vertices)
-            # Transform from (x,y,z)->(-z, -x, y) for user coordinate system
-            BDLO_vert = torch.zeros_like(BDLO_vert_no_trans)
-            BDLO_vert[:, :, :, 0] = -BDLO_vert_no_trans[:, :, :, 2]
-            BDLO_vert[:, :, :, 1] = -BDLO_vert_no_trans[:, :, :, 0]
-            BDLO_vert[:, :, :, 2] = BDLO_vert_no_trans[:, :, :, 1]
-
-            mu_0_list = torch.zeros(verts.size()[0] - 1 - 1, n_branch, 3).to(self.device)
-
-            # Build up sequences (previous, current, next) for the training horizon
-            for i in range(total_time - 1 - training_time_horizon):
-                # The size check ensures each chunk is [training_time_horizon, n_branch, n_parent_vertices, 3]
-                if not BDLO_vert[i: i + training_time_horizon].size() == (
-                training_time_horizon, n_branch, n_parent_vertices, 3):
-                    print("False Size")
-                self.BDLOs_previous_vertices.append(BDLO_vert[i: i + training_time_horizon].numpy())
-                self.BDLOs_vertices.append(BDLO_vert[i + 1: i + 1 + training_time_horizon].numpy())
-                self.BDLOs_target_vertices.append(BDLO_vert[i + 2: i + 2 + training_time_horizon].numpy())
-                self.mu_0.append(mu_0_list[i: i + training_time_horizon])
-
-        # Convert to np.array for indexing
-        self.previous_vertices = np.array(self.BDLOs_previous_vertices)
-        self.vertices = np.array(self.BDLOs_vertices)
-        self.target_vertices = np.array(self.BDLOs_target_vertices)
-
-    def __len__(self):
-        # Number of training sequences
-        return len(self.vertices)
-
-    def __getitem__(self, index):
-        # Return a single training sequence: (previous, current, target, mu_0)
-        previous_vertices = torch.tensor(self.previous_vertices[index]).to(self.device)
-        vertices = torch.tensor(self.vertices[index]).to(self.device)
-        target_vertices = torch.tensor(self.target_vertices[index]).to(self.device)
-        return (previous_vertices.clone().detach(),
-                vertices.clone().detach(),
-                target_vertices.clone().detach(),
-                self.mu_0[index].clone().detach())
-
-
-class Eval_DEFTData(Dataset):
-    """
-    A PyTorch Dataset for loading and transforming evaluation data for DEFT-based rod simulation.
-    Each data item is (previous_vertices, current_vertices, target_vertices), typically over a longer time horizon.
-    """
-
-    def __init__(self, BDLO_type, n_parent_vertices, n_children_vertices, n_branch,
-                 rigid_body_coupling_index, eval_set_number, total_time, eval_time_horizon, device):
-        super(Eval_DEFTData, self).__init__()
-        # Root directory for evaluation data
-        self.root_dir = "dataset/BDLO%s/eval/" % BDLO_type
-        file_list = glob.glob(self.root_dir + "*")
-        self.device = device
-
-        self.BDLOs_previous_vertices = []
-        self.BDLOs_vertices = []
-        self.BDLOs_target_vertices = []
-
-        n_child1_vertices, n_child2_vertices = n_children_vertices
-
-        # Hard-coded transformations
-        point1 = np.array([0.652495, 0.012239, -0.703962])
-        point2 = np.array([0.359612, 0.012701, -0.701503])
-        point3 = np.array([0.358077, 0.009511, -0.995053])
-        midpoint = np.array([
-            point2[0] + (point1[0] - point2[0]) / 2.,
-            (point1[1] + point2[1] + point3[1]) / 3,
-            point2[2] - (point2[2] - point3[2]) / 2.
-        ])
-        midpoint_mod = torch.tensor(np.array([-midpoint[2], -midpoint[0], midpoint[1]]))
-
-        bar = tqdm(file_list)
-        for rope_data in bar:
-            # Same reading procedure as training set
-            verts = torch.tensor(pd.read_pickle(r'%s' % str(rope_data))) \
-                .view(3, total_time, -1).permute(1, 2, 0)
-
-            parent_vertices = verts[:, :n_parent_vertices]
-            child1_vertices = verts[:, n_parent_vertices: n_parent_vertices + n_child1_vertices - 1]
-            child2_vertices = verts[:, n_parent_vertices + n_child1_vertices - 1:]
-
-            BDLO_vert_no_trans = construct_BDLOs_data(total_time, rigid_body_coupling_index,
-                                                      n_parent_vertices, n_children_vertices,
-                                                      n_branch, parent_vertices, child1_vertices, child2_vertices)
-            BDLO_vert = torch.zeros_like(BDLO_vert_no_trans)
-            BDLO_vert[:, :, :, 0] = -BDLO_vert_no_trans[:, :, :, 2]
-            BDLO_vert[:, :, :, 1] = -BDLO_vert_no_trans[:, :, :, 0]
-            BDLO_vert[:, :, :, 2] = BDLO_vert_no_trans[:, :, :, 1]
-
-            # We only take the first [eval_time_horizon] chunk for the previous, current, target.
-            if not BDLO_vert[0: 0 + eval_time_horizon].size() == (eval_time_horizon, n_branch, n_parent_vertices, 3):
-                print("False Size")
-            self.BDLOs_previous_vertices.append(BDLO_vert[0: 0 + eval_time_horizon].numpy())
-            self.BDLOs_vertices.append(BDLO_vert[1: 1 + eval_time_horizon].numpy())
-            self.BDLOs_target_vertices.append(BDLO_vert[2: 2 + eval_time_horizon].numpy())
-
-        self.previous_vertices = np.array(self.BDLOs_previous_vertices)
-        self.vertices = np.array(self.BDLOs_vertices)
-        self.target_vertices = np.array(self.BDLOs_target_vertices)
-
-    def __len__(self):
-        # Number of evaluation sequences
-        return len(self.vertices)
-
-    def __getitem__(self, index):
-        # Return (previous, current, target)
-        previous_vertices = torch.tensor(self.previous_vertices[index]).to(self.device)
-        vertices = torch.tensor(self.vertices[index]).to(self.device)
-        target_vertices = torch.tensor(self.target_vertices[index]).to(self.device)
-        return (previous_vertices.clone().detach(),
-                vertices.clone().detach(),
-                target_vertices.clone().detach())
